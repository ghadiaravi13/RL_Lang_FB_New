{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccce523c-f7e2-459c-89d3-775573e476e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset feedback_qa (/home/raja/.cache/huggingface/datasets/McGill-NLP___feedback_qa/plain_text/1.0.0/20c8f938f417c88303bb7041cea9554c1d14667686d7d7c5dda83dd4f39e5dc4)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0179440975189209,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d75674c25274c8dae88f198ad586f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "from torch import nn\n",
    "from nltk import tokenize as nltk_tokenizer\n",
    "\n",
    "dataset = load_dataset(\"McGill-NLP/feedbackQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4626aded-95e1-47ec-bb47-59914940c8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_scores = {'Excellent':3 , 'Acceptable':2 , 'Could be Improved':1, 'Bad': -1}\n",
    "\n",
    "def process_df(df):\n",
    "    df['list_feedback'] = df['feedback'].apply(lambda x: [ r + \"___\" + e for r,e in zip(x['rating'],x['explanation']) ])\n",
    "    df['sampled_feedback'] = df['list_feedback'].apply(lambda x: np.random.choice(x).split(\"___\") )\n",
    "    df['rating_score'] = df['sampled_feedback'].apply(lambda x: rating_scores[x[0]])\n",
    "    df['rating'] = df['sampled_feedback'].apply(lambda x: x[0])\n",
    "    df['explanation'] = df['sampled_feedback'].apply(lambda x: x[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2ffa3d-fae5-45d9-89c6-899dba3982fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = process_df(pd.DataFrame(dataset['train']))\n",
    "val_df = process_df(pd.DataFrame(dataset['validation']))\n",
    "test_df = process_df(pd.DataFrame(dataset['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40dc46db-a864-459a-8e7a-b82df484643b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "bert_chkpt = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_chkpt)\n",
    "model = AutoModel.from_pretrained(bert_chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31c623b-2b7b-4b28-a499-b63ba8311ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '[UNK]', '<pad>', '<mask>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744c4863-8096-4c67-b473-90e03a0df39c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>feedback</th>\n",
       "      <th>list_feedback</th>\n",
       "      <th>sampled_feedback</th>\n",
       "      <th>rating_score</th>\n",
       "      <th>rating</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Could be Improved'],...</td>\n",
       "      <td>[Excellent___Has a link to detailed informatio...</td>\n",
       "      <td>[Excellent, Has a link to detailed information...</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Has a link to detailed information about gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Excellent'], 'explan...</td>\n",
       "      <td>[Excellent___A link to a job search website is...</td>\n",
       "      <td>[Excellent, A link to a job search website is ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A link to a job search website is included, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information and support...</td>\n",
       "      <td>{'rating': ['Bad', 'Acceptable'], 'explanation...</td>\n",
       "      <td>[Bad___Talks about tax credits for businesses ...</td>\n",
       "      <td>[Acceptable, This answer discusses the Employm...</td>\n",
       "      <td>2</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>This answer discusses the Employment Fund, whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nWorking holiday ma...</td>\n",
       "      <td>{'rating': ['Could be Improved', 'Acceptable']...</td>\n",
       "      <td>[Could be Improved___Answer is about Working H...</td>\n",
       "      <td>[Acceptable, Answer is rather cut and dry but ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Answer is rather cut and dry but is also a lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nCOVID-19 Pandemic ...</td>\n",
       "      <td>{'rating': ['Bad', 'Could be Improved'], 'expl...</td>\n",
       "      <td>[Bad___Discusses pandemic visas. Doesn't menti...</td>\n",
       "      <td>[Could be Improved, This answer is very vague ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>This answer is very vague and does not answer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   How do I get help finding a job?   \n",
       "1                   How do I get help finding a job?   \n",
       "2                   How do I get help finding a job?   \n",
       "3  If I am in Australia on a worker holiday marke...   \n",
       "4  If I am in Australia on a worker holiday marke...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Coronavirus (COVID-19) information for job see...   \n",
       "1  Coronavirus (COVID-19) information for job see...   \n",
       "2  Coronavirus (COVID-19) information and support...   \n",
       "3  Frequently Asked Questions\\nWorking holiday ma...   \n",
       "4  Frequently Asked Questions\\nCOVID-19 Pandemic ...   \n",
       "\n",
       "                                            feedback  \\\n",
       "0  {'rating': ['Excellent', 'Could be Improved'],...   \n",
       "1  {'rating': ['Excellent', 'Excellent'], 'explan...   \n",
       "2  {'rating': ['Bad', 'Acceptable'], 'explanation...   \n",
       "3  {'rating': ['Could be Improved', 'Acceptable']...   \n",
       "4  {'rating': ['Bad', 'Could be Improved'], 'expl...   \n",
       "\n",
       "                                       list_feedback  \\\n",
       "0  [Excellent___Has a link to detailed informatio...   \n",
       "1  [Excellent___A link to a job search website is...   \n",
       "2  [Bad___Talks about tax credits for businesses ...   \n",
       "3  [Could be Improved___Answer is about Working H...   \n",
       "4  [Bad___Discusses pandemic visas. Doesn't menti...   \n",
       "\n",
       "                                    sampled_feedback  rating_score  \\\n",
       "0  [Excellent, Has a link to detailed information...             3   \n",
       "1  [Excellent, A link to a job search website is ...             3   \n",
       "2  [Acceptable, This answer discusses the Employm...             2   \n",
       "3  [Acceptable, Answer is rather cut and dry but ...             2   \n",
       "4  [Could be Improved, This answer is very vague ...             1   \n",
       "\n",
       "              rating                                        explanation  \n",
       "0          Excellent  Has a link to detailed information about gover...  \n",
       "1          Excellent  A link to a job search website is included, as...  \n",
       "2         Acceptable  This answer discusses the Employment Fund, whi...  \n",
       "3         Acceptable  Answer is rather cut and dry but is also a lit...  \n",
       "4  Could be Improved  This answer is very vague and does not answer ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9078f4a5-10f0-4d44-886e-53ae3826ea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coronavirus (COVID-19) information for job seekers\\nExisiting job seekers\\nIf you are a current job seeker or participant, this fact sheet provides\\nimportant information about mutual obligation requirements, appointments with\\nyour provider, and what to do if you are self-isolating:\\n\\nInformation for job seekers and participants\\n\\nIf you are participating in the ParentsNext program, this fact sheet provides\\nimportant information about your activities and appointments.\\n\\n\\nInformation for ParentsNext participants\\n\\n\\nParentsNext participants Frequently Asked Questions\\n\\n\\nIf you are a New Business Assistance with NEIS participant, these Frequently\\nAsked Questions (FAQ) provides information about accessing the Coronavirus\\nSupplement and what support is available during this time:\\n\\nNew Business Assistance with NEIS participants - Frequently Asked Questions\\n\\nIf you are a New Business Assistance with NEIS provider, these Frequently\\nAsked Questions (FAQ) provides information about supporting NEIS participants\\nduring the Coronavirus situation.\\n\\nNew Business Assistance with NEIS providers – Frequently Asked Questions\\n\\n*[NEIS]: New Enterprise Incentive Scheme'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['answer'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "619de540-d154-431a-8d5e-bab3bba6d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  7596,  1014,  2133,  2028,  2021,  2729,  1033,     2, 19614,\n",
       "          4139,  9545,  9545,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'length': tensor([14])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Hello, how are you doing?'+ f\" {tokenizer.eos_token} \" + \"Hemlooooo\",add_special_tokens=True,return_tensors='pt', return_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af181ac2-b1ae-4fcd-b59d-74b4defb3d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_tokenizer.sent_tokenize(train_df['answer'].loc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f22dd1b8-d28f-4d16-9acc-cd3dce4579cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21891, 23354, 1010, 2526, 17262, 1015, 2543, 1011, 2596, 2009, 3109, 24075, 4658, 17421, 3440, 3109, 24075, 2069, 2021, 2028, 1041, 2787, 3109, 29448, 2034, 13184, 1014, 2027, 2759, 7127, 3644, 2594, 2596, 2059, 8207, 14991, 5922, 1014, 14655, 2011, 2119, 10806, 1014, 2002, 2058, 2004, 2083, 2069, 2021, 2028, 2973, 1015, 11167, 22252, 1028, 2596, 2009, 3109, 24075, 2002, 6822, 2069, 2021, 2028, 8023, 2003, 2000, 3012, 2642, 18417, 2569, 1014, 2027, 2759, 7127, 3644, 2594, 2596, 2059, 2119, 3454, 2002, 14655, 1016], [2596, 2009, 3012, 2642, 18417, 6822, 3012, 2642, 18417, 6822, 4707, 2360, 3984, 2069, 2021, 2028, 1041, 2051, 2453, 5379, 2011, 11269, 2487, 13184, 1014, 2126, 4707, 2360, 3984, 1010, 6908, 4164, 1011, 3644, 2596, 2059, 3233, 2079, 2000, 21891, 23354, 12452, 2002, 2058, 2494, 2007, 2804, 2080, 2027, 2055, 1028, 2051, 2453, 5379, 2011, 11269, 2487, 6822, 1015, 4707, 2360, 3984, 2069, 2021, 2028, 1041, 2051, 2453, 5379, 2011, 11269, 2487, 10806, 1014, 2126, 4707, 2360, 3984, 1010, 6908, 4164, 1011, 3644, 2596, 2059, 4641, 11269, 2487, 6822, 2080, 2000, 21891, 23354, 3667, 1016], [2051, 2453, 5379, 2011, 11269, 2487, 11674, 1520, 4707, 2360, 3984, 1012, 1035, 11269, 2487, 1037, 1028, 2051, 6964, 20442, 5683]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_inp = tokenizer(nltk_tokenizer.sent_tokenize(train_df['answer'].loc[0]),add_special_tokens=False,return_token_type_ids=True)#,max_length=200,padding='max_length')\n",
    "tok_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05e6d281-2513-459b-a854-3f099d26309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7184f-4ca8-4d75-8dd4-5650f67a61a2",
   "metadata": {},
   "source": [
    "# NP Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3176cc13-e34e-4ebc-9a03-4ff4c9493e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import benepar, spacy\n",
    "benepar.download('benepar_en3')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "if spacy.__version__.startswith('2'):\n",
    "        nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1245c94f-093b-472d-9c80-d41b70e167be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coronavirus (COVID-19) information',\n",
       " 'FAQ',\n",
       " 'Information',\n",
       " 'NEIS participant',\n",
       " 'NEIS participants',\n",
       " 'NEIS provider',\n",
       " 'NEIS providers',\n",
       " 'New Business Assistance',\n",
       " 'New Enterprise Incentive Scheme',\n",
       " 'ParentsNext participants',\n",
       " 'Questions',\n",
       " 'a New Business Assistance',\n",
       " 'a current job seeker',\n",
       " 'appointments',\n",
       " 'important information',\n",
       " 'information',\n",
       " 'job seekers',\n",
       " 'mutual obligation requirements',\n",
       " 'participant',\n",
       " 'participants',\n",
       " 'the Coronavirus Supplement',\n",
       " 'the Coronavirus situation',\n",
       " 'the ParentsNext program',\n",
       " 'these Frequently Asked Questions',\n",
       " 'this fact sheet',\n",
       " 'this time',\n",
       " 'what',\n",
       " 'what support',\n",
       " 'you',\n",
       " 'your activities',\n",
       " 'your provider'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(train_df['answer'].loc[0].replace('\\n',' '))\n",
    "nps = []\n",
    "for np in doc.noun_chunks:\n",
    "    nps.append(np.text)\n",
    "\n",
    "set(nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a093a991-7536-4082-9bd2-7602825edfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "class feedback_QA_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,max_length=500):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.data = []\n",
    "        \n",
    "        for i in tqdm.tqdm(range(len(self.df)),desc='vectorizing..'):\n",
    "            \n",
    "            d = {}\n",
    "            \n",
    "            tok_question = tokenizer(self.df.iloc[i]['question'], add_special_tokens=False)\n",
    "            tok_answer = tokenizer(self.df.iloc[i]['answer'], add_special_tokens=False, max_length=self.max_len-len(tok_question['input_ids']), padding='max_length', truncation='only_first')\n",
    "            tok_feedback = tokenizer(self.df.iloc[i]['explanation'], add_special_tokens=False, max_length=self.max_len, padding='max_length', truncation='only_first')\n",
    "            \n",
    "            d['sentence'] = [tokenizer.bos_token_id] + tok_question['input_ids'] + [tokenizer.sep_token_id]*2 + tok_answer['input_ids']\n",
    "            d['sentence_attn'] = [1] + tok_question['attention_mask'] + [1,1] + tok_answer['attention_mask']\n",
    "            d['feedback'] = tok_feedback['input_ids']\n",
    "            d['feedback_attn'] = tok_feedback['attention_mask']\n",
    "            \n",
    "            d['sentence_pool_mask'] = [0] + [0]*len(tok_question['input_ids']) + [0,0] + tok_answer['attention_mask']\n",
    "            d['feedback_pool_mask'] = tok_feedback['attention_mask']\n",
    "            \n",
    "            answer_phrases = nltk_tokenizer.sent_tokenize(self.df.iloc[i]['answer'])\n",
    "            tok_phrases = tokenizer(answer_phrases,add_special_tokens=False,return_token_type_ids=True)\n",
    "            \n",
    "            d['answer_phrases_pool_mask'] = []\n",
    "            \n",
    "            for j in range(len(answer_phrases)):\n",
    "                answer_phrases_attn_mask = tok_phrases['token_type_ids'].copy()\n",
    "                answer_phrases_attn_mask[j] = tok_phrases['attention_mask'][j].copy()\n",
    "                answer_phrases_attn_mask = list(itertools.chain.from_iterable(answer_phrases_attn_mask))\n",
    "                pad_len = len(tok_answer['attention_mask']) - len(answer_phrases_attn_mask)\n",
    "                answer_phrases_attn_mask += [0]*pad_len\n",
    "                \n",
    "                answer_phrase_pool_mask = [0] + [0]*len(tok_question['input_ids']) + [0,0] + answer_phrases_attn_mask\n",
    "                \n",
    "                d['answer_phrases_pool_mask'].append(answer_phrase_pool_mask)\n",
    "            \n",
    "            if len(d['answer_phrases_pool_mask'][0])>len(d['sentence_pool_mask']):\n",
    "                continue\n",
    "                \n",
    "            self.data.append(d)\n",
    "\n",
    "    def add_neg_samples(self):\n",
    "        for i in tqdm.tqdm(range(self.__len__()),desc='adding neg samples...'):\n",
    "            self.data[i]['feedback_set'] = [self.data[i]['feedback']]\n",
    "            self.data[i]['feedback_attn_set'] = [self.data[i]['feedback_attn']]\n",
    "            self.data[i]['feedback_pool_mask_set'] = [self.data[i]['feedback_pool_mask']]\n",
    "            L = list(range(self.__len__()))\n",
    "            L.remove(i)\n",
    "            neg_samples_idx = np.random.choice(L,size=4)\n",
    "            for n_id in neg_samples_idx:\n",
    "                self.data[i]['feedback_set'].append(self.data[n_id]['feedback'])\n",
    "                self.data[i]['feedback_attn_set'].append(self.data[n_id]['feedback_attn'])\n",
    "                self.data[i]['feedback_pool_mask_set'].append(self.data[n_id]['feedback_pool_mask'])\n",
    "            for k in self.data[i].keys():\n",
    "                self.data[i][k] = torch.tensor(self.data[i][k])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c69c540d-1963-419c-8c09-08f5d65aa803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vectorizing..: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1995/1995 [00:07<00:00, 259.78it/s]\n",
      "adding neg samples...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1835/1835 [00:07<00:00, 235.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = feedback_QA_dataset(train_df)\n",
    "# train_dataset.add_neg_samples()\n",
    "# valid_dataset = feedback_QA_dataset(val_df)\n",
    "# valid_dataset.add_neg_samples()\n",
    "test_dataset = feedback_QA_dataset(test_df)\n",
    "test_dataset.add_neg_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92049336-0c27-4e1d-b5f7-9791745c5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_DL = DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
    "# valid_DL = DataLoader(valid_dataset,batch_size=1,shuffle=True)\n",
    "test_DL = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1da63016-24f0-400e-9a29-9093ab832bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence torch.Size([1, 503])\n",
      "sentence_attn torch.Size([1, 503])\n",
      "feedback torch.Size([1, 500])\n",
      "feedback_attn torch.Size([1, 500])\n",
      "sentence_pool_mask torch.Size([1, 503])\n",
      "feedback_pool_mask torch.Size([1, 500])\n",
      "answer_phrases_pool_mask torch.Size([1, 2, 503])\n",
      "feedback_set torch.Size([1, 5, 500])\n",
      "feedback_attn_set torch.Size([1, 5, 500])\n",
      "feedback_pool_mask_set torch.Size([1, 5, 500])\n"
     ]
    }
   ],
   "source": [
    "for b in test_DL:\n",
    "    for k in b.keys():\n",
    "        print(k,b[k].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31416162-1980-45a8-a672-a90fa84e8cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "model = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "# model.load_state_dict(torch.load('Detect_Span_FB_MPNET_chkpts_1/best_model_chkpt.pth.tar')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b9b7764-a417-46c3-aabd-e1e935079ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chkpt = torch.load('Detect_Span_FB_MPNET_chkpts_1/best_model_chkpt.pth.tar')\n",
    "from collections import OrderedDict\n",
    "model_state = OrderedDict([(k[6:],v) for k,v in chkpt['model_state'].items()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e23dbff6-4e92-4e4e-b00b-495431368712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3a73fde-3dbf-47ba-a20a-b849b3340efe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 503, 768]) torch.Size([1, 2, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([2, 768]) tensor([ 0.9780,  0.7319,  0.1223,  0.4054, -0.0970], device='cuda:1') tensor([ 0.9776,  0.7315,  0.1223,  0.4052, -0.0970], device='cuda:1')\n",
      "\n",
      "Input:  what are my options if i can not support myself on a whm visa? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa? you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you. \n",
      "\n",
      "Feedback:  this is off task, the answer is more about an expired visa \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa?\n",
      "Relevance of phrase 0 is -0.00047281384468078613 \n",
      "\n",
      "Phrase 1: you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you.\n",
      "Relevance of phrase 1 is 0.00036218762397766113 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 2, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([2, 768]) tensor([ 0.5416,  0.0491, -0.1569, -0.3828,  0.3020], device='cuda:1') tensor([ 0.5413,  0.0490, -0.1569, -0.3826,  0.3018], device='cuda:1')\n",
      "\n",
      "Input:  i was a working holiday maker but lost my job ; what should i do? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa? you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you. \n",
      "\n",
      "Feedback:  there is not a lot of information here. it doesn't say at all what to do if you lost your job. \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa?\n",
      "Relevance of phrase 0 is 0.0010895729064941406 \n",
      "\n",
      "Phrase 1: you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you.\n",
      "Relevance of phrase 1 is -0.0012090802192687988 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 6, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([6, 768]) tensor([ 0.7724,  0.3264,  0.5669, -0.1619,  0.3540], device='cuda:1') tensor([ 0.7703,  0.3285,  0.5689, -0.1606,  0.3540], device='cuda:1')\n",
      "\n",
      "Input:  is it practical to expect children to practice social distancing in childcare settings? physical distancing for coronavirus ( covid - 19 ) in schools if your child is sick, they must not go to school or childcare. you must keep them at home and away from others. to reduce the spread of viruses or germs in schools students and staff should continue to practise good hygiene. the australian health protection principal committee ( ahppc ) has issued updated advice on reducing the potential risk of covid - 19 transmission in schools. the ahppc also issued a statement on risk management for re - opening boarding schools and school - based residential colleges. for more information on school operations, visit the department of education, skills and employment website. \n",
      "\n",
      "Feedback:  this answer touches on children and the virus but doesn't really answer the question. there is nothing stating whether children should be expected to follow all the protocals. \n",
      "\n",
      "Phrase 0: physical distancing for coronavirus ( covid - 19 ) in schools if your child is sick, they must not go to school or childcare.\n",
      "Relevance of phrase 0 is 0.002256453037261963 \n",
      "\n",
      "Phrase 1: you must keep them at home and away from others.\n",
      "Relevance of phrase 1 is -0.006522268056869507 \n",
      "\n",
      "Phrase 2: to reduce the spread of viruses or germs in schools students and staff should continue to practise good hygiene.\n",
      "Relevance of phrase 2 is -0.0037783682346343994 \n",
      "\n",
      "Phrase 3: the australian health protection principal committee ( ahppc ) has issued updated advice on reducing the potential risk of covid - 19 transmission in schools.\n",
      "Relevance of phrase 3 is 0.0009734630584716797 \n",
      "\n",
      "Phrase 4: the ahppc also issued a statement on risk management for re - opening boarding schools and school - based residential colleges.\n",
      "Relevance of phrase 4 is 0.0013984143733978271 \n",
      "\n",
      "Phrase 5: for more information on school operations, visit the department of education, skills and employment website.\n",
      "Relevance of phrase 5 is 0.00140458345413208 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 4, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([4, 768]) tensor([ 0.9612, -0.1301, -0.0585,  0.2877,  0.5774], device='cuda:1') tensor([ 0.9603, -0.1305, -0.0582,  0.2900,  0.5773], device='cuda:1')\n",
      "\n",
      "Input:  do i have to continue making gym membership payments if my gym has closed due to the coronavirus outbreak? covid - 19 ( coronavirus ) information for consumers gym memberships can my gym charge me a membership ‘ freeze ’ or ‘ holding ’ fee for the period they are closed? membership ‘ freeze ’ or ‘ holding ’ fees may be charged by gyms when customers elect to pause their membership, if this is permitted by the terms and conditions. given many memberships are being paused due to the government restrictions preventing gyms from operating, rather than customers requesting a pause, the accc expects that gyms will not charge membership ‘ freeze ’ or ‘ holding ’ fees. the accc also expects that gyms will refund any such holding fees incorrectly charged since the government restrictions came into effect. \n",
      "\n",
      "Feedback:  this is a good answer. it gives examples of what a gym might do with fees if they are forced to close. \n",
      "\n",
      "Phrase 0: covid - 19 ( coronavirus ) information for consumers gym memberships can my gym charge me a membership ‘ freeze ’ or ‘ holding ’ fee for the period they are closed?\n",
      "Relevance of phrase 0 is 0.00025075674057006836 \n",
      "\n",
      "Phrase 1: membership ‘ freeze ’ or ‘ holding ’ fees may be charged by gyms when customers elect to pause their membership, if this is permitted by the terms and conditions.\n",
      "Relevance of phrase 1 is -7.852911949157715e-05 \n",
      "\n",
      "Phrase 2: given many memberships are being paused due to the government restrictions preventing gyms from operating, rather than customers requesting a pause, the accc expects that gyms will not charge membership ‘ freeze ’ or ‘ holding ’ fees.\n",
      "Relevance of phrase 2 is 0.0008198916912078857 \n",
      "\n",
      "Phrase 3: the accc also expects that gyms will refund any such holding fees incorrectly charged since the government restrictions came into effect.\n",
      "Relevance of phrase 3 is -0.0023232102394104004 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 15, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([15, 768]) tensor([ 0.9795,  0.4886, -0.3534,  0.7035, -0.0591], device='cuda:1') tensor([ 0.9798,  0.4876, -0.3531,  0.7030, -0.0591], device='cuda:1')\n",
      "\n",
      "Input:  can i keep on working while waiting to see if the application for my next whm visa is accepted or not? frequently asked questions temporary visa measures supporting the agriculture sector employers due to the covid - 19 border restrictions, seasonal workers and pacific labour scheme participants are unable to travel to australia at present. what other options are available to access workers to address labour needs? in response to the current covid - 19 pandemic, the australian government has announced temporary measures to assist temporary visa holders currently in australia, including seasonal worker programme and pacific labour scheme participants, who are unable to currently return to their home country, to extend their stay in australia, and enable flexibility in changing approved employers where required. under these temporary measures, current approved employers may wish to employ seasonal worker programme or pacific labour scheme participants who have finished employment with their current approved employer, but who are unable to return to their home country. approved employers, like any employer, may also wish to employ temporary activity ( subclass 408 ) australian government endorsed event ( agee ) stream visa holders this visa will have a nil visa application charge ( vac ) for the covid - 19 pandemic event. employer sponsorship arrangements similar to the seasonal worker programme will also apply to the subclass 408 visa. these temporary measures are not intended to prevent the recruitment of australians to undertake this work. before seeking access to seasonal workers under the seasonal worker programme, approved employers must first try to recruit australians. where australian workers are unavailable, employers can also seek seasonal labour through the working holiday maker program. working holiday makers who are working in critical sectors ( i. e. agriculture, food processing, health care, aged care, disability care or child care ) will be exempt from the six month work limitation with one employer and eligible for a temporary activity ( subclass 408 ) visa in the australian government endorsed event ( agee ) stream. employers are still required to abide by all relevant australian workplace laws. overseas workers have the same rights under australian workplace law as all other employees. these temporary measures will be in place for a timeframe that allows relevant critical industries to bridge the gap between their immediate needs and the time to recruit, train and on - board australians. the department of home affairs is working with the department of education, skills and employment to ensure australians are prioritised for future job opportunities. \n",
      "\n",
      "Feedback:  this does not answer the question. it does not provide any information on whether or not workers can keep on working while waiting for the approval for their whm visa. instead, this answer provides information for seasonal worker programme and pacific labour scheme participants, temporary activity agee stream visa holders and also recommendation for employers to seek seasonal labor through working holiday maker program. \n",
      "\n",
      "Phrase 0: frequently asked questions temporary visa measures supporting the agriculture sector employers due to the covid - 19 border restrictions, seasonal workers and pacific labour scheme participants are unable to travel to australia at present.\n",
      "Relevance of phrase 0 is 0.00011223554611206055 \n",
      "\n",
      "Phrase 1: what other options are available to access workers to address labour needs?\n",
      "Relevance of phrase 1 is 0.00011020898818969727 \n",
      "\n",
      "Phrase 2: in response to the current covid - 19 pandemic, the australian government has announced temporary measures to assist temporary visa holders currently in australia, including seasonal worker programme and pacific labour scheme participants, who are unable to currently return to their home country, to extend their stay in australia, and enable flexibility in changing approved employers where required.\n",
      "Relevance of phrase 2 is -0.00048795342445373535 \n",
      "\n",
      "Phrase 3: under these temporary measures, current approved employers may wish to employ seasonal worker programme or pacific labour scheme participants who have finished employment with their current approved employer, but who are unable to return to their home country.\n",
      "Relevance of phrase 3 is -2.5212764739990234e-05 \n",
      "\n",
      "Phrase 4: approved employers, like any employer, may also wish to employ temporary activity ( subclass 408 ) australian government endorsed event ( agee ) stream visa holders this visa will have a nil visa application charge ( vac ) for the covid - 19 pandemic event.\n",
      "Relevance of phrase 4 is -0.000440448522567749 \n",
      "\n",
      "Phrase 5: employer sponsorship arrangements similar to the seasonal worker programme will also apply to the subclass 408 visa.\n",
      "Relevance of phrase 5 is -0.0006549358367919922 \n",
      "\n",
      "Phrase 6: these temporary measures are not intended to prevent the recruitment of australians to undertake this work.\n",
      "Relevance of phrase 6 is -1.436471939086914e-05 \n",
      "\n",
      "Phrase 7: before seeking access to seasonal workers under the seasonal worker programme, approved employers must first try to recruit australians.\n",
      "Relevance of phrase 7 is -2.288818359375e-05 \n",
      "\n",
      "Phrase 8: where australian workers are unavailable, employers can also seek seasonal labour through the working holiday maker program.\n",
      "Relevance of phrase 8 is 0.0007713139057159424 \n",
      "\n",
      "Phrase 9: working holiday makers who are working in critical sectors ( i. e.\n",
      "Relevance of phrase 9 is 0.0015052258968353271 \n",
      "\n",
      "Phrase 10: agriculture, food processing, health care, aged care, disability care or child care ) will be exempt from the six month work limitation with one employer and eligible for a temporary activity ( subclass 408 ) visa in the australian government endorsed event ( agee ) stream.\n",
      "Relevance of phrase 10 is -0.0003286600112915039 \n",
      "\n",
      "Phrase 11: employers are still required to abide by all relevant australian workplace laws.\n",
      "Relevance of phrase 11 is 0.0001360476016998291 \n",
      "\n",
      "Phrase 12: overseas workers have the same rights under australian workplace law as all other employees.\n",
      "Relevance of phrase 12 is 0.0017251670360565186 \n",
      "\n",
      "Phrase 13: these temporary measures will be in place for a timeframe that allows relevant critical industries to bridge the gap between their immediate needs and the time to recruit, train and on - board australians.\n",
      "Relevance of phrase 13 is 0.0002085268497467041 \n",
      "\n",
      "Phrase 14: the department of home affairs is working with the department of education, skills and employment to ensure australians are prioritised for future job opportunities.\n",
      "Relevance of phrase 14 is -1.0699033737182617e-05 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 3, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([3, 768]) tensor([ 0.9935, -0.0473,  0.1043, -0.1254, -0.4454], device='cuda:1') tensor([ 0.9932, -0.0491,  0.1035, -0.1242, -0.4448], device='cuda:1')\n",
      "\n",
      "Input:  can i continue to work while i am waiting for a decision for my application for my whm visa? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am overseas. can i be granted a covid - 19 pandemic event visa? the covid - 19 pandemic event visa can only be granted to people in australia. \n",
      "\n",
      "Feedback:  this does not answer our question, this talks about, this talks about granting of visa and our question asked about working and waiting for whm visa \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am overseas.\n",
      "Relevance of phrase 0 is -0.0003190040588378906 \n",
      "\n",
      "Phrase 1: can i be granted a covid - 19 pandemic event visa?\n",
      "Relevance of phrase 1 is 0.0004601776599884033 \n",
      "\n",
      "Phrase 2: the covid - 19 pandemic event visa can only be granted to people in australia.\n",
      "Relevance of phrase 2 is -0.00010192394256591797 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 6, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([6, 768]) tensor([ 0.9277, -0.2802, -0.1675, -0.3038,  0.4180], device='cuda:1') tensor([ 0.9303, -0.2777, -0.1651, -0.3033,  0.4192], device='cuda:1')\n",
      "\n",
      "Input:  can i get a refund for the tickets i bought because i no longer want to attend an event for covid - 19 concerns? covid - 19 ( coronavirus ) information for consumers event cancellations i bought tickets for an event but no longer wish to attend due to concerns about covid - 19. am i entitled to a refund? if you no longer wish to attend an event due to concerns about covid - 19, this may be treated as a'change of mind '. you should contact the event organiser to see if you are entitled to a remedy such as full or partial refund, credit note or voucher. if you have a health condition that means you are at higher risk, you should contact the event organiser to see if they will offer you a refund or a voucher for a later date. given the exceptional circumstances, the accc encourages all businesses to treat consumers fairly, including by offering refunds as a goodwill gesture where appropriate. \n",
      "\n",
      "Feedback:  lets a person know that the refund is dependent upon the individual facility policies and to contact the facility for more information. \n",
      "\n",
      "Phrase 0: covid - 19 ( coronavirus ) information for consumers event cancellations i bought tickets for an event but no longer wish to attend due to concerns about covid - 19.\n",
      "Relevance of phrase 0 is -0.0014357268810272217 \n",
      "\n",
      "Phrase 1: am i entitled to a refund?\n",
      "Relevance of phrase 1 is 0.002916097640991211 \n",
      "\n",
      "Phrase 2: if you no longer wish to attend an event due to concerns about covid - 19, this may be treated as a'change of mind '.\n",
      "Relevance of phrase 2 is -0.0005946457386016846 \n",
      "\n",
      "Phrase 3: you should contact the event organiser to see if you are entitled to a remedy such as full or partial refund, credit note or voucher.\n",
      "Relevance of phrase 3 is 0.000996410846710205 \n",
      "\n",
      "Phrase 4: if you have a health condition that means you are at higher risk, you should contact the event organiser to see if they will offer you a refund or a voucher for a later date.\n",
      "Relevance of phrase 4 is -0.0010522007942199707 \n",
      "\n",
      "Phrase 5: given the exceptional circumstances, the accc encourages all businesses to treat consumers fairly, including by offering refunds as a goodwill gesture where appropriate.\n",
      "Relevance of phrase 5 is 0.0006584823131561279 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 4, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([4, 768]) tensor([ 0.9953, -0.4220,  0.0598, -0.2276, -0.2781], device='cuda:1') tensor([ 0.9949, -0.4218,  0.0589, -0.2273, -0.2778], device='cuda:1')\n",
      "\n",
      "Input:  where and how will the economic support payment be paid? coronavirus ( covid - 19 ) information and support frequently asked questions does the economic support payment go into my income management account? if you are in receipt of an eligible income support payment and you are an income management participant, the full $ 750 will be placed into your income management account. this is the same for other lump - sum payments. this will apply for both rounds of payments. \n",
      "\n",
      "Feedback:  this answer could give more information or resources for how the economic support payment will be paid. \n",
      "\n",
      "Phrase 0: coronavirus ( covid - 19 ) information and support frequently asked questions does the economic support payment go into my income management account?\n",
      "Relevance of phrase 0 is -0.000171661376953125 \n",
      "\n",
      "Phrase 1: if you are in receipt of an eligible income support payment and you are an income management participant, the full $ 750 will be placed into your income management account.\n",
      "Relevance of phrase 1 is -0.00022813677787780762 \n",
      "\n",
      "Phrase 2: this is the same for other lump - sum payments.\n",
      "Relevance of phrase 2 is 6.130337715148926e-05 \n",
      "\n",
      "Phrase 3: this will apply for both rounds of payments.\n",
      "Relevance of phrase 3 is 3.8117170333862305e-05 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 3, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([3, 768]) tensor([ 0.9257,  0.2714,  0.4466,  0.0131, -0.3511], device='cuda:1') tensor([ 0.9248,  0.2707,  0.4450,  0.0120, -0.3506], device='cuda:1')\n",
      "\n",
      "Input:  what ways can i apply for a temporal activity with a temporal visa frequently asked questions new zealand 444 special category visa ( scv ) what should i do if i am unable to support myself in australia and am not eligible for one of the above payments? under recently announced measures, new zealand citizens and permanent residents can access up to $ 10, 000 of their australian superannuation tax - free in 2019 - 20 and a further $ 10, 000 in 2020 - 21. if you are unable to support yourself, are not eligible for any of the above payments, and unable to find any employment, you should consider returning to new zealand. \n",
      "\n",
      "Feedback:  this discusses superannuation tax free and not temporal visa \n",
      "\n",
      "Phrase 0: frequently asked questions new zealand 444 special category visa ( scv ) what should i do if i am unable to support myself in australia and am not eligible for one of the above payments?\n",
      "Relevance of phrase 0 is 0.0003771781921386719 \n",
      "\n",
      "Phrase 1: under recently announced measures, new zealand citizens and permanent residents can access up to $ 10, 000 of their australian superannuation tax - free in 2019 - 20 and a further $ 10, 000 in 2020 - 21.\n",
      "Relevance of phrase 1 is -0.0008899569511413574 \n",
      "\n",
      "Phrase 2: if you are unable to support yourself, are not eligible for any of the above payments, and unable to find any employment, you should consider returning to new zealand.\n",
      "Relevance of phrase 2 is 0.0004737377166748047 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 4, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([4, 768]) tensor([ 0.9715, -0.3161, -0.0074, -0.2453, -0.0629], device='cuda:1') tensor([ 0.9708, -0.3153, -0.0076, -0.2446, -0.0624], device='cuda:1')\n",
      "\n",
      "Input:  if i am in australia on temporary visa and have been offered a job, can i apply for the australian government endorsed event stream visa? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am on a bridging visa. can i apply for the covid - 19 pandemic event visa? temporary visa holders, including bridging visa holders can apply for the covid - 19 pandemic event visa if they meet all of the eligibility criteria. bridging visa holders who have a s. 48 bar and / or who have not held a substantive temporary visa in the 28 days prior to application will not be able to apply. \n",
      "\n",
      "Feedback:  it talks about applying for visa but not for when it concerns a job \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am on a bridging visa.\n",
      "Relevance of phrase 0 is 0.0008067488670349121 \n",
      "\n",
      "Phrase 1: can i apply for the covid - 19 pandemic event visa?\n",
      "Relevance of phrase 1 is -0.0010388195514678955 \n",
      "\n",
      "Phrase 2: temporary visa holders, including bridging visa holders can apply for the covid - 19 pandemic event visa if they meet all of the eligibility criteria.\n",
      "Relevance of phrase 2 is -0.0004303157329559326 \n",
      "\n",
      "Phrase 3: bridging visa holders who have a s. 48 bar and / or who have not held a substantive temporary visa in the 28 days prior to application will not be able to apply.\n",
      "Relevance of phrase 3 is -0.0004431605339050293 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 9, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([9, 768]) tensor([ 0.9906, -0.3856, -0.5929,  0.2202, -0.4089], device='cuda:1') tensor([ 0.9903, -0.3854, -0.5927,  0.2200, -0.4084], device='cuda:1')\n",
      "\n",
      "Input:  can children who were full fee paying before still attend childcare? early childhood education and care covid - 19 frequently asked questions early childhood education and care relief package – information for providers and services how will the early childhood education and care relief package payments affect families on additional child care subsidy? the early childhood education and care relief package payments will be made instead of the usual child care subsidy ( ccs ) and additional child care subsidy ( accs ) payments. if the family ’ s current accs determination continues past the end of the early childhood education and care relief package payment period, they will return to their accs entitlement. this will be the case for most families receiving accs ( grandparent ). to ensure that accs ( child wellbeing ) continues to flow when the system returns to normal, if a family ’ s accs ( child wellbeing ) determination expires during the period, services will need to apply for a new determination. we encourage providers to submit determinations prior to the resumption of the regular system to avoid any gaps in accs ( child wellbeing ). if a family ’ s ccs cancels during the payment period they will need to reapply for ccs ( and be assessed as eligible ) for a service to receive accs ( child wellbeing ) payments when regular payments resume. if a family has submitted an application for accs ( temporary financial hardship ) their eligibility will be assessed and payment made up to 5 april 2020. if a person ’ s accs ( transition to work ) eligibility expires during the relief package period or the person requests to cease the accs ( transition to work ), they will need to apply for accs ( transition to work ) if they meet the eligibility criteria for the payment to recommence on 28 june 2020. \n",
      "\n",
      "Feedback:  this information does not answer the question. this information is about accs payments and the question is asking for information on whether or not children who paid full fee before the pandemic can still attend childcare during the pandemic. \n",
      "\n",
      "Phrase 0: early childhood education and care covid - 19 frequently asked questions early childhood education and care relief package – information for providers and services how will the early childhood education and care relief package payments affect families on additional child care subsidy?\n",
      "Relevance of phrase 0 is -0.001769334077835083 \n",
      "\n",
      "Phrase 1: the early childhood education and care relief package payments will be made instead of the usual child care subsidy ( ccs ) and additional child care subsidy ( accs ) payments.\n",
      "Relevance of phrase 1 is -0.0009092986583709717 \n",
      "\n",
      "Phrase 2: if the family ’ s current accs determination continues past the end of the early childhood education and care relief package payment period, they will return to their accs entitlement.\n",
      "Relevance of phrase 2 is 0.0003090500831604004 \n",
      "\n",
      "Phrase 3: this will be the case for most families receiving accs ( grandparent ).\n",
      "Relevance of phrase 3 is -1.4096498489379883e-05 \n",
      "\n",
      "Phrase 4: to ensure that accs ( child wellbeing ) continues to flow when the system returns to normal, if a family ’ s accs ( child wellbeing ) determination expires during the period, services will need to apply for a new determination.\n",
      "Relevance of phrase 4 is -8.07344913482666e-05 \n",
      "\n",
      "Phrase 5: we encourage providers to submit determinations prior to the resumption of the regular system to avoid any gaps in accs ( child wellbeing ).\n",
      "Relevance of phrase 5 is -0.0002721250057220459 \n",
      "\n",
      "Phrase 6: if a family ’ s ccs cancels during the payment period they will need to reapply for ccs ( and be assessed as eligible ) for a service to receive accs ( child wellbeing ) payments when regular payments resume.\n",
      "Relevance of phrase 6 is 0.0005067288875579834 \n",
      "\n",
      "Phrase 7: if a family has submitted an application for accs ( temporary financial hardship ) their eligibility will be assessed and payment made up to 5 april 2020.\n",
      "Relevance of phrase 7 is 0.0009675025939941406 \n",
      "\n",
      "Phrase 8: if a person ’ s accs ( transition to work ) eligibility expires during the relief package period or the person requests to cease the accs ( transition to work ), they will need to apply for accs ( transition to work ) if they meet the eligibility criteria for the payment to recommence on 28 june 2020.\n",
      "Relevance of phrase 8 is 0.00037854909896850586 \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return F.normalize(se, p=2, dim=1)\n",
    "\n",
    "j = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b in test_DL:\n",
    "        se = mean_pooling( model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device)), b['sentence_pool_mask'].to(device))\n",
    "        fe = mean_pooling(model(input_ids = b['feedback_set'][0].to(device),attention_mask=b['feedback_attn_set'][0].to(device)), b['feedback_pool_mask_set'][0].to(device))\n",
    "        pmo = model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device))\n",
    "        print(pmo[0].shape,b['answer_phrases_pool_mask'].shape)\n",
    "        pe = [mean_pooling(pmo,b['answer_phrases_pool_mask'][0][i].to(device) ) for i in range(b['answer_phrases_pool_mask'][0].shape[0])]\n",
    "        pe = torch.stack(pe).squeeze(1)\n",
    "        cos_sim = F.cosine_similarity(se,fe,dim=1)\n",
    "        cos_phrase_sim = torch.matmul(pe,fe.transpose(1,0))\n",
    "        print(fe.shape,se.shape,pe.shape,cos_sim,cos_phrase_sim.mean(0))\n",
    "        \n",
    "        sent_probs = F.softmax(cos_sim,dim=-1)\n",
    "        phrase_probs = F.softmax(cos_phrase_sim,dim=-1)\n",
    "        \n",
    "        print('\\nInput: ',tokenizer.decode(b['sentence'][0],skip_special_tokens=True),'\\n')\n",
    "        print('Feedback: ',tokenizer.decode(b['feedback'][0],skip_special_tokens=True),'\\n')\n",
    "        for i in range(b['answer_phrases_pool_mask'][0].shape[0]):\n",
    "            relevance = phrase_probs[i][0] - sent_probs[0]\n",
    "            \n",
    "            phrase_tok = torch.mul(b['sentence'][0],b['answer_phrases_pool_mask'][0][i])\n",
    "            print(f\"Phrase {i}:\",tokenizer.decode(phrase_tok,skip_special_tokens=True))\n",
    "            print(f\"Relevance of phrase {i} is {relevance}\",'\\n')\n",
    "        \n",
    "#         print('softmax: ',F.softmax(cos_sim),F.softmax(cos_phrase_sim,dim=-1))\n",
    "        \n",
    "#         tgt_tensor = torch.zeros(b['feedback_set'].shape[1] , device=device)\n",
    "#         tgt_tensor[0] = 1.0\n",
    "#         print('CE Loss: ', F.cross_entropy(cos_sim,target=tgt_tensor), F.cross_entropy(cos_phrase_sim.mean(0),target=torch.tensor([1.0,0,0,0,0]).to(device)))\n",
    "        print('----------------------------')\n",
    "        j+=1\n",
    "        if j>10:\n",
    "            break\n",
    "            \n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67dc5140-7f2c-4896-85bf-b464106da28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1835/1835 [02:14<00:00, 13.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return F.normalize(se, p=2, dim=1)\n",
    "\n",
    "j = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with open('test_preds.txt','w') as f:\n",
    "        for b in tqdm.tqdm(test_DL):\n",
    "            se = mean_pooling( model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device)), b['sentence_pool_mask'].to(device))\n",
    "            fe = mean_pooling(model(input_ids = b['feedback_set'][0].to(device),attention_mask=b['feedback_attn_set'][0].to(device)), b['feedback_pool_mask_set'][0].to(device))\n",
    "            pmo = model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device))\n",
    "            # f.write(pmo[0].shape,b['answer_phrases_pool_mask'].shape)\n",
    "            pe = [mean_pooling(pmo,b['answer_phrases_pool_mask'][0][i].to(device) ) for i in range(b['answer_phrases_pool_mask'][0].shape[0])]\n",
    "            pe = torch.stack(pe).squeeze(1)\n",
    "            cos_sim = F.cosine_similarity(se,fe,dim=1)\n",
    "            cos_phrase_sim = torch.matmul(pe,fe.transpose(1,0))\n",
    "            # f.write(fe.shape,se.shape,pe.shape,cos_sim,cos_phrase_sim.mean(0))\n",
    "\n",
    "            sent_probs = F.softmax(cos_sim,dim=-1)\n",
    "            phrase_probs = F.softmax(cos_phrase_sim,dim=-1)\n",
    "\n",
    "            f.write(f\"\\nInput: {tokenizer.decode(b['sentence'][0],skip_special_tokens=True)}\\n\\n\")\n",
    "            f.write(f\"Feedback: {tokenizer.decode(b['feedback'][0],skip_special_tokens=True)}\\n\\n\")\n",
    "            for i in range(b['answer_phrases_pool_mask'][0].shape[0]):\n",
    "                relevance = phrase_probs[i][0] - sent_probs[0]\n",
    "\n",
    "                phrase_tok = torch.mul(b['sentence'][0],b['answer_phrases_pool_mask'][0][i])\n",
    "                f.write(f\"Phrase {i}: {tokenizer.decode(phrase_tok,skip_special_tokens=True)}\")\n",
    "                f.write(f\"\\nRelevance of phrase {i} is {relevance}\\n\\n\")\n",
    "\n",
    "    #         print('softmax: ',F.softmax(cos_sim),F.softmax(cos_phrase_sim,dim=-1))\n",
    "\n",
    "    #         tgt_tensor = torch.zeros(b['feedback_set'].shape[1] , device=device)\n",
    "    #         tgt_tensor[0] = 1.0\n",
    "    #         print('CE Loss: ', F.cross_entropy(cos_sim,target=tgt_tensor), F.cross_entropy(cos_phrase_sim.mean(0),target=torch.tensor([1.0,0,0,0,0]).to(device)))\n",
    "            f.write('----------------------------')\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f3ed8bc-1d6e-47fa-bfbb-0f6b3b1d97b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4, 5],\n",
       "         [6, 7, 8, 9, 0]],\n",
       "\n",
       "        [[1, 2, 3, 4, 5],\n",
       "         [6, 7, 8, 9, 0]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[[1,2,3,4,5],[6,7,8,9,0]]])\n",
    "t.repeat(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "39373ab0-572f-42ec-8bee-d6945dd568bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self, model_chkpt, device='cuda:0'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_chkpt).to(device)\n",
    "        self.device = device\n",
    "        \n",
    "    def mean_pooling(self,model_output,attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return F.normalize(se, p=2, dim=1)\n",
    "        \n",
    "    def forward(self, b):\n",
    "        sent_model_out = self.model(input_ids = b['sentence'].to(self.device),attention_mask=b['sentence_attn'].to(self.device))\n",
    "        feedback_model_out = self.model(input_ids = b['feedback_set'][0].to(self.device),attention_mask=b['feedback_attn_set'][0].to(self.device))\n",
    "        \n",
    "        sent_emb = self.mean_pooling( sent_model_out, b['sentence_pool_mask'].to(self.device))\n",
    "        feedback_emb = self.mean_pooling( feedback_model_out, b['feedback_pool_mask_set'][0].to(self.device))\n",
    "        \n",
    "        # print(pmo[0].shape,b['answer_phrases_pool_mask'].shape)\n",
    "        phrase_emb = [ self.mean_pooling( sent_model_out, b['answer_phrases_pool_mask'][0][i].to(self.device) ) for i in range(b['answer_phrases_pool_mask'][0].shape[0])]\n",
    "        phrase_emb = torch.stack(phrase_emb).squeeze(1)\n",
    "        cos_sim = F.cosine_similarity(sent_emb,feedback_emb,dim=1)\n",
    "        cos_phrase_sim = torch.matmul(phrase_emb,feedback_emb.transpose(1,0))\n",
    "        \n",
    "        tgt_tensor = torch.zeros(b['feedback_set'].shape[1] , device=self.device)\n",
    "        tgt_tensor[0] = 1.0 #the relevant feedback is always present at index 0\n",
    "        \n",
    "        return_dict = {'sent_ce_loss': F.cross_entropy(cos_sim,target=tgt_tensor),\n",
    "                       'avg_phrase_ce_loss': F.cross_entropy(cos_phrase_sim.mean(0),target=tgt_tensor),\n",
    "                       'sent_probs': F.softmax(cos_sim),\n",
    "                       'phrase_probs': F.softmax(cos_phrase_sim,dim=-1)}\n",
    "        \n",
    "        return return_dict\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "97a1fcd9-7fb7-4557-a1ee-023591930420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminator,train_dl,valid_dl,epochs,batch_size,optimizer,PATIENCE=20,save_dir=None):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    discriminator.train()\n",
    "    \n",
    "    loss_acc = 0\n",
    "    num_batches = 0\n",
    "    total_steps = 0\n",
    "    best_valid_loss = np.inf\n",
    "    patience = PATIENCE\n",
    "    \n",
    "    train_loss_arr,valid_loss_arr = [],[]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    discriminator.zero_grad()\n",
    "    \n",
    "    for E in range(epochs):\n",
    "        \n",
    "        valid_loss = validate(discriminator,valid_dl)\n",
    "        valid_loss_arr.append(valid_loss/len(valid_dl))\n",
    "        \n",
    "        num_samples = 0\n",
    "        \n",
    "        for b in train_dl:\n",
    "            \n",
    "            y = discriminator(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['sent_ce_loss'] + y['avg_phrase_ce_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            \n",
    "            num_samples+=1\n",
    "            \n",
    "            loss.backward()\n",
    "            loss_acc += loss.item()\n",
    "            \n",
    "            if num_samples%batch_size==0:\n",
    "                optimizer.step()\n",
    "\n",
    "                num_batches += 1\n",
    "                total_steps += 1\n",
    "            \n",
    "                train_loss_arr.append(loss_acc/num_batches)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "                if total_steps%100==0 and total_steps!=0:\n",
    "                    print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "            \n",
    "        #print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "        \n",
    "        torch.save({'model_state':discriminator.state_dict(),\n",
    "                    'optimizer':optimizer.state_dict(),\n",
    "                    'epoch':E},\n",
    "                    f\"{save_dir}/Epoch_{E}_model_chkpt.pth.tar\")\n",
    "        \n",
    "        if valid_loss<best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            patience = PATIENCE\n",
    "            \n",
    "            torch.save({'model_state':discriminator.state_dict(),\n",
    "                        'optimizer':optimizer.state_dict(),\n",
    "                        'epoch':E},\n",
    "                        f\"{save_dir}/best_model_chkpt.pth.tar\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            print(f\"REDUCING PATIENCE...{patience}\")\n",
    "\n",
    "        if patience<=0:\n",
    "            print(\"RUNNING OUT OF PATIENCE... TERMINATING\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "    return train_loss_arr,valid_loss_arr\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b5e5931d-65fc-421d-8bf3-4bdb58b8b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(discriminator,valid_dl):\n",
    "    \n",
    "    discriminator.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for b in valid_dl:\n",
    "            y = discriminator(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['sent_ce_loss'] + y['avg_phrase_ce_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    print(\"Validation Loss:\",valid_loss)\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d1cb84b-dd2e-495f-845d-03ec726b7bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22424/1622610299.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# MPNet = AutoModel.from_pretrained(bert_chkpt).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdiscriminator_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_chkpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "# MPNet = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "discriminator_model = discriminator(bert_chkpt,device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(discriminator_model.parameters(),lr=1e-5)\n",
    "\n",
    "save_dir = 'Detect_Span_FB_MPNET_chkpts_1'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "train_loss,valid_loss = train(discriminator_model,\n",
    "                              train_DL,\n",
    "                              valid_DL,\n",
    "                              EPOCHS,\n",
    "                              BATCH_SIZE,\n",
    "                              optimizer,\n",
    "                              PATIENCE=5,\n",
    "                              save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91101fb6-ccc5-4b70-a781-f80306d79560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train_loss.json','w') as f:\n",
    "    json.dump(train_loss,f)\n",
    "\n",
    "with open('valid_loss.json','w') as f:\n",
    "    json.dump(valid_loss,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1438eb8-e8f1-41bd-ab9c-8c0ee15ab891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_ds = np.array(train_loss)[np.round(np.linspace(0, len(train_loss) - 1, len(valid_loss))).astype(int)]\n",
    "loss_df = pd.DataFrame({'train_loss':train_loss_ds , 'valid_loss':valid_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32161e3-1a96-4893-ac8a-5b567044334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import express as px\n",
    "px.line(loss_df,y=['train_loss','valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b9d00-0197-4bcc-be96-83e62d9c96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.load_state_dict(torch.load('GenFB_BART_chkpts_1/Epoch_0_model_chkpt.pth.tar')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3a035-e5a3-49e4-bbf4-6a0699945e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for b in train_DL:\n",
    "    out = discriminator.generate(inputs=b['input'][0:1,0].to(device),top_p=0.5)\n",
    "    print(tokenizer.decode(b['input'][0:1,0][0],skip_special_tokens=True))\n",
    "    print(tokenizer.decode(b['feedback'][0:1,0][0],skip_special_tokens=True))\n",
    "    print(tokenizer.decode(out[0]))\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    i+=1\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96357d85-64e1-4d7e-8eab-ee36d405bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
