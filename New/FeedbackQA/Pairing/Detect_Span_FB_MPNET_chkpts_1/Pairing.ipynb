{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ccce523c-f7e2-459c-89d3-775573e476e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset feedback_qa (/home/raja/.cache/huggingface/datasets/McGill-NLP___feedback_qa/plain_text/1.0.0/20c8f938f417c88303bb7041cea9554c1d14667686d7d7c5dda83dd4f39e5dc4)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017275333404541016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00eb1a4b02fb4ddfbfadba5e2b3b779f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "dataset = load_dataset(\"McGill-NLP/feedbackQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4626aded-95e1-47ec-bb47-59914940c8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_scores = {'Excellent':3 , 'Acceptable':2 , 'Could be Improved':1, 'Bad': -1}\n",
    "\n",
    "def process_df(df):\n",
    "    df['list_feedback'] = df['feedback'].apply(lambda x: [ r + \"___\" + e for r,e in zip(x['rating'],x['explanation']) ])\n",
    "    df['sampled_feedback'] = df['list_feedback'].apply(lambda x: np.random.choice(x).split(\"___\") )\n",
    "    df['rating_score'] = df['sampled_feedback'].apply(lambda x: rating_scores[x[0]])\n",
    "    df['rating'] = df['sampled_feedback'].apply(lambda x: x[0])\n",
    "    df['explanation'] = df['sampled_feedback'].apply(lambda x: x[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd2ffa3d-fae5-45d9-89c6-899dba3982fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = process_df(pd.DataFrame(dataset['train']))\n",
    "val_df = process_df(pd.DataFrame(dataset['validation']))\n",
    "test_df = process_df(pd.DataFrame(dataset['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40dc46db-a864-459a-8e7a-b82df484643b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "bert_chkpt = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_chkpt)\n",
    "model = AutoModel.from_pretrained(bert_chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d31c623b-2b7b-4b28-a499-b63ba8311ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '[UNK]', '<pad>', '<mask>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "744c4863-8096-4c67-b473-90e03a0df39c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>feedback</th>\n",
       "      <th>list_feedback</th>\n",
       "      <th>sampled_feedback</th>\n",
       "      <th>rating_score</th>\n",
       "      <th>rating</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Could be Improved'],...</td>\n",
       "      <td>[Excellent___Has a link to detailed informatio...</td>\n",
       "      <td>[Could be Improved, This answer provides a lin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>This answer provides a link for job searches, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Excellent'], 'explan...</td>\n",
       "      <td>[Excellent___A link to a job search website is...</td>\n",
       "      <td>[Excellent, A link to a job search website is ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A link to a job search website is included, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information and support...</td>\n",
       "      <td>{'rating': ['Bad', 'Acceptable'], 'explanation...</td>\n",
       "      <td>[Bad___Talks about tax credits for businesses ...</td>\n",
       "      <td>[Bad, Talks about tax credits for businesses t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Talks about tax credits for businesses that hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nWorking holiday ma...</td>\n",
       "      <td>{'rating': ['Could be Improved', 'Acceptable']...</td>\n",
       "      <td>[Could be Improved___Answer is about Working H...</td>\n",
       "      <td>[Could be Improved, Answer is about Working Ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>Answer is about Working Holiday Makers, but do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nCOVID-19 Pandemic ...</td>\n",
       "      <td>{'rating': ['Bad', 'Could be Improved'], 'expl...</td>\n",
       "      <td>[Bad___Discusses pandemic visas. Doesn't menti...</td>\n",
       "      <td>[Could be Improved, This answer is very vague ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>This answer is very vague and does not answer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   How do I get help finding a job?   \n",
       "1                   How do I get help finding a job?   \n",
       "2                   How do I get help finding a job?   \n",
       "3  If I am in Australia on a worker holiday marke...   \n",
       "4  If I am in Australia on a worker holiday marke...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Coronavirus (COVID-19) information for job see...   \n",
       "1  Coronavirus (COVID-19) information for job see...   \n",
       "2  Coronavirus (COVID-19) information and support...   \n",
       "3  Frequently Asked Questions\\nWorking holiday ma...   \n",
       "4  Frequently Asked Questions\\nCOVID-19 Pandemic ...   \n",
       "\n",
       "                                            feedback  \\\n",
       "0  {'rating': ['Excellent', 'Could be Improved'],...   \n",
       "1  {'rating': ['Excellent', 'Excellent'], 'explan...   \n",
       "2  {'rating': ['Bad', 'Acceptable'], 'explanation...   \n",
       "3  {'rating': ['Could be Improved', 'Acceptable']...   \n",
       "4  {'rating': ['Bad', 'Could be Improved'], 'expl...   \n",
       "\n",
       "                                       list_feedback  \\\n",
       "0  [Excellent___Has a link to detailed informatio...   \n",
       "1  [Excellent___A link to a job search website is...   \n",
       "2  [Bad___Talks about tax credits for businesses ...   \n",
       "3  [Could be Improved___Answer is about Working H...   \n",
       "4  [Bad___Discusses pandemic visas. Doesn't menti...   \n",
       "\n",
       "                                    sampled_feedback  rating_score  \\\n",
       "0  [Could be Improved, This answer provides a lin...             1   \n",
       "1  [Excellent, A link to a job search website is ...             3   \n",
       "2  [Bad, Talks about tax credits for businesses t...            -1   \n",
       "3  [Could be Improved, Answer is about Working Ho...             1   \n",
       "4  [Could be Improved, This answer is very vague ...             1   \n",
       "\n",
       "              rating                                        explanation  \n",
       "0  Could be Improved  This answer provides a link for job searches, ...  \n",
       "1          Excellent  A link to a job search website is included, as...  \n",
       "2                Bad  Talks about tax credits for businesses that hi...  \n",
       "3  Could be Improved  Answer is about Working Holiday Makers, but do...  \n",
       "4  Could be Improved  This answer is very vague and does not answer ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9078f4a5-10f0-4d44-886e-53ae3826ea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coronavirus (COVID-19) information for job seekers\\nExisiting job seekers\\nIf you are a current job seeker or participant, this fact sheet provides\\nimportant information about mutual obligation requirements, appointments with\\nyour provider, and what to do if you are self-isolating:\\n\\nInformation for job seekers and participants\\n\\nIf you are participating in the ParentsNext program, this fact sheet provides\\nimportant information about your activities and appointments.\\n\\n\\nInformation for ParentsNext participants\\n\\n\\nParentsNext participants Frequently Asked Questions\\n\\n\\nIf you are a New Business Assistance with NEIS participant, these Frequently\\nAsked Questions (FAQ) provides information about accessing the Coronavirus\\nSupplement and what support is available during this time:\\n\\nNew Business Assistance with NEIS participants - Frequently Asked Questions\\n\\nIf you are a New Business Assistance with NEIS provider, these Frequently\\nAsked Questions (FAQ) provides information about supporting NEIS participants\\nduring the Coronavirus situation.\\n\\nNew Business Assistance with NEIS providers – Frequently Asked Questions\\n\\n*[NEIS]: New Enterprise Incentive Scheme'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['answer'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "619de540-d154-431a-8d5e-bab3bba6d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  7596,  1014,  2133,  2028,  2021,  2729,  1033,     2, 19614,\n",
       "          4139,  9545,  9545,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'length': tensor([14])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Hello, how are you doing?'+ f\" {tokenizer.eos_token} \" + \"Hemlooooo\",add_special_tokens=True,return_tensors='pt', return_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af181ac2-b1ae-4fcd-b59d-74b4defb3d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize as nltk_tokenizer\n",
    "len(nltk_tokenizer.sent_tokenize(train_df['answer'].loc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f22dd1b8-d28f-4d16-9acc-cd3dce4579cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21891, 23354, 1010, 2526, 17262, 1015, 2543, 1011, 2596, 2009, 3109, 24075, 4658, 17421, 3440, 3109, 24075, 2069, 2021, 2028, 1041, 2787, 3109, 29448, 2034, 13184, 1014, 2027, 2759, 7127, 3644, 2594, 2596, 2059, 8207, 14991, 5922, 1014, 14655, 2011, 2119, 10806, 1014, 2002, 2058, 2004, 2083, 2069, 2021, 2028, 2973, 1015, 11167, 22252, 1028, 2596, 2009, 3109, 24075, 2002, 6822, 2069, 2021, 2028, 8023, 2003, 2000, 3012, 2642, 18417, 2569, 1014, 2027, 2759, 7127, 3644, 2594, 2596, 2059, 2119, 3454, 2002, 14655, 1016], [2596, 2009, 3012, 2642, 18417, 6822, 3012, 2642, 18417, 6822, 4707, 2360, 3984, 2069, 2021, 2028, 1041, 2051, 2453, 5379, 2011, 11269, 2487, 13184, 1014, 2126, 4707, 2360, 3984, 1010, 6908, 4164, 1011, 3644, 2596, 2059, 3233, 2079, 2000, 21891, 23354, 12452, 2002, 2058, 2494, 2007, 2804, 2080, 2027, 2055, 1028, 2051, 2453, 5379, 2011, 11269, 2487, 6822, 1015, 4707, 2360, 3984, 2069, 2021, 2028, 1041, 2051, 2453, 5379, 2011, 11269, 2487, 10806, 1014, 2126, 4707, 2360, 3984, 1010, 6908, 4164, 1011, 3644, 2596, 2059, 4641, 11269, 2487, 6822, 2080, 2000, 21891, 23354, 3667, 1016], [2051, 2453, 5379, 2011, 11269, 2487, 11674, 1520, 4707, 2360, 3984, 1012, 1035, 11269, 2487, 1037, 1028, 2051, 6964, 20442, 5683]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_inp = tokenizer(nltk_tokenizer.sent_tokenize(train_df['answer'].loc[0]),add_special_tokens=False,return_token_type_ids=True)#,max_length=200,padding='max_length')\n",
    "tok_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05e6d281-2513-459b-a854-3f099d26309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7184f-4ca8-4d75-8dd4-5650f67a61a2",
   "metadata": {},
   "source": [
    "# NP Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3176cc13-e34e-4ebc-9a03-4ff4c9493e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import benepar, spacy\n",
    "benepar.download('benepar_en3')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "if spacy.__version__.startswith('2'):\n",
    "        nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1245c94f-093b-472d-9c80-d41b70e167be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coronavirus (COVID-19) information',\n",
       " 'FAQ',\n",
       " 'Information',\n",
       " 'NEIS participant',\n",
       " 'NEIS participants',\n",
       " 'NEIS provider',\n",
       " 'NEIS providers',\n",
       " 'New Business Assistance',\n",
       " 'New Enterprise Incentive Scheme',\n",
       " 'ParentsNext participants',\n",
       " 'Questions',\n",
       " 'a New Business Assistance',\n",
       " 'a current job seeker',\n",
       " 'appointments',\n",
       " 'important information',\n",
       " 'information',\n",
       " 'job seekers',\n",
       " 'mutual obligation requirements',\n",
       " 'participant',\n",
       " 'participants',\n",
       " 'the Coronavirus Supplement',\n",
       " 'the Coronavirus situation',\n",
       " 'the ParentsNext program',\n",
       " 'these Frequently Asked Questions',\n",
       " 'this fact sheet',\n",
       " 'this time',\n",
       " 'what',\n",
       " 'what support',\n",
       " 'you',\n",
       " 'your activities',\n",
       " 'your provider'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(train_df['answer'].loc[0].replace('\\n',' '))\n",
    "nps = []\n",
    "for np in doc.noun_chunks:\n",
    "    nps.append(np.text)\n",
    "\n",
    "set(nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a093a991-7536-4082-9bd2-7602825edfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "class feedback_QA_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,max_length=500):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.data = []\n",
    "        \n",
    "        for i in tqdm.tqdm(range(len(self.df)),desc='vectorizing..'):\n",
    "            \n",
    "            d = {}\n",
    "            \n",
    "            tok_question = tokenizer(self.df.iloc[i]['question'], add_special_tokens=False)\n",
    "            tok_answer = tokenizer(self.df.iloc[i]['answer'], add_special_tokens=False, max_length=self.max_len-len(tok_question['input_ids']), padding='max_length', truncation='only_first')\n",
    "            tok_feedback = tokenizer(self.df.iloc[i]['explanation'], add_special_tokens=False, max_length=self.max_len, padding='max_length', truncation='only_first')\n",
    "            \n",
    "            d['sentence'] = [tokenizer.bos_token_id] + tok_question['input_ids'] + [tokenizer.sep_token_id]*2 + tok_answer['input_ids']\n",
    "            d['sentence_attn'] = [1] + tok_question['attention_mask'] + [1,1] + tok_answer['attention_mask']\n",
    "            d['feedback'] = tok_feedback['input_ids']\n",
    "            d['feedback_attn'] = tok_feedback['attention_mask']\n",
    "            \n",
    "            d['sentence_pool_mask'] = [0] + [0]*len(tok_question['input_ids']) + [0,0] + tok_answer['attention_mask']\n",
    "            d['feedback_pool_mask'] = tok_feedback['attention_mask']\n",
    "            \n",
    "            answer_phrases = nltk_tokenizer.sent_tokenize(self.df.iloc[i]['answer'])\n",
    "            tok_phrases = tokenizer(answer_phrases,add_special_tokens=False,return_token_type_ids=True)\n",
    "            \n",
    "            d['answer_phrases_pool_mask'] = []\n",
    "            \n",
    "            for j in range(len(answer_phrases)):\n",
    "                answer_phrases_attn_mask = tok_phrases['token_type_ids'].copy()\n",
    "                answer_phrases_attn_mask[j] = tok_phrases['attention_mask'][j].copy()\n",
    "                answer_phrases_attn_mask = list(itertools.chain.from_iterable(answer_phrases_attn_mask))\n",
    "                pad_len = len(tok_answer['attention_mask']) - len(answer_phrases_attn_mask)\n",
    "                answer_phrases_attn_mask += [0]*pad_len\n",
    "                \n",
    "                answer_phrase_pool_mask = [0] + [0]*len(tok_question['input_ids']) + [0,0] + answer_phrases_attn_mask\n",
    "                \n",
    "                d['answer_phrases_pool_mask'].append(answer_phrase_pool_mask)\n",
    "            \n",
    "            if len(d['answer_phrases_pool_mask'][0])>len(d['sentence_pool_mask']):\n",
    "                continue\n",
    "                \n",
    "            self.data.append(d)\n",
    "\n",
    "    def add_neg_samples(self):\n",
    "        for i in tqdm.tqdm(range(self.__len__()),desc='adding neg samples...'):\n",
    "            self.data[i]['feedback_set'] = [self.data[i]['feedback']]\n",
    "            self.data[i]['feedback_attn_set'] = [self.data[i]['feedback_attn']]\n",
    "            self.data[i]['feedback_pool_mask_set'] = [self.data[i]['feedback_pool_mask']]\n",
    "            L = list(range(self.__len__()))\n",
    "            L.remove(i)\n",
    "            neg_samples_idx = np.random.choice(L,size=4)\n",
    "            for n_id in neg_samples_idx:\n",
    "                self.data[i]['feedback_set'].append(self.data[n_id]['feedback'])\n",
    "                self.data[i]['feedback_attn_set'].append(self.data[n_id]['feedback_attn'])\n",
    "                self.data[i]['feedback_pool_mask_set'].append(self.data[n_id]['feedback_pool_mask'])\n",
    "            for k in self.data[i].keys():\n",
    "                self.data[i][k] = torch.tensor(self.data[i][k])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c69c540d-1963-419c-8c09-08f5d65aa803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vectorizing..: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5660/5660 [00:18<00:00, 299.12it/s]\n",
      "adding neg samples...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 5279/5279 [00:22<00:00, 230.19it/s]\n",
      "vectorizing..: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1410/1410 [00:04<00:00, 290.53it/s]\n",
      "adding neg samples...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1316/1316 [00:05<00:00, 252.15it/s]\n",
      "vectorizing..: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1995/1995 [00:07<00:00, 260.13it/s]\n",
      "adding neg samples...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1835/1835 [00:07<00:00, 245.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = feedback_QA_dataset(train_df)\n",
    "train_dataset.add_neg_samples()\n",
    "valid_dataset = feedback_QA_dataset(val_df)\n",
    "valid_dataset.add_neg_samples()\n",
    "test_dataset = feedback_QA_dataset(test_df)\n",
    "test_dataset.add_neg_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "92049336-0c27-4e1d-b5f7-9791745c5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DL = DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
    "valid_DL = DataLoader(valid_dataset,batch_size=1,shuffle=True)\n",
    "test_DL = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1da63016-24f0-400e-9a29-9093ab832bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence torch.Size([1, 503])\n",
      "sentence_attn torch.Size([1, 503])\n",
      "feedback torch.Size([1, 500])\n",
      "feedback_attn torch.Size([1, 500])\n",
      "sentence_pool_mask torch.Size([1, 503])\n",
      "feedback_pool_mask torch.Size([1, 500])\n",
      "answer_phrases_pool_mask torch.Size([1, 3, 503])\n",
      "feedback_set torch.Size([1, 5, 500])\n",
      "feedback_attn_set torch.Size([1, 5, 500])\n",
      "feedback_pool_mask_set torch.Size([1, 5, 500])\n"
     ]
    }
   ],
   "source": [
    "for b in train_DL:\n",
    "    for k in b.keys():\n",
    "        print(k,b[k].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "524eef71-2aad-4803-892f-01b0a6fa82de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 503, 768]) torch.Size([1, 2, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([2, 768]) tensor([0.1847, 0.1714, 0.1046, 0.1936, 0.2543], device='cuda:0') tensor([0.1812, 0.1683, 0.1025, 0.1908, 0.2488], device='cuda:0')\n",
      "\n",
      "Input:  what are my options if i can not support myself on a whm visa? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa? you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you. \n",
      "\n",
      "Feedback:  this only talks about visa application, it fails to talk about the topic \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa?\n",
      "Relevance of phrase 0 is -3.585219383239746e-05 \n",
      "\n",
      "Phrase 1: you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you.\n",
      "Relevance of phrase 1 is -5.0827860832214355e-05 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 2, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([2, 768]) tensor([ 0.3963,  0.2174,  0.1381, -0.0235,  0.2542], device='cuda:0') tensor([ 0.3851,  0.2116,  0.1346, -0.0224,  0.2482], device='cuda:0')\n",
      "\n",
      "Input:  i was a working holiday maker but lost my job ; what should i do? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa? you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you. \n",
      "\n",
      "Feedback:  there is not a lot of information here. it doesn't say at all what to do if you lost your job. \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa?\n",
      "Relevance of phrase 0 is -0.008139640092849731 \n",
      "\n",
      "Phrase 1: you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you.\n",
      "Relevance of phrase 1 is 0.005527481436729431 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 6, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([6, 768]) tensor([ 0.4718,  0.0158,  0.2379, -0.0204,  0.1407], device='cuda:0') tensor([ 0.4584,  0.0154,  0.2293, -0.0200,  0.1383], device='cuda:0')\n",
      "\n",
      "Input:  is it practical to expect children to practice social distancing in childcare settings? physical distancing for coronavirus ( covid - 19 ) in schools if your child is sick, they must not go to school or childcare. you must keep them at home and away from others. to reduce the spread of viruses or germs in schools students and staff should continue to practise good hygiene. the australian health protection principal committee ( ahppc ) has issued updated advice on reducing the potential risk of covid - 19 transmission in schools. the ahppc also issued a statement on risk management for re - opening boarding schools and school - based residential colleges. for more information on school operations, visit the department of education, skills and employment website. \n",
      "\n",
      "Feedback:  it didn't talk about how practical it is to expect children to practice social distancing. \n",
      "\n",
      "Phrase 0: physical distancing for coronavirus ( covid - 19 ) in schools if your child is sick, they must not go to school or childcare.\n",
      "Relevance of phrase 0 is 0.006138890981674194 \n",
      "\n",
      "Phrase 1: you must keep them at home and away from others.\n",
      "Relevance of phrase 1 is 0.006233900785446167 \n",
      "\n",
      "Phrase 2: to reduce the spread of viruses or germs in schools students and staff should continue to practise good hygiene.\n",
      "Relevance of phrase 2 is -0.007832139730453491 \n",
      "\n",
      "Phrase 3: the australian health protection principal committee ( ahppc ) has issued updated advice on reducing the potential risk of covid - 19 transmission in schools.\n",
      "Relevance of phrase 3 is -0.007587403059005737 \n",
      "\n",
      "Phrase 4: the ahppc also issued a statement on risk management for re - opening boarding schools and school - based residential colleges.\n",
      "Relevance of phrase 4 is -0.005729973316192627 \n",
      "\n",
      "Phrase 5: for more information on school operations, visit the department of education, skills and employment website.\n",
      "Relevance of phrase 5 is -0.0033657848834991455 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 4, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([4, 768]) tensor([6.1255e-01, 1.8905e-01, 2.1566e-01, 6.4469e-02, 1.3964e-04],\n",
      "       device='cuda:0') tensor([0.6037, 0.1919, 0.2131, 0.0653, 0.0009], device='cuda:0')\n",
      "\n",
      "Input:  do i have to continue making gym membership payments if my gym has closed due to the coronavirus outbreak? covid - 19 ( coronavirus ) information for consumers gym memberships can my gym charge me a membership ‘ freeze ’ or ‘ holding ’ fee for the period they are closed? membership ‘ freeze ’ or ‘ holding ’ fees may be charged by gyms when customers elect to pause their membership, if this is permitted by the terms and conditions. given many memberships are being paused due to the government restrictions preventing gyms from operating, rather than customers requesting a pause, the accc expects that gyms will not charge membership ‘ freeze ’ or ‘ holding ’ fees. the accc also expects that gyms will refund any such holding fees incorrectly charged since the government restrictions came into effect. \n",
      "\n",
      "Feedback:  this is a good answer. it gives examples of what a gym might do with fees if they are forced to close. \n",
      "\n",
      "Phrase 0: covid - 19 ( coronavirus ) information for consumers gym memberships can my gym charge me a membership ‘ freeze ’ or ‘ holding ’ fee for the period they are closed?\n",
      "Relevance of phrase 0 is 0.001047760248184204 \n",
      "\n",
      "Phrase 1: membership ‘ freeze ’ or ‘ holding ’ fees may be charged by gyms when customers elect to pause their membership, if this is permitted by the terms and conditions.\n",
      "Relevance of phrase 1 is 0.000505596399307251 \n",
      "\n",
      "Phrase 2: given many memberships are being paused due to the government restrictions preventing gyms from operating, rather than customers requesting a pause, the accc expects that gyms will not charge membership ‘ freeze ’ or ‘ holding ’ fees.\n",
      "Relevance of phrase 2 is -0.0009500980377197266 \n",
      "\n",
      "Phrase 3: the accc also expects that gyms will refund any such holding fees incorrectly charged since the government restrictions came into effect.\n",
      "Relevance of phrase 3 is -0.00820833444595337 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 15, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([15, 768]) tensor([0.7977, 0.0632, 0.1302, 0.1488, 0.0589], device='cuda:0') tensor([0.7785, 0.0608, 0.1231, 0.1487, 0.0505], device='cuda:0')\n",
      "\n",
      "Input:  can i keep on working while waiting to see if the application for my next whm visa is accepted or not? frequently asked questions temporary visa measures supporting the agriculture sector employers due to the covid - 19 border restrictions, seasonal workers and pacific labour scheme participants are unable to travel to australia at present. what other options are available to access workers to address labour needs? in response to the current covid - 19 pandemic, the australian government has announced temporary measures to assist temporary visa holders currently in australia, including seasonal worker programme and pacific labour scheme participants, who are unable to currently return to their home country, to extend their stay in australia, and enable flexibility in changing approved employers where required. under these temporary measures, current approved employers may wish to employ seasonal worker programme or pacific labour scheme participants who have finished employment with their current approved employer, but who are unable to return to their home country. approved employers, like any employer, may also wish to employ temporary activity ( subclass 408 ) australian government endorsed event ( agee ) stream visa holders this visa will have a nil visa application charge ( vac ) for the covid - 19 pandemic event. employer sponsorship arrangements similar to the seasonal worker programme will also apply to the subclass 408 visa. these temporary measures are not intended to prevent the recruitment of australians to undertake this work. before seeking access to seasonal workers under the seasonal worker programme, approved employers must first try to recruit australians. where australian workers are unavailable, employers can also seek seasonal labour through the working holiday maker program. working holiday makers who are working in critical sectors ( i. e. agriculture, food processing, health care, aged care, disability care or child care ) will be exempt from the six month work limitation with one employer and eligible for a temporary activity ( subclass 408 ) visa in the australian government endorsed event ( agee ) stream. employers are still required to abide by all relevant australian workplace laws. overseas workers have the same rights under australian workplace law as all other employees. these temporary measures will be in place for a timeframe that allows relevant critical industries to bridge the gap between their immediate needs and the time to recruit, train and on - board australians. the department of home affairs is working with the department of education, skills and employment to ensure australians are prioritised for future job opportunities. \n",
      "\n",
      "Feedback:  this does not answer the question. it does not provide any information on whether or not workers can keep on working while waiting for the approval for their whm visa. instead, this answer provides information for seasonal worker programme and pacific labour scheme participants, temporary activity agee stream visa holders and also recommendation for employers to seek seasonal labor through working holiday maker program. \n",
      "\n",
      "Phrase 0: frequently asked questions temporary visa measures supporting the agriculture sector employers due to the covid - 19 border restrictions, seasonal workers and pacific labour scheme participants are unable to travel to australia at present.\n",
      "Relevance of phrase 0 is -0.005220949649810791 \n",
      "\n",
      "Phrase 1: what other options are available to access workers to address labour needs?\n",
      "Relevance of phrase 1 is 0.0005821883678436279 \n",
      "\n",
      "Phrase 2: in response to the current covid - 19 pandemic, the australian government has announced temporary measures to assist temporary visa holders currently in australia, including seasonal worker programme and pacific labour scheme participants, who are unable to currently return to their home country, to extend their stay in australia, and enable flexibility in changing approved employers where required.\n",
      "Relevance of phrase 2 is -0.007068425416946411 \n",
      "\n",
      "Phrase 3: under these temporary measures, current approved employers may wish to employ seasonal worker programme or pacific labour scheme participants who have finished employment with their current approved employer, but who are unable to return to their home country.\n",
      "Relevance of phrase 3 is 0.0010851025581359863 \n",
      "\n",
      "Phrase 4: approved employers, like any employer, may also wish to employ temporary activity ( subclass 408 ) australian government endorsed event ( agee ) stream visa holders this visa will have a nil visa application charge ( vac ) for the covid - 19 pandemic event.\n",
      "Relevance of phrase 4 is -0.006114304065704346 \n",
      "\n",
      "Phrase 5: employer sponsorship arrangements similar to the seasonal worker programme will also apply to the subclass 408 visa.\n",
      "Relevance of phrase 5 is -0.0024841129779815674 \n",
      "\n",
      "Phrase 6: these temporary measures are not intended to prevent the recruitment of australians to undertake this work.\n",
      "Relevance of phrase 6 is -0.003878474235534668 \n",
      "\n",
      "Phrase 7: before seeking access to seasonal workers under the seasonal worker programme, approved employers must first try to recruit australians.\n",
      "Relevance of phrase 7 is 0.0025942623615264893 \n",
      "\n",
      "Phrase 8: where australian workers are unavailable, employers can also seek seasonal labour through the working holiday maker program.\n",
      "Relevance of phrase 8 is 0.0057759881019592285 \n",
      "\n",
      "Phrase 9: working holiday makers who are working in critical sectors ( i. e.\n",
      "Relevance of phrase 9 is -0.00182303786277771 \n",
      "\n",
      "Phrase 10: agriculture, food processing, health care, aged care, disability care or child care ) will be exempt from the six month work limitation with one employer and eligible for a temporary activity ( subclass 408 ) visa in the australian government endorsed event ( agee ) stream.\n",
      "Relevance of phrase 10 is -0.0032051503658294678 \n",
      "\n",
      "Phrase 11: employers are still required to abide by all relevant australian workplace laws.\n",
      "Relevance of phrase 11 is -0.009967178106307983 \n",
      "\n",
      "Phrase 12: overseas workers have the same rights under australian workplace law as all other employees.\n",
      "Relevance of phrase 12 is -0.007970213890075684 \n",
      "\n",
      "Phrase 13: these temporary measures will be in place for a timeframe that allows relevant critical industries to bridge the gap between their immediate needs and the time to recruit, train and on - board australians.\n",
      "Relevance of phrase 13 is -0.003447622060775757 \n",
      "\n",
      "Phrase 14: the department of home affairs is working with the department of education, skills and employment to ensure australians are prioritised for future job opportunities.\n",
      "Relevance of phrase 14 is -0.007946610450744629 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 3, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([3, 768]) tensor([0.0184, 0.1597, 0.2454, 0.2845, 0.0405], device='cuda:0') tensor([0.0099, 0.1593, 0.2246, 0.2651, 0.0387], device='cuda:0')\n",
      "\n",
      "Input:  can i continue to work while i am waiting for a decision for my application for my whm visa? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am overseas. can i be granted a covid - 19 pandemic event visa? the covid - 19 pandemic event visa can only be granted to people in australia. \n",
      "\n",
      "Feedback:  this does not answer the question and is off topic \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am overseas.\n",
      "Relevance of phrase 0 is 0.001007080078125 \n",
      "\n",
      "Phrase 1: can i be granted a covid - 19 pandemic event visa?\n",
      "Relevance of phrase 1 is 0.0007690191268920898 \n",
      "\n",
      "Phrase 2: the covid - 19 pandemic event visa can only be granted to people in australia.\n",
      "Relevance of phrase 2 is -0.0006523579359054565 \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return F.normalize(se, p=2, dim=1)\n",
    "\n",
    "j = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b in test_DL:\n",
    "        se = mean_pooling( model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device)), b['sentence_pool_mask'].to(device))\n",
    "        fe = mean_pooling(model(input_ids = b['feedback_set'][0].to(device),attention_mask=b['feedback_attn_set'][0].to(device)), b['feedback_pool_mask_set'][0].to(device))\n",
    "        pmo = model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device))\n",
    "        print(pmo[0].shape,b['answer_phrases_pool_mask'].shape)\n",
    "        pe = [mean_pooling(pmo,b['answer_phrases_pool_mask'][0][i].to(device) ) for i in range(b['answer_phrases_pool_mask'][0].shape[0])]\n",
    "        pe = torch.stack(pe).squeeze(1)\n",
    "        cos_sim = F.cosine_similarity(se,fe,dim=1)\n",
    "        cos_phrase_sim = torch.matmul(pe,fe.transpose(1,0))\n",
    "        print(fe.shape,se.shape,pe.shape,cos_sim,cos_phrase_sim.mean(0))\n",
    "        \n",
    "        sent_probs = F.softmax(cos_sim,dim=-1)\n",
    "        phrase_probs = F.softmax(cos_phrase_sim,dim=-1)\n",
    "        \n",
    "        print('\\nInput: ',tokenizer.decode(b['sentence'][0],skip_special_tokens=True),'\\n')\n",
    "        print('Feedback: ',tokenizer.decode(b['feedback'][0],skip_special_tokens=True),'\\n')\n",
    "        for i in range(b['answer_phrases_pool_mask'][0].shape[0]):\n",
    "            relevance = phrase_probs[i][0] - sent_probs[0]\n",
    "            \n",
    "            phrase_tok = torch.mul(b['sentence'][0],b['answer_phrases_pool_mask'][0][i])\n",
    "            print(f\"Phrase {i}:\",tokenizer.decode(phrase_tok,skip_special_tokens=True))\n",
    "            print(f\"Relevance of phrase {i} is {relevance}\",'\\n')\n",
    "        \n",
    "#         print('softmax: ',F.softmax(cos_sim),F.softmax(cos_phrase_sim,dim=-1))\n",
    "        \n",
    "#         tgt_tensor = torch.zeros(b['feedback_set'].shape[1] , device=device)\n",
    "#         tgt_tensor[0] = 1.0\n",
    "#         print('CE Loss: ', F.cross_entropy(cos_sim,target=tgt_tensor), F.cross_entropy(cos_phrase_sim.mean(0),target=torch.tensor([1.0,0,0,0,0]).to(device)))\n",
    "        print('----------------------------')\n",
    "        j+=1\n",
    "        if j>5:\n",
    "            break\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f3ed8bc-1d6e-47fa-bfbb-0f6b3b1d97b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4, 5],\n",
       "         [6, 7, 8, 9, 0]],\n",
       "\n",
       "        [[1, 2, 3, 4, 5],\n",
       "         [6, 7, 8, 9, 0]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[[1,2,3,4,5],[6,7,8,9,0]]])\n",
    "t.repeat(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "39373ab0-572f-42ec-8bee-d6945dd568bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self, model_chkpt, device='cuda:0'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_chkpt).to(device)\n",
    "        self.device = device\n",
    "        \n",
    "    def mean_pooling(self,model_output,attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return F.normalize(se, p=2, dim=1)\n",
    "        \n",
    "    def forward(self, b):\n",
    "        sent_model_out = self.model(input_ids = b['sentence'].to(self.device),attention_mask=b['sentence_attn'].to(self.device))\n",
    "        feedback_model_out = self.model(input_ids = b['feedback_set'][0].to(self.device),attention_mask=b['feedback_attn_set'][0].to(self.device))\n",
    "        \n",
    "        sent_emb = self.mean_pooling( sent_model_out, b['sentence_pool_mask'].to(self.device))\n",
    "        feedback_emb = self.mean_pooling( feedback_model_out, b['feedback_pool_mask_set'][0].to(self.device))\n",
    "        \n",
    "        # print(pmo[0].shape,b['answer_phrases_pool_mask'].shape)\n",
    "        phrase_emb = [ self.mean_pooling( sent_model_out, b['answer_phrases_pool_mask'][0][i].to(self.device) ) for i in range(b['answer_phrases_pool_mask'][0].shape[0])]\n",
    "        phrase_emb = torch.stack(phrase_emb).squeeze(1)\n",
    "        cos_sim = F.cosine_similarity(sent_emb,feedback_emb,dim=1)\n",
    "        cos_phrase_sim = torch.matmul(phrase_emb,feedback_emb.transpose(1,0))\n",
    "        \n",
    "        tgt_tensor = torch.zeros(b['feedback_set'].shape[1] , device=self.device)\n",
    "        tgt_tensor[0] = 1.0 #the relevant feedback is always present at index 0\n",
    "        \n",
    "        return_dict = {'sent_ce_loss': F.cross_entropy(cos_sim,target=tgt_tensor),\n",
    "                       'avg_phrase_ce_loss': F.cross_entropy(cos_phrase_sim.mean(0),target=tgt_tensor),\n",
    "                       'sent_probs': F.softmax(cos_sim,dim=-1),\n",
    "                       'phrase_probs': F.softmax(cos_phrase_sim,dim=-1)}\n",
    "        \n",
    "        return return_dict\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "97a1fcd9-7fb7-4557-a1ee-023591930420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminator,train_dl,valid_dl,epochs,batch_size,optimizer,PATIENCE=20,save_dir=None):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    discriminator.train()\n",
    "    \n",
    "    loss_acc = 0\n",
    "    num_batches = 0\n",
    "    total_steps = 0\n",
    "    best_valid_loss = np.inf\n",
    "    patience = PATIENCE\n",
    "    \n",
    "    train_loss_arr,valid_loss_arr = [],[]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    discriminator.zero_grad()\n",
    "    \n",
    "    for E in range(epochs):\n",
    "        \n",
    "        valid_loss = validate(discriminator,valid_dl)\n",
    "        valid_loss_arr.append(valid_loss/len(valid_dl))\n",
    "        \n",
    "        num_samples = 0\n",
    "        \n",
    "        for b in train_dl:\n",
    "            \n",
    "            y = discriminator(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['sent_ce_loss'] + y['avg_phrase_ce_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            \n",
    "            num_samples+=1\n",
    "            \n",
    "            loss.backward()\n",
    "            loss_acc += loss.item()\n",
    "            \n",
    "            if num_samples%batch_size==0:\n",
    "                optimizer.step()\n",
    "\n",
    "                num_batches += 1\n",
    "                total_steps += 1\n",
    "            \n",
    "                train_loss_arr.append(loss_acc/num_batches)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "                if total_steps%100==0 and total_steps!=0:\n",
    "                    print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "            \n",
    "        #print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "        \n",
    "        torch.save({'model_state':discriminator.state_dict(),\n",
    "                    'optimizer':optimizer.state_dict(),\n",
    "                    'epoch':E},\n",
    "                    f\"{save_dir}/Epoch_{E}_model_chkpt.pth.tar\")\n",
    "        \n",
    "        if valid_loss<best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            patience = PATIENCE\n",
    "            \n",
    "            torch.save({'model_state':discriminator.state_dict(),\n",
    "                        'optimizer':optimizer.state_dict(),\n",
    "                        'epoch':E},\n",
    "                        f\"{save_dir}/best_model_chkpt.pth.tar\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            print(f\"REDUCING PATIENCE...{patience}\")\n",
    "\n",
    "        if patience<=0:\n",
    "            print(\"RUNNING OUT OF PATIENCE... TERMINATING\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "    return train_loss_arr,valid_loss_arr\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b5e5931d-65fc-421d-8bf3-4bdb58b8b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(discriminator,valid_dl):\n",
    "    \n",
    "    discriminator.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for b in valid_dl:\n",
    "            y = discriminator(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['sent_ce_loss'] + y['avg_phrase_ce_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    print(\"Validation Loss:\",valid_loss)\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7d1cb84b-dd2e-495f-845d-03ec726b7bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Ravi/rghadia_env/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3615.1683789491653\n",
      "Epoch: 0 \t Steps taken: 100 \tLoss: 37.71666325211525\n",
      "Epoch: 0 \t Steps taken: 200 \tLoss: 36.52932067990303\n",
      "Epoch: 0 \t Steps taken: 300 \tLoss: 36.01980754494667\n",
      "Validation Loss: 2872.763494491577\n",
      "Epoch: 1 \t Steps taken: 400 \tLoss: 35.59265251427889\n",
      "Epoch: 1 \t Steps taken: 500 \tLoss: 35.165306582212445\n",
      "Epoch: 1 \t Steps taken: 600 \tLoss: 34.886897427837056\n",
      "Validation Loss: 2844.0738703012466\n",
      "Epoch: 2 \t Steps taken: 700 \tLoss: 34.64229964988572\n",
      "Epoch: 2 \t Steps taken: 800 \tLoss: 34.32756020218134\n",
      "Epoch: 2 \t Steps taken: 900 \tLoss: 34.09135734041532\n",
      "Validation Loss: 2844.4556016921997\n",
      "Epoch: 3 \t Steps taken: 1000 \tLoss: 33.94833424413204\n",
      "Epoch: 3 \t Steps taken: 1100 \tLoss: 33.71300002867525\n",
      "Epoch: 3 \t Steps taken: 1200 \tLoss: 33.50649184077978\n",
      "Epoch: 3 \t Steps taken: 1300 \tLoss: 33.35283208085941\n",
      "REDUCING PATIENCE...4\n",
      "Validation Loss: 2829.7463079690933\n",
      "Epoch: 4 \t Steps taken: 1400 \tLoss: 33.189559691463195\n",
      "Epoch: 4 \t Steps taken: 1500 \tLoss: 33.016933360815045\n",
      "Epoch: 4 \t Steps taken: 1600 \tLoss: 32.871917424350976\n",
      "Validation Loss: 2839.9378185272217\n",
      "Epoch: 5 \t Steps taken: 1700 \tLoss: 32.7428625302455\n",
      "Epoch: 5 \t Steps taken: 1800 \tLoss: 32.59137649913629\n",
      "Epoch: 5 \t Steps taken: 1900 \tLoss: 32.45775387613397\n",
      "REDUCING PATIENCE...4\n",
      "Validation Loss: 2847.635892510414\n",
      "Epoch: 6 \t Steps taken: 2000 \tLoss: 32.34584897208214\n",
      "Epoch: 6 \t Steps taken: 2100 \tLoss: 32.21432023752303\n",
      "Epoch: 6 \t Steps taken: 2200 \tLoss: 32.09777820316228\n",
      "Epoch: 6 \t Steps taken: 2300 \tLoss: 31.993057424555655\n",
      "REDUCING PATIENCE...3\n",
      "Validation Loss: 2856.7004598379135\n",
      "Epoch: 7 \t Steps taken: 2400 \tLoss: 31.881085532208285\n",
      "Epoch: 7 \t Steps taken: 2500 \tLoss: 31.772468768930434\n",
      "Epoch: 7 \t Steps taken: 2600 \tLoss: 31.68502562078146\n",
      "REDUCING PATIENCE...2\n",
      "Validation Loss: 2865.634364962578\n",
      "Epoch: 8 \t Steps taken: 2700 \tLoss: 31.589705600650223\n",
      "Epoch: 8 \t Steps taken: 2800 \tLoss: 31.496960785729545\n",
      "Epoch: 8 \t Steps taken: 2900 \tLoss: 31.406555746958173\n",
      "REDUCING PATIENCE...1\n",
      "Validation Loss: 2889.0780141353607\n",
      "Epoch: 9 \t Steps taken: 3000 \tLoss: 31.32495020457109\n",
      "Epoch: 9 \t Steps taken: 3100 \tLoss: 31.232797093545237\n",
      "Epoch: 9 \t Steps taken: 3200 \tLoss: 31.14797064855695\n",
      "REDUCING PATIENCE...0\n",
      "RUNNING OUT OF PATIENCE... TERMINATING\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "# MPNet = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "discriminator_model = discriminator(bert_chkpt,device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(discriminator_model.parameters(),lr=1e-5)\n",
    "\n",
    "save_dir = 'Detect_Span_FB_MPNET_chkpts_1'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "train_loss,valid_loss = train(discriminator_model,\n",
    "                              train_DL,\n",
    "                              valid_DL,\n",
    "                              EPOCHS,\n",
    "                              BATCH_SIZE,\n",
    "                              optimizer,\n",
    "                              PATIENCE=5,\n",
    "                              save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91101fb6-ccc5-4b70-a781-f80306d79560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train_loss.json','w') as f:\n",
    "    json.dump(train_loss,f)\n",
    "\n",
    "with open('valid_loss.json','w') as f:\n",
    "    json.dump(valid_loss,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1438eb8-e8f1-41bd-ab9c-8c0ee15ab891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_ds = np.array(train_loss)[np.round(np.linspace(0, len(train_loss) - 1, len(valid_loss))).astype(int)]\n",
    "loss_df = pd.DataFrame({'train_loss':train_loss_ds , 'valid_loss':valid_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32161e3-1a96-4893-ac8a-5b567044334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import express as px\n",
    "px.line(loss_df,y=['train_loss','valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b9d00-0197-4bcc-be96-83e62d9c96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.load_state_dict(torch.load('GenFB_BART_chkpts_1/Epoch_0_model_chkpt.pth.tar')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3a035-e5a3-49e4-bbf4-6a0699945e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for b in train_DL:\n",
    "    out = discriminator.generate(inputs=b['input'][0:1,0].to(device),top_p=0.5)\n",
    "    print(tokenizer.decode(b['input'][0:1,0][0],skip_special_tokens=True))\n",
    "    print(tokenizer.decode(b['feedback'][0:1,0][0],skip_special_tokens=True))\n",
    "    print(tokenizer.decode(out[0]))\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    i+=1\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96357d85-64e1-4d7e-8eab-ee36d405bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
