{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccce523c-f7e2-459c-89d3-775573e476e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from nltk import sent_tokenize as nltk_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ded45-9a0e-412b-a267-9f9f0e8b4e52",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bb3ad6-fd28-4103-b963-913ae82e1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data(csv,use_feedback=False):\n",
    "    df = pd.read_csv(csv)\n",
    "    new_df = []#pd.DataFrame(columns=['id','prompt','gen_text','error','feedback','severity','text_before_span','span','text_after_span'])\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(df)),desc='unrolling data'):\n",
    "        id = df.loc[i]['id']\n",
    "        prompt = df.loc[i]['prompt']\n",
    "        gen_text = df.loc[i]['generation']#.replace(u'\\xa0', u' ').replace(u'  ', u' ')\n",
    "        feedbacks = eval(df.loc[i]['responses'])\n",
    "        if not use_feedback:\n",
    "            dic = {\"id\":id,\n",
    "                  \"prompt\":prompt,\n",
    "                  \"gen_text\":gen_text,\n",
    "                  \"error\":\"NA\",\n",
    "                  \"feedback\":\"NA\",\n",
    "                  \"severity\":\"NA\",\n",
    "                  \"span_beg\":\"NA\",\n",
    "                  \"span_end\":\"NA\",\n",
    "                  \"span\":\"NA\"}\n",
    "\n",
    "            new_df.append(dic)\n",
    "            continue\n",
    "        else:\n",
    "            for response in feedbacks:\n",
    "                if len(response)==0:\n",
    "                    continue\n",
    "                for r in response:\n",
    "\n",
    "                    error = r[0]\n",
    "                    feedback = r[1].replace(\"_SEP_\",\",\").replace(\"_QUOTE_\",'\"')\n",
    "                    severity = r[2]\n",
    "                    beg = r[3]\n",
    "                    end = r[4]\n",
    "\n",
    "                    span = gen_text[beg:end]\n",
    "\n",
    "                    dic = {\"id\":id,\n",
    "                          \"prompt\":prompt,\n",
    "                          \"gen_text\":gen_text,\n",
    "                          \"error\":error,\n",
    "                          \"feedback\":feedback,\n",
    "                          \"severity\":severity,\n",
    "                          \"span_beg\":beg,\n",
    "                          \"span_end\":end,\n",
    "                          \"span\":span}\n",
    "\n",
    "                    new_df.append(dic)\n",
    "\n",
    "    return pd.DataFrame(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d28def48-424a-4775-9d18-ee0efe58c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrolling data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1308/1308 [00:01<00:00, 1110.10it/s]\n"
     ]
    }
   ],
   "source": [
    "data = flatten_data('../../../grouped_data.csv',use_feedback=True)\n",
    "\n",
    "# language_errors = ['Grammar_Usage', 'Off-prompt', 'Redundant', 'Self-contradiction', 'Incoherent']\n",
    "# data = data[data['error'].isin(language_errors)]\n",
    "# data = data[data['severity']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23af2716-9786-4e71-9f04-639ea758aa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41862"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70867267-c556-45c5-8d4c-0c721459ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>gen_text</th>\n",
       "      <th>error</th>\n",
       "      <th>feedback</th>\n",
       "      <th>severity</th>\n",
       "      <th>span_beg</th>\n",
       "      <th>span_end</th>\n",
       "      <th>span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>In the wild, animals display tender moments of...</td>\n",
       "      <td>To honor the effort he put into his latest set...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>this may just be overly nit-picky but these tw...</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>268</td>\n",
       "      <td>A lion and its cub enjoy a tender moment toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>In the wild, animals display tender moments of...</td>\n",
       "      <td>To honor the effort he put into his latest set...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>It does not need to go that much into detail b...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>268</td>\n",
       "      <td>The lion's paws rest on top of the front paws ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>In the wild, animals display tender moments of...</td>\n",
       "      <td>To honor the effort he put into his latest set...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>I think this is very mild and could almost not...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>268</td>\n",
       "      <td>The lion's paws rest on top of the front paws ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>The long-rumored Apple car might finally becom...</td>\n",
       "      <td>According to the Financial Times, Apple's been...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>repeats concept.</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>183</td>\n",
       "      <td>autonomous car.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>Earbuds and headphones are among the most pers...</td>\n",
       "      <td>Wifi range and device integration features als...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>It's assumed that a person wearing hearing aid...</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>165</td>\n",
       "      <td>with hearing loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41692</th>\n",
       "      <td>1301</td>\n",
       "      <td>Contrary reports that she died after a stray b...</td>\n",
       "      <td>She was shot in the head by a stray bullet dur...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>The selected span contains the same informati...</td>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>433</td>\n",
       "      <td>she was hit by the stray bullet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41694</th>\n",
       "      <td>1301</td>\n",
       "      <td>Contrary reports that she died after a stray b...</td>\n",
       "      <td>She was shot in the head by a stray bullet dur...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>Repeats the first sentence, but sounds appropr...</td>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>433</td>\n",
       "      <td>she was hit by the stray bullet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>1301</td>\n",
       "      <td>Contrary reports that she died after a stray b...</td>\n",
       "      <td>She was shot in the head by a stray bullet dur...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>This is already implied that it was a stray bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>433</td>\n",
       "      <td>stray bullet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41770</th>\n",
       "      <td>1304</td>\n",
       "      <td>Donald Trump's Space Force is preparing to act...</td>\n",
       "      <td>The Space Fence is a $1.6 billion project that...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>This is being repeated in the prompt. Given th...</td>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>486</td>\n",
       "      <td>President Donald Trump's Space Force is prepar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41792</th>\n",
       "      <td>1304</td>\n",
       "      <td>Donald Trump's Space Force is preparing to act...</td>\n",
       "      <td>The Space Fence is a $1.6 billion project that...</td>\n",
       "      <td>Redundant</td>\n",
       "      <td>restates antecedent</td>\n",
       "      <td>1</td>\n",
       "      <td>429</td>\n",
       "      <td>486</td>\n",
       "      <td>radar system that spots and tracks objects orb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4710 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             prompt  \\\n",
       "5         0  In the wild, animals display tender moments of...   \n",
       "9         0  In the wild, animals display tender moments of...   \n",
       "12        0  In the wild, animals display tender moments of...   \n",
       "28        1  The long-rumored Apple car might finally becom...   \n",
       "71        2  Earbuds and headphones are among the most pers...   \n",
       "...     ...                                                ...   \n",
       "41692  1301  Contrary reports that she died after a stray b...   \n",
       "41694  1301  Contrary reports that she died after a stray b...   \n",
       "41698  1301  Contrary reports that she died after a stray b...   \n",
       "41770  1304  Donald Trump's Space Force is preparing to act...   \n",
       "41792  1304  Donald Trump's Space Force is preparing to act...   \n",
       "\n",
       "                                                gen_text      error  \\\n",
       "5      To honor the effort he put into his latest set...  Redundant   \n",
       "9      To honor the effort he put into his latest set...  Redundant   \n",
       "12     To honor the effort he put into his latest set...  Redundant   \n",
       "28     According to the Financial Times, Apple's been...  Redundant   \n",
       "71     Wifi range and device integration features als...  Redundant   \n",
       "...                                                  ...        ...   \n",
       "41692  She was shot in the head by a stray bullet dur...  Redundant   \n",
       "41694  She was shot in the head by a stray bullet dur...  Redundant   \n",
       "41698  She was shot in the head by a stray bullet dur...  Redundant   \n",
       "41770  The Space Fence is a $1.6 billion project that...  Redundant   \n",
       "41792  The Space Fence is a $1.6 billion project that...  Redundant   \n",
       "\n",
       "                                                feedback  severity  span_beg  \\\n",
       "5      this may just be overly nit-picky but these tw...         1       127   \n",
       "9      It does not need to go that much into detail b...         1       178   \n",
       "12     I think this is very mild and could almost not...         1       178   \n",
       "28                                      repeats concept.         1       168   \n",
       "71     It's assumed that a person wearing hearing aid...         1       148   \n",
       "...                                                  ...       ...       ...   \n",
       "41692   The selected span contains the same informati...         1       401   \n",
       "41694  Repeats the first sentence, but sounds appropr...         1       401   \n",
       "41698  This is already implied that it was a stray bu...         1       420   \n",
       "41770  This is being repeated in the prompt. Given th...         1       340   \n",
       "41792                                restates antecedent         1       429   \n",
       "\n",
       "       span_end                                               span  \n",
       "5           268  A lion and its cub enjoy a tender moment toget...  \n",
       "9           268  The lion's paws rest on top of the front paws ...  \n",
       "12          268  The lion's paws rest on top of the front paws ...  \n",
       "28          183                                    autonomous car.  \n",
       "71          165                                  with hearing loss  \n",
       "...         ...                                                ...  \n",
       "41692       433                   she was hit by the stray bullet.  \n",
       "41694       433                   she was hit by the stray bullet.  \n",
       "41698       433                                      stray bullet.  \n",
       "41770       486  President Donald Trump's Space Force is prepar...  \n",
       "41792       486  radar system that spots and tracks objects orb...  \n",
       "\n",
       "[4710 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['error']=='Redundant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a3ca98-7c92-4d37-8ec3-b9baaae64d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['span_len'] = data['span'].apply(lambda x: len(x))\n",
    "#px.histogram(data['span_len'],nbins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb490eef-c99f-4280-ad51-14d3fb179d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['span_len']>20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d517f43c-e61c-4bd0-a76d-f005c4639626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['span_len']>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292b8ad0-8f94-49fe-9948-27d091922613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: error, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce48c0ff-3efa-4066-9523-5c2ab9799052",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gen_sentences'] = data['gen_text'].apply(lambda x: nltk_tokenizer(x))\n",
    "data['span_is_sentence'] = [1 if x in y else 0 for x,y in zip(data['span'],data['gen_sentences'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fd53e02-10b2-4191-8c5b-8ff5f7cbc6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: span_is_sentence, dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['span_is_sentence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee808bf2-ff63-44fa-9db1-730604a8ee18",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18785/3633372739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m392\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#data.loc[i]['gen_sentences'] = [s.strip() for s in data.loc[i]['gen_sentences']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gen_sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ravi/rghadia_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ravi/rghadia_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ravi/rghadia_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "i = 392\n",
    "#data.loc[i]['gen_sentences'] = [s.strip() for s in data.loc[i]['gen_sentences']]\n",
    "s = \" \".join(data.iloc[i]['gen_sentences'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70c2e69c-c948-43ac-b2e1-cea2a9468eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18785/4278889650.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gen_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Ravi/rghadia_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ravi/rghadia_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ravi/rghadia_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "data.iloc[i]['gen_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea1e414e-578c-4a4a-87bb-f4c2d82adb90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will Starbucks launch vegan options at all of its more than 5,000 locations in the United States?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[i]['span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14bc7853-0c81-401a-834f-e1617579080f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "span_beg    499\n",
       "span_end    596\n",
       "Name: 1037, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[i][['span_beg','span_end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "229065e6-d519-465d-a5ef-1c3de0cc5c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[data.iloc[i]['span_beg']:data.iloc[i]['span_end']]==data.iloc[i]['span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea3d1c33-2417-4b1c-bbf2-195591af1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check to see if the above technique is working fine for most data points\n",
    "data['tech_works'] = [\" \".join(data.iloc[i]['gen_sentences'])[data.iloc[i]['span_beg']:data.iloc[i]['span_end']] == data.iloc[i]['span'] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1eec121-9057-4541-8a36-12718876bdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     8401\n",
       "False     183\n",
       "Name: tech_works, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tech_works'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db00e595-1220-4849-935a-144fd61a8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['tech_works']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b6cdb99-7e40-42a9-b17b-f6f727b3d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e2c991a-0b77-4874-8606-4f43c2166cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_err_sentence(sentences,span_beg,span_end,multi_class=False,error_type=None):\n",
    "    \n",
    "    output = []\n",
    "    total_len = sum([len(s) for s in sentences]) + len(sentences) - 1 #total sentences length + (sentences-1) spaces\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    if multi_class:\n",
    "        label = error_type+1\n",
    "    else:\n",
    "        label = 1\n",
    "    \n",
    "    for s in sentences:\n",
    "        if idx>=span_beg and idx<=span_end:\n",
    "            output.append(label)\n",
    "        elif idx+len(s)>=span_beg and idx+len(s)<=span_end:\n",
    "            output.append(label)\n",
    "        elif idx<=span_beg and idx+len(s)>=span_end:\n",
    "            output.append(label)\n",
    "        else:\n",
    "            output.append(0)\n",
    "        \n",
    "        idx += len(s)+1\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd806a6d-cc26-4895-bbee-0dc6dcb96566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Given the fact that lots of cuts are a part of some diets, it seems obvious that this year could end up being A New Year's Eve for many people, either in class or in life.\",\n",
       " '* Runewee County is the majority weight loss state for about 65 percent of adults and deaths are linked to losing other lifestyle factors, such as diabetes or atopic dermatitis.',\n",
       " 'MD Anderson University obesity research from 2012 shows that African American males who were obese between 22 and 40 were more likely to end up with skin, dental and vision problems than their white, \"newborn.\"']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 101\n",
    "data.iloc[i]['gen_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "067ccf3c-e50f-4cbd-936a-6507823c7940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'African American males who were obese between 22 and 40 were more likely to end up with skin, dental and vision problems than their white,'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[i]['span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8539fdb3-1d46-4d43-b7f5-e2e8ec4fb8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_err_sentence(data.iloc[i]['gen_sentences'],data.iloc[i]['span_beg'],data.iloc[i]['span_end'],multi_class=True,error_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f2aca05-300c-4d77-9599-ec7269b23a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Off-prompt            2445\n",
       "Redundant             2131\n",
       "Incoherent            1900\n",
       "Grammar_Usage         1076\n",
       "Self-contradiction     849\n",
       "Name: error, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f37237b2-dc21-4196-b3b1-361b485c723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_MAP = {'Redundant':0,\n",
    "             'Off-prompt':1,\n",
    "             'Grammar_Usage':2,\n",
    "             'Incoherent':3,\n",
    "             'Self-contradiction':4,\n",
    "             'Needs_Google':5,\n",
    "             'Technical_Jargon':6,\n",
    "             'Commonsense':7,\n",
    "             'Encyclopedic':8,\n",
    "             'Bad_Math':9}\n",
    "\n",
    "INV_ERROR_MAP = {v:k for k,v in ERROR_MAP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4626aded-95e1-47ec-bb47-59914940c8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_scores = {'Excellent':3 , 'Acceptable':2 , 'Could be Improved':1, 'Bad': -1}\n",
    "\n",
    "def process_df(df):\n",
    "    df['list_feedback'] = df['feedback'].apply(lambda x: [ r + \"___\" + e for r,e in zip(x['rating'],x['explanation']) ])\n",
    "    df['sampled_feedback'] = df['list_feedback'].apply(lambda x: np.random.choice(x).split(\"___\") )\n",
    "    df['rating_score'] = df['sampled_feedback'].apply(lambda x: rating_scores[x[0]])\n",
    "    df['rating'] = df['sampled_feedback'].apply(lambda x: x[0])\n",
    "    df['explanation'] = df['sampled_feedback'].apply(lambda x: x[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd2ffa3d-fae5-45d9-89c6-899dba3982fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = process_df(pd.DataFrame(dataset['train']))\n",
    "val_df = process_df(pd.DataFrame(dataset['validation']))\n",
    "test_df = process_df(pd.DataFrame(dataset['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40dc46db-a864-459a-8e7a-b82df484643b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "bert_chkpt = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_chkpt)\n",
    "model = AutoModel.from_pretrained(bert_chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d31c623b-2b7b-4b28-a499-b63ba8311ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '[UNK]', '<pad>', '<mask>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "744c4863-8096-4c67-b473-90e03a0df39c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>feedback</th>\n",
       "      <th>list_feedback</th>\n",
       "      <th>sampled_feedback</th>\n",
       "      <th>rating_score</th>\n",
       "      <th>rating</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Could be Improved'],...</td>\n",
       "      <td>[Excellent___Has a link to detailed informatio...</td>\n",
       "      <td>[Could be Improved, This answer provides a lin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>This answer provides a link for job searches, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Excellent'], 'explan...</td>\n",
       "      <td>[Excellent___A link to a job search website is...</td>\n",
       "      <td>[Excellent, A link to a job search website is ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A link to a job search website is included, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information and support...</td>\n",
       "      <td>{'rating': ['Bad', 'Acceptable'], 'explanation...</td>\n",
       "      <td>[Bad___Talks about tax credits for businesses ...</td>\n",
       "      <td>[Bad, Talks about tax credits for businesses t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Talks about tax credits for businesses that hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nWorking holiday ma...</td>\n",
       "      <td>{'rating': ['Could be Improved', 'Acceptable']...</td>\n",
       "      <td>[Could be Improved___Answer is about Working H...</td>\n",
       "      <td>[Could be Improved, Answer is about Working Ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>Answer is about Working Holiday Makers, but do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nCOVID-19 Pandemic ...</td>\n",
       "      <td>{'rating': ['Bad', 'Could be Improved'], 'expl...</td>\n",
       "      <td>[Bad___Discusses pandemic visas. Doesn't menti...</td>\n",
       "      <td>[Could be Improved, This answer is very vague ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>This answer is very vague and does not answer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   How do I get help finding a job?   \n",
       "1                   How do I get help finding a job?   \n",
       "2                   How do I get help finding a job?   \n",
       "3  If I am in Australia on a worker holiday marke...   \n",
       "4  If I am in Australia on a worker holiday marke...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Coronavirus (COVID-19) information for job see...   \n",
       "1  Coronavirus (COVID-19) information for job see...   \n",
       "2  Coronavirus (COVID-19) information and support...   \n",
       "3  Frequently Asked Questions\\nWorking holiday ma...   \n",
       "4  Frequently Asked Questions\\nCOVID-19 Pandemic ...   \n",
       "\n",
       "                                            feedback  \\\n",
       "0  {'rating': ['Excellent', 'Could be Improved'],...   \n",
       "1  {'rating': ['Excellent', 'Excellent'], 'explan...   \n",
       "2  {'rating': ['Bad', 'Acceptable'], 'explanation...   \n",
       "3  {'rating': ['Could be Improved', 'Acceptable']...   \n",
       "4  {'rating': ['Bad', 'Could be Improved'], 'expl...   \n",
       "\n",
       "                                       list_feedback  \\\n",
       "0  [Excellent___Has a link to detailed informatio...   \n",
       "1  [Excellent___A link to a job search website is...   \n",
       "2  [Bad___Talks about tax credits for businesses ...   \n",
       "3  [Could be Improved___Answer is about Working H...   \n",
       "4  [Bad___Discusses pandemic visas. Doesn't menti...   \n",
       "\n",
       "                                    sampled_feedback  rating_score  \\\n",
       "0  [Could be Improved, This answer provides a lin...             1   \n",
       "1  [Excellent, A link to a job search website is ...             3   \n",
       "2  [Bad, Talks about tax credits for businesses t...            -1   \n",
       "3  [Could be Improved, Answer is about Working Ho...             1   \n",
       "4  [Could be Improved, This answer is very vague ...             1   \n",
       "\n",
       "              rating                                        explanation  \n",
       "0  Could be Improved  This answer provides a link for job searches, ...  \n",
       "1          Excellent  A link to a job search website is included, as...  \n",
       "2                Bad  Talks about tax credits for businesses that hi...  \n",
       "3  Could be Improved  Answer is about Working Holiday Makers, but do...  \n",
       "4  Could be Improved  This answer is very vague and does not answer ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9078f4a5-10f0-4d44-886e-53ae3826ea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coronavirus (COVID-19) information for job seekers\\nExisiting job seekers\\nIf you are a current job seeker or participant, this fact sheet provides\\nimportant information about mutual obligation requirements, appointments with\\nyour provider, and what to do if you are self-isolating:\\n\\nInformation for job seekers and participants\\n\\nIf you are participating in the ParentsNext program, this fact sheet provides\\nimportant information about your activities and appointments.\\n\\n\\nInformation for ParentsNext participants\\n\\n\\nParentsNext participants Frequently Asked Questions\\n\\n\\nIf you are a New Business Assistance with NEIS participant, these Frequently\\nAsked Questions (FAQ) provides information about accessing the Coronavirus\\nSupplement and what support is available during this time:\\n\\nNew Business Assistance with NEIS participants - Frequently Asked Questions\\n\\nIf you are a New Business Assistance with NEIS provider, these Frequently\\nAsked Questions (FAQ) provides information about supporting NEIS participants\\nduring the Coronavirus situation.\\n\\nNew Business Assistance with NEIS providers – Frequently Asked Questions\\n\\n*[NEIS]: New Enterprise Incentive Scheme'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['answer'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "619de540-d154-431a-8d5e-bab3bba6d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  7596,  1014,  2133,  2028,  2021,  2729,  1033,     2, 19614,\n",
       "          4139,  9545,  9545,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'length': tensor([14])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Hello, how are you doing?'+ f\" {tokenizer.eos_token} \" + \"Hemlooooo\",add_special_tokens=True,return_tensors='pt', return_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af181ac2-b1ae-4fcd-b59d-74b4defb3d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize as nltk_tokenizer\n",
    "len(nltk_tokenizer.sent_tokenize(train_df['answer'].loc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f22dd1b8-d28f-4d16-9acc-cd3dce4579cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21891, 23354, 1010, 2526, 17262, 1015, 2543, 1011, 2596, 2009, 3109, 24075, 4658, 17421, 3440, 3109, 24075, 2069, 2021, 2028, 1041, 2787, 3109, 29448, 2034, 13184, 1014, 2027, 2759, 7127, 3644, 2594, 2596, 2059, 8207, 14991, 5922, 1014, 14655, 2011, 2119, 10806, 1014, 2002, 2058, 2004, 2083, 2069, 2021, 2028, 2973, 1015, 11167, 22252, 1028, 2596, 2009, 3109, 24075, 2002, 6822, 2069, 2021, 2028, 8023, 2003, 2000, 3012, 2642, 18417, 2569, 1014, 2027, 2759, 7127, 3644, 2594, 2596, 2059, 2119, 3454, 2002, 14655, 1016], [2596, 2009, 3012, 2642, 18417, 6822, 3012, 2642, 18417, 6822, 4707, 2360, 3984, 2069, 2021, 2028, 1041, 2051, 2453, 5379, 2011, 11269, 2487, 13184, 1014, 2126, 4707, 2360, 3984, 1010, 6908, 4164, 1011, 3644, 2596, 2059, 3233, 2079, 2000, 21891, 23354, 12452, 2002, 2058, 2494, 2007, 2804, 2080, 2027, 2055, 1028, 2051, 2453, 5379, 2011, 11269, 2487, 6822, 1015, 4707, 2360, 3984, 2069, 2021, 2028, 1041, 2051, 2453, 5379, 2011, 11269, 2487, 10806, 1014, 2126, 4707, 2360, 3984, 1010, 6908, 4164, 1011, 3644, 2596, 2059, 4641, 11269, 2487, 6822, 2080, 2000, 21891, 23354, 3667, 1016], [2051, 2453, 5379, 2011, 11269, 2487, 11674, 1520, 4707, 2360, 3984, 1012, 1035, 11269, 2487, 1037, 1028, 2051, 6964, 20442, 5683]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_inp = tokenizer(nltk_tokenizer.sent_tokenize(train_df['answer'].loc[0]),add_special_tokens=False,return_token_type_ids=True)#,max_length=200,padding='max_length')\n",
    "tok_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05e6d281-2513-459b-a854-3f099d26309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7184f-4ca8-4d75-8dd4-5650f67a61a2",
   "metadata": {},
   "source": [
    "# NP Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3176cc13-e34e-4ebc-9a03-4ff4c9493e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import benepar, spacy\n",
    "benepar.download('benepar_en3')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "if spacy.__version__.startswith('2'):\n",
    "        nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1245c94f-093b-472d-9c80-d41b70e167be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coronavirus (COVID-19) information',\n",
       " 'FAQ',\n",
       " 'Information',\n",
       " 'NEIS participant',\n",
       " 'NEIS participants',\n",
       " 'NEIS provider',\n",
       " 'NEIS providers',\n",
       " 'New Business Assistance',\n",
       " 'New Enterprise Incentive Scheme',\n",
       " 'ParentsNext participants',\n",
       " 'Questions',\n",
       " 'a New Business Assistance',\n",
       " 'a current job seeker',\n",
       " 'appointments',\n",
       " 'important information',\n",
       " 'information',\n",
       " 'job seekers',\n",
       " 'mutual obligation requirements',\n",
       " 'participant',\n",
       " 'participants',\n",
       " 'the Coronavirus Supplement',\n",
       " 'the Coronavirus situation',\n",
       " 'the ParentsNext program',\n",
       " 'these Frequently Asked Questions',\n",
       " 'this fact sheet',\n",
       " 'this time',\n",
       " 'what',\n",
       " 'what support',\n",
       " 'you',\n",
       " 'your activities',\n",
       " 'your provider'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(train_df['answer'].loc[0].replace('\\n',' '))\n",
    "nps = []\n",
    "for np in doc.noun_chunks:\n",
    "    nps.append(np.text)\n",
    "\n",
    "set(nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a093a991-7536-4082-9bd2-7602825edfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "class feedback_QA_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,max_length=500):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.data = []\n",
    "        \n",
    "        for i in tqdm.tqdm(range(len(self.df)),desc='vectorizing..'):\n",
    "            \n",
    "            d = {}\n",
    "            \n",
    "            tok_question = tokenizer(self.df.iloc[i]['question'], add_special_tokens=False)\n",
    "            tok_answer = tokenizer(self.df.iloc[i]['answer'], add_special_tokens=False, max_length=self.max_len-len(tok_question['input_ids']), padding='max_length', truncation='only_first')\n",
    "            tok_feedback = tokenizer(self.df.iloc[i]['explanation'], add_special_tokens=False, max_length=self.max_len, padding='max_length', truncation='only_first')\n",
    "            \n",
    "            d['sentence'] = [tokenizer.bos_token_id] + tok_question['input_ids'] + [tokenizer.sep_token_id]*2 + tok_answer['input_ids']\n",
    "            d['sentence_attn'] = [1] + tok_question['attention_mask'] + [1,1] + tok_answer['attention_mask']\n",
    "            d['feedback'] = tok_feedback['input_ids']\n",
    "            d['feedback_attn'] = tok_feedback['attention_mask']\n",
    "            \n",
    "            d['sentence_pool_mask'] = [0] + [0]*len(tok_question['input_ids']) + [0,0] + tok_answer['attention_mask']\n",
    "            d['feedback_pool_mask'] = tok_feedback['attention_mask']\n",
    "            \n",
    "            answer_phrases = nltk_tokenizer.sent_tokenize(self.df.iloc[i]['answer'])\n",
    "            tok_phrases = tokenizer(answer_phrases,add_special_tokens=False,return_token_type_ids=True)\n",
    "            \n",
    "            d['answer_phrases_pool_mask'] = []\n",
    "            \n",
    "            for j in range(len(answer_phrases)):\n",
    "                answer_phrases_attn_mask = tok_phrases['token_type_ids'].copy()\n",
    "                answer_phrases_attn_mask[j] = tok_phrases['attention_mask'][j].copy()\n",
    "                answer_phrases_attn_mask = list(itertools.chain.from_iterable(answer_phrases_attn_mask))\n",
    "                pad_len = len(tok_answer['attention_mask']) - len(answer_phrases_attn_mask)\n",
    "                answer_phrases_attn_mask += [0]*pad_len\n",
    "                \n",
    "                answer_phrase_pool_mask = [0] + [0]*len(tok_question['input_ids']) + [0,0] + answer_phrases_attn_mask\n",
    "                \n",
    "                d['answer_phrases_pool_mask'].append(answer_phrase_pool_mask)\n",
    "            \n",
    "            if len(d['answer_phrases_pool_mask'][0])>len(d['sentence_pool_mask']):\n",
    "                continue\n",
    "                \n",
    "            self.data.append(d)\n",
    "\n",
    "    def add_neg_samples(self):\n",
    "        for i in tqdm.tqdm(range(self.__len__()),desc='adding neg samples...'):\n",
    "            self.data[i]['feedback_set'] = [self.data[i]['feedback']]\n",
    "            self.data[i]['feedback_attn_set'] = [self.data[i]['feedback_attn']]\n",
    "            self.data[i]['feedback_pool_mask_set'] = [self.data[i]['feedback_pool_mask']]\n",
    "            L = list(range(self.__len__()))\n",
    "            L.remove(i)\n",
    "            neg_samples_idx = np.random.choice(L,size=4)\n",
    "            for n_id in neg_samples_idx:\n",
    "                self.data[i]['feedback_set'].append(self.data[n_id]['feedback'])\n",
    "                self.data[i]['feedback_attn_set'].append(self.data[n_id]['feedback_attn'])\n",
    "                self.data[i]['feedback_pool_mask_set'].append(self.data[n_id]['feedback_pool_mask'])\n",
    "            for k in self.data[i].keys():\n",
    "                self.data[i][k] = torch.tensor(self.data[i][k])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c69c540d-1963-419c-8c09-08f5d65aa803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vectorizing..: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5660/5660 [00:18<00:00, 299.12it/s]\n",
      "adding neg samples...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 5279/5279 [00:22<00:00, 230.19it/s]\n",
      "vectorizing..: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1410/1410 [00:04<00:00, 290.53it/s]\n",
      "adding neg samples...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1316/1316 [00:05<00:00, 252.15it/s]\n",
      "vectorizing..: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1995/1995 [00:07<00:00, 260.13it/s]\n",
      "adding neg samples...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1835/1835 [00:07<00:00, 245.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = feedback_QA_dataset(train_df)\n",
    "train_dataset.add_neg_samples()\n",
    "valid_dataset = feedback_QA_dataset(val_df)\n",
    "valid_dataset.add_neg_samples()\n",
    "test_dataset = feedback_QA_dataset(test_df)\n",
    "test_dataset.add_neg_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "92049336-0c27-4e1d-b5f7-9791745c5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DL = DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
    "valid_DL = DataLoader(valid_dataset,batch_size=1,shuffle=True)\n",
    "test_DL = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1da63016-24f0-400e-9a29-9093ab832bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence torch.Size([1, 503])\n",
      "sentence_attn torch.Size([1, 503])\n",
      "feedback torch.Size([1, 500])\n",
      "feedback_attn torch.Size([1, 500])\n",
      "sentence_pool_mask torch.Size([1, 503])\n",
      "feedback_pool_mask torch.Size([1, 500])\n",
      "answer_phrases_pool_mask torch.Size([1, 3, 503])\n",
      "feedback_set torch.Size([1, 5, 500])\n",
      "feedback_attn_set torch.Size([1, 5, 500])\n",
      "feedback_pool_mask_set torch.Size([1, 5, 500])\n"
     ]
    }
   ],
   "source": [
    "for b in train_DL:\n",
    "    for k in b.keys():\n",
    "        print(k,b[k].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "524eef71-2aad-4803-892f-01b0a6fa82de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 503, 768]) torch.Size([1, 2, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([2, 768]) tensor([0.1847, 0.1714, 0.1046, 0.1936, 0.2543], device='cuda:0') tensor([0.1812, 0.1683, 0.1025, 0.1908, 0.2488], device='cuda:0')\n",
      "\n",
      "Input:  what are my options if i can not support myself on a whm visa? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa? you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you. \n",
      "\n",
      "Feedback:  this only talks about visa application, it fails to talk about the topic \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa?\n",
      "Relevance of phrase 0 is -3.585219383239746e-05 \n",
      "\n",
      "Phrase 1: you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you.\n",
      "Relevance of phrase 1 is -5.0827860832214355e-05 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 2, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([2, 768]) tensor([ 0.3963,  0.2174,  0.1381, -0.0235,  0.2542], device='cuda:0') tensor([ 0.3851,  0.2116,  0.1346, -0.0224,  0.2482], device='cuda:0')\n",
      "\n",
      "Input:  i was a working holiday maker but lost my job ; what should i do? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa? you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you. \n",
      "\n",
      "Feedback:  there is not a lot of information here. it doesn't say at all what to do if you lost your job. \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions when can i apply for the covid - 19 pandemic event visa?\n",
      "Relevance of phrase 0 is -0.008139640092849731 \n",
      "\n",
      "Phrase 1: you should only apply for this visa is you are unable to depart australia, your temporary visa expires in less than 28 days ( or did not expire more than 28 days ago ) and you have no other visa options available to you.\n",
      "Relevance of phrase 1 is 0.005527481436729431 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 6, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([6, 768]) tensor([ 0.4718,  0.0158,  0.2379, -0.0204,  0.1407], device='cuda:0') tensor([ 0.4584,  0.0154,  0.2293, -0.0200,  0.1383], device='cuda:0')\n",
      "\n",
      "Input:  is it practical to expect children to practice social distancing in childcare settings? physical distancing for coronavirus ( covid - 19 ) in schools if your child is sick, they must not go to school or childcare. you must keep them at home and away from others. to reduce the spread of viruses or germs in schools students and staff should continue to practise good hygiene. the australian health protection principal committee ( ahppc ) has issued updated advice on reducing the potential risk of covid - 19 transmission in schools. the ahppc also issued a statement on risk management for re - opening boarding schools and school - based residential colleges. for more information on school operations, visit the department of education, skills and employment website. \n",
      "\n",
      "Feedback:  it didn't talk about how practical it is to expect children to practice social distancing. \n",
      "\n",
      "Phrase 0: physical distancing for coronavirus ( covid - 19 ) in schools if your child is sick, they must not go to school or childcare.\n",
      "Relevance of phrase 0 is 0.006138890981674194 \n",
      "\n",
      "Phrase 1: you must keep them at home and away from others.\n",
      "Relevance of phrase 1 is 0.006233900785446167 \n",
      "\n",
      "Phrase 2: to reduce the spread of viruses or germs in schools students and staff should continue to practise good hygiene.\n",
      "Relevance of phrase 2 is -0.007832139730453491 \n",
      "\n",
      "Phrase 3: the australian health protection principal committee ( ahppc ) has issued updated advice on reducing the potential risk of covid - 19 transmission in schools.\n",
      "Relevance of phrase 3 is -0.007587403059005737 \n",
      "\n",
      "Phrase 4: the ahppc also issued a statement on risk management for re - opening boarding schools and school - based residential colleges.\n",
      "Relevance of phrase 4 is -0.005729973316192627 \n",
      "\n",
      "Phrase 5: for more information on school operations, visit the department of education, skills and employment website.\n",
      "Relevance of phrase 5 is -0.0033657848834991455 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 4, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([4, 768]) tensor([6.1255e-01, 1.8905e-01, 2.1566e-01, 6.4469e-02, 1.3964e-04],\n",
      "       device='cuda:0') tensor([0.6037, 0.1919, 0.2131, 0.0653, 0.0009], device='cuda:0')\n",
      "\n",
      "Input:  do i have to continue making gym membership payments if my gym has closed due to the coronavirus outbreak? covid - 19 ( coronavirus ) information for consumers gym memberships can my gym charge me a membership ‘ freeze ’ or ‘ holding ’ fee for the period they are closed? membership ‘ freeze ’ or ‘ holding ’ fees may be charged by gyms when customers elect to pause their membership, if this is permitted by the terms and conditions. given many memberships are being paused due to the government restrictions preventing gyms from operating, rather than customers requesting a pause, the accc expects that gyms will not charge membership ‘ freeze ’ or ‘ holding ’ fees. the accc also expects that gyms will refund any such holding fees incorrectly charged since the government restrictions came into effect. \n",
      "\n",
      "Feedback:  this is a good answer. it gives examples of what a gym might do with fees if they are forced to close. \n",
      "\n",
      "Phrase 0: covid - 19 ( coronavirus ) information for consumers gym memberships can my gym charge me a membership ‘ freeze ’ or ‘ holding ’ fee for the period they are closed?\n",
      "Relevance of phrase 0 is 0.001047760248184204 \n",
      "\n",
      "Phrase 1: membership ‘ freeze ’ or ‘ holding ’ fees may be charged by gyms when customers elect to pause their membership, if this is permitted by the terms and conditions.\n",
      "Relevance of phrase 1 is 0.000505596399307251 \n",
      "\n",
      "Phrase 2: given many memberships are being paused due to the government restrictions preventing gyms from operating, rather than customers requesting a pause, the accc expects that gyms will not charge membership ‘ freeze ’ or ‘ holding ’ fees.\n",
      "Relevance of phrase 2 is -0.0009500980377197266 \n",
      "\n",
      "Phrase 3: the accc also expects that gyms will refund any such holding fees incorrectly charged since the government restrictions came into effect.\n",
      "Relevance of phrase 3 is -0.00820833444595337 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 15, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([15, 768]) tensor([0.7977, 0.0632, 0.1302, 0.1488, 0.0589], device='cuda:0') tensor([0.7785, 0.0608, 0.1231, 0.1487, 0.0505], device='cuda:0')\n",
      "\n",
      "Input:  can i keep on working while waiting to see if the application for my next whm visa is accepted or not? frequently asked questions temporary visa measures supporting the agriculture sector employers due to the covid - 19 border restrictions, seasonal workers and pacific labour scheme participants are unable to travel to australia at present. what other options are available to access workers to address labour needs? in response to the current covid - 19 pandemic, the australian government has announced temporary measures to assist temporary visa holders currently in australia, including seasonal worker programme and pacific labour scheme participants, who are unable to currently return to their home country, to extend their stay in australia, and enable flexibility in changing approved employers where required. under these temporary measures, current approved employers may wish to employ seasonal worker programme or pacific labour scheme participants who have finished employment with their current approved employer, but who are unable to return to their home country. approved employers, like any employer, may also wish to employ temporary activity ( subclass 408 ) australian government endorsed event ( agee ) stream visa holders this visa will have a nil visa application charge ( vac ) for the covid - 19 pandemic event. employer sponsorship arrangements similar to the seasonal worker programme will also apply to the subclass 408 visa. these temporary measures are not intended to prevent the recruitment of australians to undertake this work. before seeking access to seasonal workers under the seasonal worker programme, approved employers must first try to recruit australians. where australian workers are unavailable, employers can also seek seasonal labour through the working holiday maker program. working holiday makers who are working in critical sectors ( i. e. agriculture, food processing, health care, aged care, disability care or child care ) will be exempt from the six month work limitation with one employer and eligible for a temporary activity ( subclass 408 ) visa in the australian government endorsed event ( agee ) stream. employers are still required to abide by all relevant australian workplace laws. overseas workers have the same rights under australian workplace law as all other employees. these temporary measures will be in place for a timeframe that allows relevant critical industries to bridge the gap between their immediate needs and the time to recruit, train and on - board australians. the department of home affairs is working with the department of education, skills and employment to ensure australians are prioritised for future job opportunities. \n",
      "\n",
      "Feedback:  this does not answer the question. it does not provide any information on whether or not workers can keep on working while waiting for the approval for their whm visa. instead, this answer provides information for seasonal worker programme and pacific labour scheme participants, temporary activity agee stream visa holders and also recommendation for employers to seek seasonal labor through working holiday maker program. \n",
      "\n",
      "Phrase 0: frequently asked questions temporary visa measures supporting the agriculture sector employers due to the covid - 19 border restrictions, seasonal workers and pacific labour scheme participants are unable to travel to australia at present.\n",
      "Relevance of phrase 0 is -0.005220949649810791 \n",
      "\n",
      "Phrase 1: what other options are available to access workers to address labour needs?\n",
      "Relevance of phrase 1 is 0.0005821883678436279 \n",
      "\n",
      "Phrase 2: in response to the current covid - 19 pandemic, the australian government has announced temporary measures to assist temporary visa holders currently in australia, including seasonal worker programme and pacific labour scheme participants, who are unable to currently return to their home country, to extend their stay in australia, and enable flexibility in changing approved employers where required.\n",
      "Relevance of phrase 2 is -0.007068425416946411 \n",
      "\n",
      "Phrase 3: under these temporary measures, current approved employers may wish to employ seasonal worker programme or pacific labour scheme participants who have finished employment with their current approved employer, but who are unable to return to their home country.\n",
      "Relevance of phrase 3 is 0.0010851025581359863 \n",
      "\n",
      "Phrase 4: approved employers, like any employer, may also wish to employ temporary activity ( subclass 408 ) australian government endorsed event ( agee ) stream visa holders this visa will have a nil visa application charge ( vac ) for the covid - 19 pandemic event.\n",
      "Relevance of phrase 4 is -0.006114304065704346 \n",
      "\n",
      "Phrase 5: employer sponsorship arrangements similar to the seasonal worker programme will also apply to the subclass 408 visa.\n",
      "Relevance of phrase 5 is -0.0024841129779815674 \n",
      "\n",
      "Phrase 6: these temporary measures are not intended to prevent the recruitment of australians to undertake this work.\n",
      "Relevance of phrase 6 is -0.003878474235534668 \n",
      "\n",
      "Phrase 7: before seeking access to seasonal workers under the seasonal worker programme, approved employers must first try to recruit australians.\n",
      "Relevance of phrase 7 is 0.0025942623615264893 \n",
      "\n",
      "Phrase 8: where australian workers are unavailable, employers can also seek seasonal labour through the working holiday maker program.\n",
      "Relevance of phrase 8 is 0.0057759881019592285 \n",
      "\n",
      "Phrase 9: working holiday makers who are working in critical sectors ( i. e.\n",
      "Relevance of phrase 9 is -0.00182303786277771 \n",
      "\n",
      "Phrase 10: agriculture, food processing, health care, aged care, disability care or child care ) will be exempt from the six month work limitation with one employer and eligible for a temporary activity ( subclass 408 ) visa in the australian government endorsed event ( agee ) stream.\n",
      "Relevance of phrase 10 is -0.0032051503658294678 \n",
      "\n",
      "Phrase 11: employers are still required to abide by all relevant australian workplace laws.\n",
      "Relevance of phrase 11 is -0.009967178106307983 \n",
      "\n",
      "Phrase 12: overseas workers have the same rights under australian workplace law as all other employees.\n",
      "Relevance of phrase 12 is -0.007970213890075684 \n",
      "\n",
      "Phrase 13: these temporary measures will be in place for a timeframe that allows relevant critical industries to bridge the gap between their immediate needs and the time to recruit, train and on - board australians.\n",
      "Relevance of phrase 13 is -0.003447622060775757 \n",
      "\n",
      "Phrase 14: the department of home affairs is working with the department of education, skills and employment to ensure australians are prioritised for future job opportunities.\n",
      "Relevance of phrase 14 is -0.007946610450744629 \n",
      "\n",
      "----------------------------\n",
      "torch.Size([1, 503, 768]) torch.Size([1, 3, 503])\n",
      "torch.Size([5, 768]) torch.Size([1, 768]) torch.Size([3, 768]) tensor([0.0184, 0.1597, 0.2454, 0.2845, 0.0405], device='cuda:0') tensor([0.0099, 0.1593, 0.2246, 0.2651, 0.0387], device='cuda:0')\n",
      "\n",
      "Input:  can i continue to work while i am waiting for a decision for my application for my whm visa? frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am overseas. can i be granted a covid - 19 pandemic event visa? the covid - 19 pandemic event visa can only be granted to people in australia. \n",
      "\n",
      "Feedback:  this does not answer the question and is off topic \n",
      "\n",
      "Phrase 0: frequently asked questions covid - 19 pandemic - australian government endorsed event ( agee ) stream of the temporary activity ( subclass 408 ) visa frequently asked questions i am overseas.\n",
      "Relevance of phrase 0 is 0.001007080078125 \n",
      "\n",
      "Phrase 1: can i be granted a covid - 19 pandemic event visa?\n",
      "Relevance of phrase 1 is 0.0007690191268920898 \n",
      "\n",
      "Phrase 2: the covid - 19 pandemic event visa can only be granted to people in australia.\n",
      "Relevance of phrase 2 is -0.0006523579359054565 \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return F.normalize(se, p=2, dim=1)\n",
    "\n",
    "j = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b in test_DL:\n",
    "        se = mean_pooling( model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device)), b['sentence_pool_mask'].to(device))\n",
    "        fe = mean_pooling(model(input_ids = b['feedback_set'][0].to(device),attention_mask=b['feedback_attn_set'][0].to(device)), b['feedback_pool_mask_set'][0].to(device))\n",
    "        pmo = model(input_ids = b['sentence'].to(device),attention_mask=b['sentence_attn'].to(device))\n",
    "        print(pmo[0].shape,b['answer_phrases_pool_mask'].shape)\n",
    "        pe = [mean_pooling(pmo,b['answer_phrases_pool_mask'][0][i].to(device) ) for i in range(b['answer_phrases_pool_mask'][0].shape[0])]\n",
    "        pe = torch.stack(pe).squeeze(1)\n",
    "        cos_sim = F.cosine_similarity(se,fe,dim=1)\n",
    "        cos_phrase_sim = torch.matmul(pe,fe.transpose(1,0))\n",
    "        print(fe.shape,se.shape,pe.shape,cos_sim,cos_phrase_sim.mean(0))\n",
    "        \n",
    "        sent_probs = F.softmax(cos_sim,dim=-1)\n",
    "        phrase_probs = F.softmax(cos_phrase_sim,dim=-1)\n",
    "        \n",
    "        print('\\nInput: ',tokenizer.decode(b['sentence'][0],skip_special_tokens=True),'\\n')\n",
    "        print('Feedback: ',tokenizer.decode(b['feedback'][0],skip_special_tokens=True),'\\n')\n",
    "        for i in range(b['answer_phrases_pool_mask'][0].shape[0]):\n",
    "            relevance = phrase_probs[i][0] - sent_probs[0]\n",
    "            \n",
    "            phrase_tok = torch.mul(b['sentence'][0],b['answer_phrases_pool_mask'][0][i])\n",
    "            print(f\"Phrase {i}:\",tokenizer.decode(phrase_tok,skip_special_tokens=True))\n",
    "            print(f\"Relevance of phrase {i} is {relevance}\",'\\n')\n",
    "        \n",
    "#         print('softmax: ',F.softmax(cos_sim),F.softmax(cos_phrase_sim,dim=-1))\n",
    "        \n",
    "#         tgt_tensor = torch.zeros(b['feedback_set'].shape[1] , device=device)\n",
    "#         tgt_tensor[0] = 1.0\n",
    "#         print('CE Loss: ', F.cross_entropy(cos_sim,target=tgt_tensor), F.cross_entropy(cos_phrase_sim.mean(0),target=torch.tensor([1.0,0,0,0,0]).to(device)))\n",
    "        print('----------------------------')\n",
    "        j+=1\n",
    "        if j>5:\n",
    "            break\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f3ed8bc-1d6e-47fa-bfbb-0f6b3b1d97b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4, 5],\n",
       "         [6, 7, 8, 9, 0]],\n",
       "\n",
       "        [[1, 2, 3, 4, 5],\n",
       "         [6, 7, 8, 9, 0]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[[1,2,3,4,5],[6,7,8,9,0]]])\n",
    "t.repeat(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "39373ab0-572f-42ec-8bee-d6945dd568bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self, model_chkpt, device='cuda:0'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_chkpt).to(device)\n",
    "        self.device = device\n",
    "        \n",
    "    def mean_pooling(self,model_output,attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return F.normalize(se, p=2, dim=1)\n",
    "        \n",
    "    def forward(self, b):\n",
    "        sent_model_out = self.model(input_ids = b['sentence'].to(self.device),attention_mask=b['sentence_attn'].to(self.device))\n",
    "        feedback_model_out = self.model(input_ids = b['feedback_set'][0].to(self.device),attention_mask=b['feedback_attn_set'][0].to(self.device))\n",
    "        \n",
    "        sent_emb = self.mean_pooling( sent_model_out, b['sentence_pool_mask'].to(self.device))\n",
    "        feedback_emb = self.mean_pooling( feedback_model_out, b['feedback_pool_mask_set'][0].to(self.device))\n",
    "        \n",
    "        # print(pmo[0].shape,b['answer_phrases_pool_mask'].shape)\n",
    "        phrase_emb = [ self.mean_pooling( sent_model_out, b['answer_phrases_pool_mask'][0][i].to(self.device) ) for i in range(b['answer_phrases_pool_mask'][0].shape[0])]\n",
    "        phrase_emb = torch.stack(phrase_emb).squeeze(1)\n",
    "        cos_sim = F.cosine_similarity(sent_emb,feedback_emb,dim=1)\n",
    "        cos_phrase_sim = torch.matmul(phrase_emb,feedback_emb.transpose(1,0))\n",
    "        \n",
    "        tgt_tensor = torch.zeros(b['feedback_set'].shape[1] , device=self.device)\n",
    "        tgt_tensor[0] = 1.0 #the relevant feedback is always present at index 0\n",
    "        \n",
    "        return_dict = {'sent_ce_loss': F.cross_entropy(cos_sim,target=tgt_tensor),\n",
    "                       'avg_phrase_ce_loss': F.cross_entropy(cos_phrase_sim.mean(0),target=tgt_tensor),\n",
    "                       'sent_probs': F.softmax(cos_sim,dim=-1),\n",
    "                       'phrase_probs': F.softmax(cos_phrase_sim,dim=-1)}\n",
    "        \n",
    "        return return_dict\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "97a1fcd9-7fb7-4557-a1ee-023591930420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminator,train_dl,valid_dl,epochs,batch_size,optimizer,PATIENCE=20,save_dir=None):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    discriminator.train()\n",
    "    \n",
    "    loss_acc = 0\n",
    "    num_batches = 0\n",
    "    total_steps = 0\n",
    "    best_valid_loss = np.inf\n",
    "    patience = PATIENCE\n",
    "    \n",
    "    train_loss_arr,valid_loss_arr = [],[]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    discriminator.zero_grad()\n",
    "    \n",
    "    for E in range(epochs):\n",
    "        \n",
    "        valid_loss = validate(discriminator,valid_dl)\n",
    "        valid_loss_arr.append(valid_loss/len(valid_dl))\n",
    "        \n",
    "        num_samples = 0\n",
    "        \n",
    "        for b in train_dl:\n",
    "            \n",
    "            y = discriminator(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['sent_ce_loss'] + y['avg_phrase_ce_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            \n",
    "            num_samples+=1\n",
    "            \n",
    "            loss.backward()\n",
    "            loss_acc += loss.item()\n",
    "            \n",
    "            if num_samples%batch_size==0:\n",
    "                optimizer.step()\n",
    "\n",
    "                num_batches += 1\n",
    "                total_steps += 1\n",
    "            \n",
    "                train_loss_arr.append(loss_acc/num_batches)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "                if total_steps%100==0 and total_steps!=0:\n",
    "                    print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "            \n",
    "        #print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "        \n",
    "        torch.save({'model_state':discriminator.state_dict(),\n",
    "                    'optimizer':optimizer.state_dict(),\n",
    "                    'epoch':E},\n",
    "                    f\"{save_dir}/Epoch_{E}_model_chkpt.pth.tar\")\n",
    "        \n",
    "        if valid_loss<best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            patience = PATIENCE\n",
    "            \n",
    "            torch.save({'model_state':discriminator.state_dict(),\n",
    "                        'optimizer':optimizer.state_dict(),\n",
    "                        'epoch':E},\n",
    "                        f\"{save_dir}/best_model_chkpt.pth.tar\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            print(f\"REDUCING PATIENCE...{patience}\")\n",
    "\n",
    "        if patience<=0:\n",
    "            print(\"RUNNING OUT OF PATIENCE... TERMINATING\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "    return train_loss_arr,valid_loss_arr\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b5e5931d-65fc-421d-8bf3-4bdb58b8b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(discriminator,valid_dl):\n",
    "    \n",
    "    discriminator.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for b in valid_dl:\n",
    "            y = discriminator(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['sent_ce_loss'] + y['avg_phrase_ce_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    print(\"Validation Loss:\",valid_loss)\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7d1cb84b-dd2e-495f-845d-03ec726b7bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Ravi/rghadia_env/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3615.1683789491653\n",
      "Epoch: 0 \t Steps taken: 100 \tLoss: 37.71666325211525\n",
      "Epoch: 0 \t Steps taken: 200 \tLoss: 36.52932067990303\n",
      "Epoch: 0 \t Steps taken: 300 \tLoss: 36.01980754494667\n",
      "Validation Loss: 2872.763494491577\n",
      "Epoch: 1 \t Steps taken: 400 \tLoss: 35.59265251427889\n",
      "Epoch: 1 \t Steps taken: 500 \tLoss: 35.165306582212445\n",
      "Epoch: 1 \t Steps taken: 600 \tLoss: 34.886897427837056\n",
      "Validation Loss: 2844.0738703012466\n",
      "Epoch: 2 \t Steps taken: 700 \tLoss: 34.64229964988572\n",
      "Epoch: 2 \t Steps taken: 800 \tLoss: 34.32756020218134\n",
      "Epoch: 2 \t Steps taken: 900 \tLoss: 34.09135734041532\n",
      "Validation Loss: 2844.4556016921997\n",
      "Epoch: 3 \t Steps taken: 1000 \tLoss: 33.94833424413204\n",
      "Epoch: 3 \t Steps taken: 1100 \tLoss: 33.71300002867525\n",
      "Epoch: 3 \t Steps taken: 1200 \tLoss: 33.50649184077978\n",
      "Epoch: 3 \t Steps taken: 1300 \tLoss: 33.35283208085941\n",
      "REDUCING PATIENCE...4\n",
      "Validation Loss: 2829.7463079690933\n",
      "Epoch: 4 \t Steps taken: 1400 \tLoss: 33.189559691463195\n",
      "Epoch: 4 \t Steps taken: 1500 \tLoss: 33.016933360815045\n",
      "Epoch: 4 \t Steps taken: 1600 \tLoss: 32.871917424350976\n",
      "Validation Loss: 2839.9378185272217\n",
      "Epoch: 5 \t Steps taken: 1700 \tLoss: 32.7428625302455\n",
      "Epoch: 5 \t Steps taken: 1800 \tLoss: 32.59137649913629\n",
      "Epoch: 5 \t Steps taken: 1900 \tLoss: 32.45775387613397\n",
      "REDUCING PATIENCE...4\n",
      "Validation Loss: 2847.635892510414\n",
      "Epoch: 6 \t Steps taken: 2000 \tLoss: 32.34584897208214\n",
      "Epoch: 6 \t Steps taken: 2100 \tLoss: 32.21432023752303\n",
      "Epoch: 6 \t Steps taken: 2200 \tLoss: 32.09777820316228\n",
      "Epoch: 6 \t Steps taken: 2300 \tLoss: 31.993057424555655\n",
      "REDUCING PATIENCE...3\n",
      "Validation Loss: 2856.7004598379135\n",
      "Epoch: 7 \t Steps taken: 2400 \tLoss: 31.881085532208285\n",
      "Epoch: 7 \t Steps taken: 2500 \tLoss: 31.772468768930434\n",
      "Epoch: 7 \t Steps taken: 2600 \tLoss: 31.68502562078146\n",
      "REDUCING PATIENCE...2\n",
      "Validation Loss: 2865.634364962578\n",
      "Epoch: 8 \t Steps taken: 2700 \tLoss: 31.589705600650223\n",
      "Epoch: 8 \t Steps taken: 2800 \tLoss: 31.496960785729545\n",
      "Epoch: 8 \t Steps taken: 2900 \tLoss: 31.406555746958173\n",
      "REDUCING PATIENCE...1\n",
      "Validation Loss: 2889.0780141353607\n",
      "Epoch: 9 \t Steps taken: 3000 \tLoss: 31.32495020457109\n",
      "Epoch: 9 \t Steps taken: 3100 \tLoss: 31.232797093545237\n",
      "Epoch: 9 \t Steps taken: 3200 \tLoss: 31.14797064855695\n",
      "REDUCING PATIENCE...0\n",
      "RUNNING OUT OF PATIENCE... TERMINATING\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "# MPNet = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "discriminator_model = discriminator(bert_chkpt,device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(discriminator_model.parameters(),lr=1e-5)\n",
    "\n",
    "save_dir = 'Detect_Span_FB_MPNET_chkpts_1'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "train_loss,valid_loss = train(discriminator_model,\n",
    "                              train_DL,\n",
    "                              valid_DL,\n",
    "                              EPOCHS,\n",
    "                              BATCH_SIZE,\n",
    "                              optimizer,\n",
    "                              PATIENCE=5,\n",
    "                              save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91101fb6-ccc5-4b70-a781-f80306d79560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train_loss.json','w') as f:\n",
    "    json.dump(train_loss,f)\n",
    "\n",
    "with open('valid_loss.json','w') as f:\n",
    "    json.dump(valid_loss,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1438eb8-e8f1-41bd-ab9c-8c0ee15ab891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_ds = np.array(train_loss)[np.round(np.linspace(0, len(train_loss) - 1, len(valid_loss))).astype(int)]\n",
    "loss_df = pd.DataFrame({'train_loss':train_loss_ds , 'valid_loss':valid_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32161e3-1a96-4893-ac8a-5b567044334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import express as px\n",
    "px.line(loss_df,y=['train_loss','valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b9d00-0197-4bcc-be96-83e62d9c96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.load_state_dict(torch.load('GenFB_BART_chkpts_1/Epoch_0_model_chkpt.pth.tar')['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3a035-e5a3-49e4-bbf4-6a0699945e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for b in train_DL:\n",
    "    out = discriminator.generate(inputs=b['input'][0:1,0].to(device),top_p=0.5)\n",
    "    print(tokenizer.decode(b['input'][0:1,0][0],skip_special_tokens=True))\n",
    "    print(tokenizer.decode(b['feedback'][0:1,0][0],skip_special_tokens=True))\n",
    "    print(tokenizer.decode(out[0]))\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    i+=1\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96357d85-64e1-4d7e-8eab-ee36d405bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
