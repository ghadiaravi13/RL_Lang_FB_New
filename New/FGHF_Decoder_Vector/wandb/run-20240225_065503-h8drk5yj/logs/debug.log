2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_setup.py:_flush():76] Current SDK version is 0.15.4
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_setup.py:_flush():76] Configure stats pid to 15661
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_setup.py:_flush():76] Loading settings from /home/raja/.config/wandb/settings
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_setup.py:_flush():76] Loading settings from /home/jupyter/Ravi_new/RL_Language_Feedback/New/FGHF_Decoder_Vector/wandb/settings
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'New/FGHF_Decoder_Vector/tasks/qa_feedback/training/train_finegrained.py', 'program': '/home/jupyter/Ravi_new/RL_Language_Feedback/New/FGHF_Decoder_Vector/tasks/qa_feedback/training/train_finegrained.py'}
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_init.py:_log_setup():507] Logging user logs to /home/jupyter/Ravi_new/RL_Language_Feedback/New/FGHF_Decoder_Vector/wandb/run-20240225_065503-h8drk5yj/logs/debug.log
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jupyter/Ravi_new/RL_Language_Feedback/New/FGHF_Decoder_Vector/wandb/run-20240225_065503-h8drk5yj/logs/debug-internal.log
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_init.py:init():547] calling init triggers
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
config: {'vector_RL': 3, 'model': {'policy_model': {'ckpt': './tasks/qa_feedback/model_outputs/t5-large-1k-train', 'input_padding_side': 'right', 'train_generation_kwargs': {'do_sample': True, 'top_k': 20, 'top_p': None, 'temperature': 10.0}, 'eval_generation_kwargs': {'do_sample': False, 'num_beams': 1}}, 'value_model': {'ckpt': 't5-base', 'freeze_value_model': False, 'policy_value_sharing': False}}, 'reward': {'relevance_model': {'ckpt': './tasks/qa_feedback/model_outputs/rel_rm', 'positive_reward': 0.3, 'negative_reward': -0.3}, 'factuality_model': {'ckpt': './tasks/qa_feedback/model_outputs/fact_rm', 'positive_reward': 0.5, 'negative_reward': -0.5}, 'completeness_model': {'ckpt': './tasks/qa_feedback/model_outputs/comp_rm', 'mean': -0.44677690555995353, 'std': 8.301160619054132, 'bias': 0.0, 'scale': 0.3}}, 'env': {'max_input_len': 512, 'max_generated_len': 200, 'train_num_samples_per_input': 3}, 'ppo': {'kl_coef': 0.3, 'lam': 0.95, 'gamma': 1.0, 'pg_coef': 1.0, 'vf_coef': 1.0, 'cliprange': 0.2, 'cliprange_value': 0.2, 'whiten_rewards': True}, 'train': {'total_episodes': 80000, 'eval_interval': 5, 'sampling_batch_size_per_card': 2, 'training_batch_size_per_card': 2, 'lr': 5e-05, 'n_warmup_steps': 0, 'n_ppo_epoch_per_rollout': 1, 'kl_threshold': 10.0, 'clip_grad': False, 'max_grad_norm': 0.5, 'seed': 42, 'cuda_deterministic': True}, 'logging': {'run_name': 'FG_vectorRL_sep_rew_const_lr_5e-5_temp_10_decoder_head', 'wandb_log': True, 'wandb_entity': 'rl-lang-fb', 'wandb_project': 'FGHF_Vector_RL_Decoder_head', 'log_interval': 1, 'save_dir': './tasks/qa_feedback/model_outputs/FG_vectorRL_sep_rew_const_lr_5e-5_temp_10_decoder_head'}}
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_init.py:init():596] starting backend
2024-02-25 06:55:03,752 INFO    MainThread:15661 [wandb_init.py:init():600] setting up manager
2024-02-25 06:55:03,757 INFO    MainThread:15661 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-02-25 06:55:03,765 INFO    MainThread:15661 [wandb_init.py:init():606] backend started and connected
2024-02-25 06:55:03,772 INFO    MainThread:15661 [wandb_init.py:init():703] updated telemetry
2024-02-25 06:55:03,839 INFO    MainThread:15661 [wandb_init.py:init():736] communicating run to backend with 60.0 second timeout
2024-02-25 06:55:03,991 INFO    MainThread:15661 [wandb_run.py:_on_init():2176] communicating current version
2024-02-25 06:55:04,066 INFO    MainThread:15661 [wandb_run.py:_on_init():2185] got version response upgrade_message: "wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-02-25 06:55:04,066 INFO    MainThread:15661 [wandb_init.py:init():787] starting run threads in backend
2024-02-25 06:55:04,153 INFO    MainThread:15661 [wandb_run.py:_console_start():2155] atexit reg
2024-02-25 06:55:04,153 INFO    MainThread:15661 [wandb_run.py:_redirect():2010] redirect: SettingsConsole.WRAP_RAW
2024-02-25 06:55:04,154 INFO    MainThread:15661 [wandb_run.py:_redirect():2075] Wrapping output streams.
2024-02-25 06:55:04,154 INFO    MainThread:15661 [wandb_run.py:_redirect():2100] Redirects installed.
2024-02-25 06:55:04,155 INFO    MainThread:15661 [wandb_init.py:init():828] run started, returning control to user process
2024-02-25 06:55:14,546 WARNING MsgRouterThr:15661 [router.py:message_loop():77] message_loop has been closed
