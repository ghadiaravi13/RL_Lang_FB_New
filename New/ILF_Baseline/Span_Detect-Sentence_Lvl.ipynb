{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1874918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "import plotly.express as px\n",
    "from nltk import tokenize\n",
    "import itertools\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143c08f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/jupyter/Ravi_new/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt',download_dir='/home/jupyter/Ravi_new/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d431aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3cab55",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86059d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    new_df = []#pd.DataFrame(columns=['id','prompt','gen_text','error','feedback','severity','text_before_span','span','text_after_span'])\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(df)),desc='unrolling data'):\n",
    "        id = df.loc[i]['id']\n",
    "        prompt = df.loc[i]['prompt']\n",
    "        gen_text = df.loc[i]['generation']#.replace(u'\\xa0', u' ').replace(u'  ', u' ')\n",
    "        feedbacks = eval(df.loc[i]['responses'])\n",
    "\n",
    "        for response in feedbacks:\n",
    "            if len(response)==0:\n",
    "                continue\n",
    "            for r in response:\n",
    "\n",
    "                error = r[0]\n",
    "                feedback = r[1].replace(\"_SEP_\",\",\").replace(\"_QUOTE_\",'\"')\n",
    "                severity = r[2]\n",
    "                beg = r[3]\n",
    "                end = r[4]\n",
    "\n",
    "                span = gen_text[beg:end]\n",
    "                \n",
    "                dic = {\"id\":id,\n",
    "                      \"prompt\":prompt,\n",
    "                      \"gen_text\":gen_text,\n",
    "                      \"error\":error,\n",
    "                      \"feedback\":feedback,\n",
    "                      \"severity\":severity,\n",
    "                      \"span_beg\":beg,\n",
    "                      \"span_end\":end,\n",
    "                      \"span\":span}\n",
    "\n",
    "                new_df.append(dic)\n",
    "\n",
    "    return pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59508c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = flatten_data('../grouped_data.csv')\n",
    "\n",
    "language_errors = ['Grammar_Usage', 'Off-prompt', 'Redundant', 'Self-contradiction', 'Incoherent']\n",
    "data = data[data['error'].isin(language_errors)]\n",
    "# data = data[data['severity']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26adfdc5-56d0-4261-8c50-0edffe9a937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['span_len'] = data['span'].apply(lambda x: len(x))\n",
    "#px.histogram(data['span_len'],nbins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['span_len']>20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14358482",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['span_len']>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c25bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gen_sentences'] = data['gen_text'].apply(lambda x: tokenize.sent_tokenize(x))\n",
    "data['span_is_sentence'] = [1 if x in y else 0 for x,y in zip(data['span'],data['gen_sentences'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e00cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['span_is_sentence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 392\n",
    "#data.loc[i]['gen_sentences'] = [s.strip() for s in data.loc[i]['gen_sentences']]\n",
    "s = \" \".join(data.iloc[i]['gen_sentences'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[i]['gen_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b44352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.iloc[i]['span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[i][['span_beg','span_end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[data.iloc[i]['span_beg']:data.iloc[i]['span_end']]==data.iloc[i]['span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ecee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check to see if the above technique is working fine for most data points\n",
    "data['tech_works'] = [\" \".join(data.iloc[i]['gen_sentences'])[data.iloc[i]['span_beg']:data.iloc[i]['span_end']] == data.iloc[i]['span'] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tech_works'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['tech_works']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9757442",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757633d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_err_sentence(sentences,span_beg,span_end,multi_class=False,error_type=None):\n",
    "    \n",
    "    output = []\n",
    "    total_len = sum([len(s) for s in sentences]) + len(sentences) - 1 #total sentences length + (sentences-1) spaces\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    if multi_class:\n",
    "        label = error_type+1\n",
    "    else:\n",
    "        label = 1\n",
    "    \n",
    "    for s in sentences:\n",
    "        if idx>=span_beg and idx<=span_end:\n",
    "            output.append(label)\n",
    "        elif idx+len(s)>=span_beg and idx+len(s)<=span_end:\n",
    "            output.append(label)\n",
    "        elif idx<=span_beg and idx+len(s)>=span_end:\n",
    "            output.append(label)\n",
    "        else:\n",
    "            output.append(0)\n",
    "        \n",
    "        idx += len(s)+1\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 101\n",
    "data.iloc[i]['gen_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284906da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[i]['span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa84269",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_err_sentence(data.iloc[i]['gen_sentences'],data.iloc[i]['span_beg'],data.iloc[i]['span_end'],multi_class=True,error_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42fce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3da605",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_MAP = {'Redundant':0,\n",
    "             'Off-prompt':1,\n",
    "             'Grammar_Usage':2,\n",
    "             'Incoherent':3,\n",
    "             'Self-contradiction':4,\n",
    "             'Needs_Google':5,\n",
    "             'Technical_Jargon':6,\n",
    "             'Commonsense':7,\n",
    "             'Encyclopedic':8,\n",
    "             'Bad_Math':9}\n",
    "\n",
    "INV_ERROR_MAP = {v:k for k,v in ERROR_MAP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e20fed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0174405574798584,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aca63eb93b4600a5bd227d90eb8138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return se #F.normalize(se, p=2, dim=1)\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "bart_chkpt = 'meta-llama/Llama-2-7b-chat-hf' #'decapoda-research/llama-13b-hf-int8'#'sentence-transformers/all-MiniLM-L6-v2' #'SpanBERT/spanbert-large-cased'# #'sentence-transformers/all-distilroberta-v1'\n",
    "tokenizer = LlamaTokenizer.from_pretrained(bart_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')#'roberta-base'\n",
    "bert_model = AutoModelForCausalLM.from_pretrained(bart_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')#, cache_dir='/home/jupyter/Ravi/HF_Cache/')\n",
    "bert_model = bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da11f3-6dd9-4449-b154-63e5167739c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adf2f755-e842-4e89-aed5-9752b3224f12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.4565, device='cuda:0'), tensor(0.7584, device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "\n",
    "ctxt = \"Hey, how are you doing?\"\n",
    "r1 = \"I'm doing fine.\"\n",
    "r2 = \"I'm doing fine. I'm doing fine. I'm doing fine. I'm doing fine. I'm doing fine.\"\n",
    "\n",
    "# ctxt = 'Hey, how are you doing?'\n",
    "# r1 = 'I am fine.'\n",
    "# r2 = 'I am fine. I am fine. I am fine.'\n",
    "\n",
    "tok_ctxt = tokenizer(ctxt, add_special_tokens=False)\n",
    "tok_pad = [-100]*len(tok_ctxt['input_ids'][:])\n",
    "tok_r1 = tokenizer(r1, add_special_tokens=False)\n",
    "tok_r2 = tokenizer(r2, add_special_tokens=False)\n",
    "\n",
    "#can use a stack structure over response and loop over it until empty to compute loss for each token in response\n",
    "\n",
    "with torch.no_grad():\n",
    "    out1 = bert_model(input_ids=torch.tensor(tok_ctxt.input_ids+tok_r1.input_ids[:]).unsqueeze(0).to('cuda:0'),\n",
    "                      labels=torch.tensor(tok_pad+tok_r1.input_ids).unsqueeze(0).to('cuda:0'))\n",
    "    out2 = bert_model(input_ids=torch.tensor(tok_ctxt.input_ids+tok_r2.input_ids[:]).unsqueeze(0).to('cuda:0'),\n",
    "                      labels=torch.tensor(tok_pad+tok_r2.input_ids).unsqueeze(0).to('cuda:0'))\n",
    "out1.loss, out2.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b8711-8b35-4865-aacb-c0593f8cbf65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer(ctxt, add_special_tokens=False), tokenizer(r1, add_special_tokens=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5701814-dfff-4dc6-be01-094755b2807f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out1.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4424d-a418-44f0-bcb0-53d818fa441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.bos_token,tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63716d3-af00-42ea-9590-6dc3b71e3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336ede0-3a67-4a94-8d30-ee2fee9bc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tokenizer('Hey there how are you doing?',return_length=True,add_special_tokens=True,padding='max_length',max_length=20).attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class scarecrow_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,max_length=1024,MULTI_CLASS=False):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.data = []\n",
    "        \n",
    "        for i in tqdm.tqdm(range(len(self.df)),desc='vectorizing..'):\n",
    "            \n",
    "            label_err_sent = label_err_sentence(self.df.iloc[i]['gen_sentences'],self.df.iloc[i]['span_beg'],self.df.iloc[i]['span_end'],multi_class=MULTI_CLASS,error_type=ERROR_MAP[self.df.iloc[i]['error']])\n",
    "            \n",
    "            for j,s in enumerate(self.df.iloc[i]['gen_sentences']):\n",
    "                d = {}\n",
    "                d['id'] = torch.tensor(self.df.iloc[i]['id'])\n",
    "                d['error'] = torch.tensor(ERROR_MAP[self.df.iloc[i]['error']])\n",
    "                \n",
    "                tok_prompt = tokenizer(self.df.iloc[i]['prompt'],return_token_type_ids=True,add_special_tokens=False)\n",
    "                tok_gen_text = tokenizer(self.df.iloc[i]['gen_sentences'],return_token_type_ids=True,add_special_tokens=False)\n",
    "                \n",
    "                tok_input = [tokenizer.bos_token_id] + tok_prompt['input_ids'] + list(itertools.chain.from_iterable(tok_gen_text['input_ids'])) + [tokenizer.eos_token_id]\n",
    "                \n",
    "                if self.max_len - len(tok_input) < len(tok_gen_text['input_ids'][j]): ##the sentence of interest should fit after the prompt + gen_text for the model to have context\n",
    "                    continue\n",
    "                tok_sent_of_interest = tokenizer(s, add_special_tokens=False, max_length=self.max_len-len(tok_input), padding='max_length')\n",
    "                tok_input += tok_sent_of_interest['input_ids']\n",
    "                \n",
    "                feedback = 'This sentence looks good.' if label_err_sent[j]==0 else self.df.iloc[i]['feedback']\n",
    "                \n",
    "                tok_feedback = tokenizer(feedback, \n",
    "                                         return_token_type_ids=True, \n",
    "                                         add_special_tokens=True, \n",
    "                                         return_length=True,\n",
    "                                         max_length=self.max_len, \n",
    "                                         padding='max_length', \n",
    "                                         truncation='only_first')\n",
    "                                \n",
    "                d['input'] = torch.LongTensor(tok_input)\n",
    "                d['feedback'] = torch.LongTensor(tok_feedback['input_ids'])\n",
    "                d['index'] = torch.tensor(sum(tok_feedback.attention_mask)-1)\n",
    "                d['class'] = torch.tensor(label_err_sent[j])\n",
    "                \n",
    "                self.data.append(d)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f92098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66661eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids , test_ids = train_test_split(data.index,test_size=0.1,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18960bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , test_df = data.loc[train_ids], data.loc[test_ids]\n",
    "train_df , valid_df = train_df.iloc[:int(0.9*len(train_df))], train_df.iloc[int(0.9*len(train_df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd9b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = scarecrow_dataset(train_df,MULTI_CLASS=False)\n",
    "valid_dataset = scarecrow_dataset(valid_df,MULTI_CLASS=False)\n",
    "test_dataset  = scarecrow_dataset(test_df,MULTI_CLASS=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8183b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DL = DataLoader(train_dataset,batch_size=10,shuffle=True)\n",
    "valid_DL = DataLoader(valid_dataset,batch_size=10,shuffle=True)\n",
    "test_DL = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde7661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(bart_chkpt).to(device)\n",
    "with torch.no_grad():\n",
    "    for b in train_DL:\n",
    "        print(b['index'].shape)\n",
    "        output = bart_model(input_ids=b['input'].to(device),\n",
    "                            decoder_input_ids=b['feedback'][:,:-1].to(device),\n",
    "                            labels=b['feedback'][:,1:].to(device),\n",
    "                            output_hidden_states=True).loss\n",
    "        print(output)\n",
    "        break\n",
    "del bart_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae9e4e",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc942de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class binary_classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,bart_chkpt='facebook/bart-base',inp_dim=768,hidden_dims=None,num_classes=2,use_norm=False,do_softmax=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bart_model = BartForConditionalGeneration.from_pretrained(bart_chkpt)\n",
    "        \n",
    "#         self.num_classes = num_classes\n",
    "        \n",
    "#         self.use_norm = use_norm\n",
    "#         self.inp_layer = nn.Linear(inp_dim,hidden_dims[0])\n",
    "\n",
    "#         hidden_layers = []\n",
    "#         for i in range(len(hidden_dims)-1):\n",
    "#             hidden_layers.append(nn.Linear(hidden_dims[i],hidden_dims[i+1]))\n",
    "#             hidden_layers.append(nn.Dropout(p=0.2))\n",
    "#             hidden_layers.append(nn.ReLU())\n",
    "#         self.layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "#         self.out_layer = nn.Linear(hidden_dims[-1],num_classes)\n",
    "        \n",
    "#         self.do_softmax = do_softmax\n",
    "        \n",
    "    \n",
    "    def forward(self,inp,ref,labels):\n",
    "        y = self.bart_model(input_ids=inp,decoder_input_ids=ref,labels=labels)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier,train_dl,valid_dl,epochs,optimizer,PATIENCE=20,save_dir=None):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    classifier.train()\n",
    "    \n",
    "    loss_acc = 0\n",
    "    num_batches = 0\n",
    "    total_steps = 0\n",
    "    best_valid_loss = np.inf\n",
    "    patience = PATIENCE\n",
    "    \n",
    "    train_loss_arr,valid_loss_arr = [],[]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    classifier.zero_grad()\n",
    "    \n",
    "    for E in range(epochs):\n",
    "        \n",
    "        for b in train_dl:\n",
    "            \n",
    "            y = classifier(b['input'].to(device),b['feedback'][:,:-1].to(device),b['feedback'][:,1:].to(device))\n",
    "            loss = y.loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_acc += loss.item()\n",
    "            num_batches += 1\n",
    "            total_steps += 1\n",
    "            \n",
    "            train_loss_arr.append(loss_acc/num_batches)\n",
    "            \n",
    "            if total_steps%100==0:\n",
    "                print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "            \n",
    "        #print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "        \n",
    "        torch.save({'model_state':classifier.state_dict(),\n",
    "                    'optimizer':optimizer.state_dict(),\n",
    "                    'epoch':E},\n",
    "                    f\"{save_dir}/Epoch_{E}_model_chkpt.pth.tar\")\n",
    "        \n",
    "        valid_loss = validate(classifier,valid_dl)\n",
    "        valid_loss_arr.append(valid_loss/len(valid_dl))\n",
    "        \n",
    "        if valid_loss<best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            patience = PATIENCE\n",
    "            \n",
    "            torch.save({'model_state':classifier.state_dict(),\n",
    "                        'optimizer':optimizer.state_dict(),\n",
    "                        'epoch':E},\n",
    "                        f\"{save_dir}/best_model_chkpt.pth.tar\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            print(f\"REDUCING PATIENCE...{patience}\")\n",
    "\n",
    "        if patience<=0:\n",
    "            print(\"RUNNING OUT OF PATIENCE... TERMINATING\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "    return train_loss_arr,valid_loss_arr\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe52a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(classifier,valid_dl):\n",
    "    \n",
    "    classifier.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for b in valid_dl:\n",
    "            y = classifier(b['input'].to(device),b['feedback'][:,:-1].to(device),b['feedback'][:,1:].to(device))\n",
    "            loss = y.loss\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    print(\"Validation Loss:\",valid_loss)\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129e854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = binary_classifier(bart_chkpt=bart_chkpt, inp_dim=768, hidden_dims=[768,256], num_classes=2, use_norm=True)\n",
    "classifier.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8e464-457a-4586-ab84-ba5bad128ec5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run if wish to freeze bert, finetune clf head\n",
    "classifier.load_state_dict(torch.load('TempFB_BART_1/best_model_chkpt.pth.tar')['model_state'])\n",
    "classifier.bert_model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e14ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(classifier.parameters(),lr=1e-5)\n",
    "\n",
    "save_dir = 'GenFB_BART_chkpts_1'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "train_loss,valid_loss = train(classifier,train_DL,valid_DL,50,optimizer,PATIENCE=5,save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9498e54-61e3-45eb-a791-d146b6f355ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "model = classifier.bart_model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b in test_DL:\n",
    "        gen = model.generate(b['input'].to(device))\n",
    "        print('\\n---------------------------------\\nContext: ',tokenizer.decode(b['input'][0],skip_special_tokens=True),'\\n\\n')\n",
    "        print('Human Feedback: ',tokenizer.decode(b['feedback'][0],skip_special_tokens=True),'\\n\\n')\n",
    "        print('Generated Feedback: ',tokenizer.decode(gen[0],skip_special_tokens=True),'\\n--------------------------------\\n')\n",
    "        i += 1\n",
    "        if i>50: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import precision_recall as PR\n",
    "from torchmetrics.classification import BinaryJaccardIndex as JI\n",
    "\n",
    "#bji = JI().to('cuda:0')\n",
    "\n",
    "def test(classifier,test_dl,binary=False,chkpt=None):\n",
    "    \n",
    "    P = []\n",
    "    R = []\n",
    "    acc = 0\n",
    "    gt,preds = [],[]\n",
    "    error_type = []\n",
    "#     JIdx = []\n",
    "    \n",
    "    if chkpt!=None:\n",
    "        classifier.load_state_dict(torch.load(chkpt)['model_state'])\n",
    "    classifier.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b in tqdm_notebook(test_dl):\n",
    "\n",
    "            logits = classifier(b['input'].to(device),b['feedback'].to(device),b['index'])\n",
    "#             print(logits)\n",
    "#             break\n",
    "            out = logits.argmax(dim=-1)\n",
    "            gl = b['class']\n",
    "            if binary:\n",
    "                out = torch.clamp(out,max=1)\n",
    "                gl = torch.clamp(gl,max=1)\n",
    "            #print(out)\n",
    "            gt.append(gl.item())\n",
    "            preds.append(out.item())\n",
    "            if out.item()==gl.item():\n",
    "                acc+=1\n",
    "            p_r = PR(preds=logits, target=gl.to(device))\n",
    "\n",
    "\n",
    "            #JIdx.append(ji.item())\n",
    "            P.append(p_r[0].item())\n",
    "            R.append(p_r[1].item())\n",
    "            error_type.append(INV_ERROR_MAP[b['error'].item()])\n",
    "            #print(p_r)\n",
    "    \n",
    "    return P,R,acc,gt,preds,error_type#acc/len(test_dl)\n",
    "\n",
    "def test_2(bin_classifier,multi_classifier,test_dl,bin_chkpt=None,multi_chkpt=None):\n",
    "    \n",
    "    P = []\n",
    "    R = []\n",
    "\n",
    "    acc = 0\n",
    "    gt,preds = [],[]\n",
    "    error_type = []\n",
    "\n",
    "    if bin_chkpt!=None:\n",
    "        bin_classifier.load_state_dict(torch.load(bin_chkpt)['model_state'])\n",
    "    if multi_chkpt!=None:\n",
    "        multi_classifier.load_state_dict(torch.load(multi_chkpt)['model_state'])\n",
    "\n",
    "    bin_classifier.eval()\n",
    "    multi_classifier.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b in tqdm_notebook(test_dl):\n",
    "\n",
    "            logits = bin_classifier(b['input'].to(device),b['sent_mask'].to(device))\n",
    "#             print(logits)\n",
    "#             break\n",
    "            out = logits.argmax(dim=-1)\n",
    "            gl = b['class']\n",
    "            if out.item()==1:\n",
    "                m_logits = multi_classifier(b['input'].to(device),b['sent_mask'].to(device))\n",
    "                m_out = m_logits.argmax(dim=-1)\n",
    "                gt.append(gl.item())\n",
    "                preds.append(m_out.item())\n",
    "                if m_out.item()==gl.item():\n",
    "                    acc+=1\n",
    "                error_type.append(INV_ERROR_MAP[b['error'].item()])\n",
    "            else:\n",
    "                #gl = torch.clamp(b['class'],min=6)\n",
    "                #out = torch.clamp(out,min=6)\n",
    "                gt.append(gl.item())\n",
    "                preds.append(out.item())\n",
    "                if out.item()==gl.item():\n",
    "                    acc+=1\n",
    "                error_type.append(INV_ERROR_MAP[b['error'].item()])\n",
    "\n",
    "\n",
    "            #print(out)\n",
    "#                 gt.append(gl.item())\n",
    "#                 preds.append(out.item())\n",
    "#                 if out.item()==gl.item():\n",
    "#                     acc+=1\n",
    "#                 #p_r = PR(preds=logits, target=gl.to(device))\n",
    "\n",
    "\n",
    "#                 #JIdx.append(ji.item())\n",
    "# #                 P.append(p_r[0].item())\n",
    "# #                 R.append(p_r[1].item())\n",
    "#                 error_type.append(INV_ERROR_MAP[b['error'].item()])\n",
    "#                 #print(p_r)\n",
    "\n",
    "    return _,_,acc,gt,preds,error_type#acc/len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P,R,acc,GT,PREDS,error_type = test_2(bin_classifier,multi_classifier,test_DL,bin_chkpt='classifier_chkpts_E2E_3/best_model_chkpt.pth.tar',multi_chkpt='classifier_chkpts_E2E_7/best_model_chkpt.pth.tar')\n",
    "P,R,acc,GT,PREDS,error_type = test(classifier,test_DL,binary=True,chkpt='FB_BART_chkpts_1/best_model_chkpt.pth.tar')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67523fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "out_df = pd.DataFrame()\n",
    "out_df['gt'] = GT\n",
    "out_df['preds'] = PREDS\n",
    "out_df['error_type'] = error_type\n",
    "\n",
    "for e in ERROR_MAP.keys():\n",
    "    gt = out_df[out_df['error_type']==e]['gt']\n",
    "    preds = out_df[out_df['error_type']==e]['preds']\n",
    "    print('\\nError:',e)\n",
    "    print('P:',precision_score(gt,preds,average='macro'))\n",
    "    print('R:',recall_score(gt,preds,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f646e0a-87a2-404f-b0a4-55e678c59ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = out_df['gt']\n",
    "preds = out_df['preds']\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(gt,preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316da0b3-7def-47f1-b43a-91341ad09dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(gt,preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f126a68-5804-4d7b-9066-ec9d87945ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(gt,preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc2279-91bd-4528-aee3-df2069e11665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\n",
    "cm = confusion_matrix(gt,preds)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4e758-a9e7-44e7-80f1-5fca0c61b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc/len(test_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ab9d8-3699-4339-ba60-2a48421e8a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
