{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccce523c-f7e2-459c-89d3-775573e476e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "dataset = load_dataset(\"McGill-NLP/feedbackQA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc95b78-59a0-49a5-aacc-c7a83a28c4b4",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626aded-95e1-47ec-bb47-59914940c8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_class = {'Excellent':3 , 'Acceptable':2 , 'Could be Improved':1, 'Bad': 0}\n",
    "\n",
    "def process_df(df):\n",
    "    df['list_feedback'] = df['feedback'].apply(lambda x: [ r + \"___\" + e for r,e in zip(x['rating'],x['explanation']) ])\n",
    "    df['sampled_feedback'] = df['list_feedback'].apply(lambda x: x[0].split(\"___\") if (x[0].split(\"___\")[0]!='Excellent' and x[0].split(\"___\")[0]!='Acceptable') else (x[1].split(\"___\") if (x[1].split(\"___\")[0]!='Excellent' and x[1].split(\"___\")[0]!='Acceptable') else np.random.choice(x).split(\"___\")) )\n",
    "    df['rating_class'] = df['sampled_feedback'].apply(lambda x: rating_class[x[0]])\n",
    "    df['rating'] = df['sampled_feedback'].apply(lambda x: x[0])\n",
    "    df['explanation'] = df['sampled_feedback'].apply(lambda x: x[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ffa3d-fae5-45d9-89c6-899dba3982fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = process_df(pd.DataFrame(dataset['train']))\n",
    "val_df = process_df(pd.DataFrame(dataset['validation']))\n",
    "test_df = process_df(pd.DataFrame(dataset['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5935e0-80ea-4ec8-8e7c-3d7f63a3d1c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "bert_chkpt = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "model = AutoModelForCausalLM.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22efe18-53a9-4974-bb9b-182080220e0b",
   "metadata": {},
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208eaaf3-37eb-4833-94ca-9c5734910132",
   "metadata": {},
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd89391-527e-43b1-a74e-0547dc598993",
   "metadata": {
    "tags": []
   },
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3579a-84fd-42a7-bcf4-87201558fe11",
   "metadata": {},
   "source": [
    "train_df['answer'].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858fa93-3ecb-4fd5-909b-0672682e88e3",
   "metadata": {},
   "source": [
    "tokenizer('Hello, how are you doing?'+ f\" {tokenizer.eos_token} \" + \"Hemlooooo\",add_special_tokens=True,return_tensors='pt', return_length=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89006f7c-adce-48be-8dfb-87ec38529f83",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29210f9c-43b4-4fb0-97e9-feadbf3ed0c9",
   "metadata": {},
   "source": [
    "from nltk import tokenize as nltk_tokenizer\n",
    "len(nltk_tokenizer.sent_tokenize(train_df['answer'].loc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4b69b-5584-4d22-b379-4c004ec95847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "bert_chkpt = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "# model = AutoModelForCausalLM.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fa790-2c79-451e-a477-d26f1696527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class feedback_QA_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,tokenizer,max_length=2048):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        skipped = 0\n",
    "        \n",
    "        for i in range(len(self.df)):\n",
    "            \n",
    "            d = {}\n",
    "            if self.df.iloc[i]['rating_class']==3:\n",
    "                skipped += 1\n",
    "                continue\n",
    "                \n",
    "            prompt = \"I will give you a question, an initial answer to the question, and feedback critiquing that answer. Based on the feedback, provide a refined answer. Do NOT generate anything other than the refined answer.\"\n",
    "            question = self.df.iloc[i]['question']\n",
    "            answer = self.df.iloc[i]['answer']\n",
    "            feedback = self.df.iloc[i]['explanation']\n",
    "            \n",
    "            tok_input = self.tokenizer(f\"{prompt}\\nQuestion:{question}\\nAnswer:{answer}\\n\\nFeedback:{feedback}\\n\\nRefined answer: \",\n",
    "                                  add_special_tokens=True\n",
    "                                 )\n",
    "            if len(tok_input['input_ids']) > self.max_len:\n",
    "                skipped += 1\n",
    "                continue\n",
    "                \n",
    "\n",
    "            \n",
    "            PAD_LEN = self.max_len - len(tok_input['input_ids'])\n",
    "\n",
    "            d['input'] = tok_input['input_ids'] + [self.tokenizer.eos_token_id]*PAD_LEN\n",
    "            d['attention_mask'] = tok_input['attention_mask'] + [0]*PAD_LEN\n",
    "            d['id'] = i\n",
    "\n",
    "            for k in d.keys():\n",
    "                d[k] = torch.tensor(d[k])\n",
    "\n",
    "            self.data.append(d)\n",
    "        # print(f'skipped: {skipped}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74550fb6-8a4a-4773-a0fd-45a3cd6c4961",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "train_dataset = feedback_QA_dataset(train_df)\n",
    "valid_dataset = feedback_QA_dataset(val_df)\n",
    "test_dataset = feedback_QA_dataset(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f4dbc-b8e0-4e41-8045-d93a03b79ce2",
   "metadata": {},
   "source": [
    "train_DL = DataLoader(train_dataset,batch_size=3,shuffle=False)\n",
    "valid_DL = DataLoader(valid_dataset,batch_size=3,shuffle=False)\n",
    "test_DL = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661223bb-76b9-4f37-9c6d-8a657d8f18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def refine(bert_chkpt,val_df):#,Accelerator):\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "    # accelerator = Accelerator()\n",
    "    device = 'cuda:1'#accelerator.device\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "    model = AutoModelForCausalLM.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "    \n",
    "    train_dataset = feedback_QA_dataset(train_df,tokenizer)\n",
    "    valid_dataset = feedback_QA_dataset(val_df,tokenizer)\n",
    "    test_dataset = feedback_QA_dataset(test_df,tokenizer)\n",
    "\n",
    "    train_DL = DataLoader(train_dataset,batch_size=3,shuffle=False)\n",
    "    valid_DL = DataLoader(valid_dataset,batch_size=3,shuffle=False)\n",
    "    test_DL = DataLoader(test_dataset,batch_size=1,shuffle=False)\n",
    "    \n",
    "    # model,valid_DL = accelerator.prepare(model,valid_DL)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for b in valid_DL:\n",
    "            out = model.generate(inputs=b['input'].to(device),\n",
    "                                 attention_mask=b['attention_mask'].to(device),\n",
    "                                 max_new_tokens=500,\n",
    "                                 num_return_sequences=1,\n",
    "                                 do_sample=True\n",
    "                                )\n",
    "            \n",
    "            l = [a.split('Refined answer: ')[1].replace('</s>','') for a in tokenizer.batch_decode(out)]\n",
    "            val_df['refined_answer'].loc[b['id'].tolist()] = l\n",
    "            # break\n",
    "    return val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a84f1-5705-4dde-aaec-92d3771c58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450e450-b84b-4099-bbda-f6eaebf4558d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df['refined_answer'] = ['None']*len(val_df)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "# from accelerate import notebook_launcher\n",
    "accelerate.notebook_launcher(refine,(bert_chkpt,val_df,accelerate.Accelerator),num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130696e2-8313-4ef1-9b28-8a794cd544cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'#accelerator.device\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "model = AutoModelForCausalLM.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "\n",
    "train_dataset = feedback_QA_dataset(train_df,tokenizer)\n",
    "valid_dataset = feedback_QA_dataset(val_df,tokenizer)\n",
    "test_dataset = feedback_QA_dataset(test_df,tokenizer)\n",
    "\n",
    "train_DL = DataLoader(train_dataset,batch_size=3,shuffle=False)\n",
    "valid_DL = DataLoader(valid_dataset,batch_size=3,shuffle=False)\n",
    "test_DL = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d82b27-cc4e-4350-bdac-84a2bfeb7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df1 = pd.read_csv('val_refined.csv')\n",
    "val_df2 = pd.read_csv('val_refined_old.csv')\n",
    "val_df1['refined_answer_3'] = val_df2['refined_answer'].copy()\n",
    "val_df1.loc[1][['question','answer','explanation','refined_answer_0','refined_answer_1','refined_answer_2','refined_answer_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19540bc5-26a6-4065-ad95-0098eef67e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>feedback</th>\n",
       "      <th>list_feedback</th>\n",
       "      <th>sampled_feedback</th>\n",
       "      <th>rating_class</th>\n",
       "      <th>rating</th>\n",
       "      <th>explanation</th>\n",
       "      <th>refined_answer_0</th>\n",
       "      <th>refined_answer_1</th>\n",
       "      <th>refined_answer_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Could be Improved'],...</td>\n",
       "      <td>['Excellent___Has a link to detailed informati...</td>\n",
       "      <td>['Could be Improved', 'This answer provides a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>This answer provides a link for job searches, ...</td>\n",
       "      <td>\\n\\nTo get help finding a job, you can visit y...</td>\n",
       "      <td>\\nHow do I get help finding a job?\\nThere are ...</td>\n",
       "      <td>\\nTo get help finding a job, you can visit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information for job see...</td>\n",
       "      <td>{'rating': ['Excellent', 'Excellent'], 'explan...</td>\n",
       "      <td>['Excellent___A link to a job search website i...</td>\n",
       "      <td>['Excellent', 'A link to a job search website ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A link to a job search website is included, as...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How do I get help finding a job?</td>\n",
       "      <td>Coronavirus (COVID-19) information and support...</td>\n",
       "      <td>{'rating': ['Bad', 'Acceptable'], 'explanation...</td>\n",
       "      <td>['Bad___Talks about tax credits for businesses...</td>\n",
       "      <td>['Bad', 'Talks about tax credits for businesse...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Talks about tax credits for businesses that hi...</td>\n",
       "      <td>\\nThere are several ways to get help finding a...</td>\n",
       "      <td>\\nThere are several ways to get help finding a...</td>\n",
       "      <td>\\nThere are several ways to get help finding a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nWorking holiday ma...</td>\n",
       "      <td>{'rating': ['Could be Improved', 'Acceptable']...</td>\n",
       "      <td>[\"Could be Improved___Answer is about Working ...</td>\n",
       "      <td>['Could be Improved', \"Answer is about Working...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could be Improved</td>\n",
       "      <td>Answer is about Working Holiday Makers, but do...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>If I am in Australia on a worker holiday marke...</td>\n",
       "      <td>Frequently Asked Questions\\nCOVID-19 Pandemic ...</td>\n",
       "      <td>{'rating': ['Bad', 'Could be Improved'], 'expl...</td>\n",
       "      <td>[\"Bad___Discusses pandemic visas. Doesn't ment...</td>\n",
       "      <td>['Bad', \"Discusses pandemic visas. Doesn't men...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Discusses pandemic visas. Doesn't mention the ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>5655</td>\n",
       "      <td>Can you explain to me what self-care is</td>\n",
       "      <td>Q&amp;A: Self-care interventions for sexual and re...</td>\n",
       "      <td>{'rating': ['Excellent', 'Excellent'], 'explan...</td>\n",
       "      <td>['Excellent___This answer explains what self c...</td>\n",
       "      <td>['Excellent', 'This answer explains what self ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>This answer explains what self care is directly.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>5656</td>\n",
       "      <td>Can you explain to me what self-care is</td>\n",
       "      <td>Q&amp;A: Self-care interventions for sexual and re...</td>\n",
       "      <td>{'rating': ['Excellent', 'Bad'], 'explanation'...</td>\n",
       "      <td>[\"Excellent___This answer talks about what sel...</td>\n",
       "      <td>['Bad', 'This does not answer the question. Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>This does not answer the question. This answer...</td>\n",
       "      <td>\\nSelf-care is the practice of taking care of ...</td>\n",
       "      <td>\\nSelf-care is an essential aspect of maintain...</td>\n",
       "      <td>answer: Self-care is the practice of taking c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>5657</td>\n",
       "      <td>Is it safe for me to manually replace my IUD a...</td>\n",
       "      <td>Q&amp;A: Contraception/Family planning and COVID-1...</td>\n",
       "      <td>{'rating': ['Bad', 'Bad'], 'explanation': ['Do...</td>\n",
       "      <td>['Bad___Does not address whether or not replac...</td>\n",
       "      <td>['Bad', 'Does not address whether or not repla...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Does not address whether or not replacing an I...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>5658</td>\n",
       "      <td>Is it safe for me to manually replace my IUD a...</td>\n",
       "      <td>Q&amp;A: Infection prevention and control for heal...</td>\n",
       "      <td>{'rating': ['Bad', 'Bad'], 'explanation': ['Do...</td>\n",
       "      <td>['Bad___Does not answer whether or not IUD can...</td>\n",
       "      <td>['Bad', 'Does not answer whether or not IUD ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Does not answer whether or not IUD can be safe...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>5659</td>\n",
       "      <td>Is it safe for me to manually replace my IUD a...</td>\n",
       "      <td>Q&amp;A: Contraception/Family planning and COVID-1...</td>\n",
       "      <td>{'rating': ['Excellent', 'Excellent'], 'explan...</td>\n",
       "      <td>['Excellent___Answers whether or not an IUD ca...</td>\n",
       "      <td>['Excellent', 'This information answers the qu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>This information answers the question directly...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5664 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           question  \\\n",
       "0             0                   How do I get help finding a job?   \n",
       "1             1                   How do I get help finding a job?   \n",
       "2             2                   How do I get help finding a job?   \n",
       "3             3  If I am in Australia on a worker holiday marke...   \n",
       "4             4  If I am in Australia on a worker holiday marke...   \n",
       "...         ...                                                ...   \n",
       "5659       5655            Can you explain to me what self-care is   \n",
       "5660       5656            Can you explain to me what self-care is   \n",
       "5661       5657  Is it safe for me to manually replace my IUD a...   \n",
       "5662       5658  Is it safe for me to manually replace my IUD a...   \n",
       "5663       5659  Is it safe for me to manually replace my IUD a...   \n",
       "\n",
       "                                                 answer  \\\n",
       "0     Coronavirus (COVID-19) information for job see...   \n",
       "1     Coronavirus (COVID-19) information for job see...   \n",
       "2     Coronavirus (COVID-19) information and support...   \n",
       "3     Frequently Asked Questions\\nWorking holiday ma...   \n",
       "4     Frequently Asked Questions\\nCOVID-19 Pandemic ...   \n",
       "...                                                 ...   \n",
       "5659  Q&A: Self-care interventions for sexual and re...   \n",
       "5660  Q&A: Self-care interventions for sexual and re...   \n",
       "5661  Q&A: Contraception/Family planning and COVID-1...   \n",
       "5662  Q&A: Infection prevention and control for heal...   \n",
       "5663  Q&A: Contraception/Family planning and COVID-1...   \n",
       "\n",
       "                                               feedback  \\\n",
       "0     {'rating': ['Excellent', 'Could be Improved'],...   \n",
       "1     {'rating': ['Excellent', 'Excellent'], 'explan...   \n",
       "2     {'rating': ['Bad', 'Acceptable'], 'explanation...   \n",
       "3     {'rating': ['Could be Improved', 'Acceptable']...   \n",
       "4     {'rating': ['Bad', 'Could be Improved'], 'expl...   \n",
       "...                                                 ...   \n",
       "5659  {'rating': ['Excellent', 'Excellent'], 'explan...   \n",
       "5660  {'rating': ['Excellent', 'Bad'], 'explanation'...   \n",
       "5661  {'rating': ['Bad', 'Bad'], 'explanation': ['Do...   \n",
       "5662  {'rating': ['Bad', 'Bad'], 'explanation': ['Do...   \n",
       "5663  {'rating': ['Excellent', 'Excellent'], 'explan...   \n",
       "\n",
       "                                          list_feedback  \\\n",
       "0     ['Excellent___Has a link to detailed informati...   \n",
       "1     ['Excellent___A link to a job search website i...   \n",
       "2     ['Bad___Talks about tax credits for businesses...   \n",
       "3     [\"Could be Improved___Answer is about Working ...   \n",
       "4     [\"Bad___Discusses pandemic visas. Doesn't ment...   \n",
       "...                                                 ...   \n",
       "5659  ['Excellent___This answer explains what self c...   \n",
       "5660  [\"Excellent___This answer talks about what sel...   \n",
       "5661  ['Bad___Does not address whether or not replac...   \n",
       "5662  ['Bad___Does not answer whether or not IUD can...   \n",
       "5663  ['Excellent___Answers whether or not an IUD ca...   \n",
       "\n",
       "                                       sampled_feedback rating_class  \\\n",
       "0     ['Could be Improved', 'This answer provides a ...            1   \n",
       "1     ['Excellent', 'A link to a job search website ...            3   \n",
       "2     ['Bad', 'Talks about tax credits for businesse...            0   \n",
       "3     ['Could be Improved', \"Answer is about Working...            1   \n",
       "4     ['Bad', \"Discusses pandemic visas. Doesn't men...            0   \n",
       "...                                                 ...          ...   \n",
       "5659  ['Excellent', 'This answer explains what self ...            3   \n",
       "5660  ['Bad', 'This does not answer the question. Th...            0   \n",
       "5661  ['Bad', 'Does not address whether or not repla...            0   \n",
       "5662  ['Bad', 'Does not answer whether or not IUD ca...            0   \n",
       "5663  ['Excellent', 'This information answers the qu...            3   \n",
       "\n",
       "                 rating                                        explanation  \\\n",
       "0     Could be Improved  This answer provides a link for job searches, ...   \n",
       "1             Excellent  A link to a job search website is included, as...   \n",
       "2                   Bad  Talks about tax credits for businesses that hi...   \n",
       "3     Could be Improved  Answer is about Working Holiday Makers, but do...   \n",
       "4                   Bad  Discusses pandemic visas. Doesn't mention the ...   \n",
       "...                 ...                                                ...   \n",
       "5659          Excellent   This answer explains what self care is directly.   \n",
       "5660                Bad  This does not answer the question. This answer...   \n",
       "5661                Bad  Does not address whether or not replacing an I...   \n",
       "5662                Bad  Does not answer whether or not IUD can be safe...   \n",
       "5663          Excellent  This information answers the question directly...   \n",
       "\n",
       "                                       refined_answer_0  \\\n",
       "0     \\n\\nTo get help finding a job, you can visit y...   \n",
       "1                                                  None   \n",
       "2     \\nThere are several ways to get help finding a...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "5659                                               None   \n",
       "5660  \\nSelf-care is the practice of taking care of ...   \n",
       "5661                                               None   \n",
       "5662                                               None   \n",
       "5663                                               None   \n",
       "\n",
       "                                       refined_answer_1  \\\n",
       "0     \\nHow do I get help finding a job?\\nThere are ...   \n",
       "1                                                  None   \n",
       "2     \\nThere are several ways to get help finding a...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "5659                                               None   \n",
       "5660  \\nSelf-care is an essential aspect of maintain...   \n",
       "5661                                               None   \n",
       "5662                                               None   \n",
       "5663                                               None   \n",
       "\n",
       "                                       refined_answer_2  \n",
       "0     \\nTo get help finding a job, you can visit you...  \n",
       "1                                                  None  \n",
       "2     \\nThere are several ways to get help finding a...  \n",
       "3                                                  None  \n",
       "4                                                  None  \n",
       "...                                                 ...  \n",
       "5659                                               None  \n",
       "5660   answer: Self-care is the practice of taking c...  \n",
       "5661                                               None  \n",
       "5662                                               None  \n",
       "5663                                               None  \n",
       "\n",
       "[5664 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_refined.csv',keep_default_na=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9910fafe-7d78-4fc9-b29a-f21351a87617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n\\nTo get help finding a job, you can visit your local job center or contact a job search agency. They can provide you with personalized assistance, including resume building, interview preparation, and job placement. Additionally, many organizations offer online job boards and career resources that can help you find job opportunities. You can also consider reaching out to professional networks, such as industry associations or alumni groups, for job leads and advice.\\n\\n\\n\\n\\n<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "       '\\nHow do I get help finding a job?\\nThere are several ways to get help finding a job, including:\\n\\n1. Job search websites: Utilize online job search websites such as LinkedIn, Indeed, or Glassdoor to search for job openings and apply to positions that match your skills and experience.\\n2. Career counseling: Many organizations offer career counseling services to help job seekers identify their strengths and weaknesses, and develop a plan to achieve their career goals.\\n3. Networking: Leverage your professional network to find job opportunities. Attend industry events, join professional organizations, and connect with former colleagues and classmates to learn about job openings.\\n4. Recruitment agencies: Consider working with recruitment agencies that specialize in your industry or job function. They can help match you with job openings and provide guidance on the application process.\\n5. Government job search resources: Utilize government job search resources such as USAJobs or State and Local Government Jobs to search for federal and state government job openings.\\nRemember, finding a job can be a challenging process, but with persistence and the right resources, you can land your dream job.<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "       '\\nTo get help finding a job, you can visit your local job center or employment agency for assistance. They can provide you with job listings, resume building workshops, and interview preparation tips. Additionally, many job centers and agencies offer online resources and job search tools to help you find employment opportunities. You can also search for job openings on reputable job boards or use professional networks such as LinkedIn to connect with potential employers.<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.replace('None',None).dropna(axis=0).loc[0][['refined_answer_0','refined_answer_1','refined_answer_2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292860c6-8a8f-49b0-a88b-1bc22f3ec6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df1[val_df1['rating_class']<3].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c584d-6899-4551-ac5d-fc62cfb9e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "model = AutoModelForCausalLM.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21036279-af25-4905-b914-7e0e42149563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda:1')\n",
    "model.eval()\n",
    "\n",
    "i=1394\n",
    "\n",
    "question = val_df1.loc[i]['question']\n",
    "answer = val_df1.loc[i]['answer']\n",
    "feedback = val_df1.loc[i]['explanation']\n",
    "r2 = val_df1.loc[i]['refined_answer_0'].replace('<unk>','').replace('\\n','')\n",
    "r0 = val_df1.loc[i]['refined_answer_1'].replace('<unk>','').replace('\\n','')\n",
    "r1 = val_df1.loc[i]['refined_answer_2'].replace('<unk>','').replace('\\n','')\n",
    "r3 = val_df1.loc[i]['refined_answer_3'].replace('<unk>','').replace('\\n','')\n",
    "\n",
    "prompt = f'I will give you a question, an initial answer, a feedback critquing that answer, and 4 different refined answers that try to incorporate the feedback. I want you to tell me, which of the four refined answers best incorporate the feedback. Strictly follow this format: if refined_answer_X is the best, just say, Best Answer: refined_answer_X. \\n Question: {question} \\n Answer: {answer} \\n Feedback: {feedback} \\n refined_answer_0: {r0} \\n refined_answer_1: {r1} \\n refined_answer_2: {r2} \\n refined_answer_3: {r3} \\n Best Answer: '\n",
    "\n",
    "inp = tokenizer(prompt,return_tensors='pt',add_special_tokens=True)['input_ids'].to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    out = model.generate(inp, max_new_tokens=50, do_sample=False, num_beams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce0021-70c8-4ad3-ada7-a1e6874ab022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbadf877-760e-4258-af5e-7c848d30a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda:1')\n",
    "model.eval()\n",
    "\n",
    "i=1394\n",
    "\n",
    "question = val_df1.loc[i]['question']\n",
    "answer = val_df1.loc[i]['answer']\n",
    "feedback = val_df1.loc[i]['explanation']\n",
    "r2 = val_df1.loc[i]['refined_answer_0'].replace('<unk>','').replace('\\n','')\n",
    "r0 = val_df1.loc[i]['refined_answer_1'].replace('<unk>','').replace('\\n','')\n",
    "r1 = val_df1.loc[i]['refined_answer_2'].replace('<unk>','').replace('\\n','')\n",
    "r3 = val_df1.loc[i]['refined_answer_3'].replace('<unk>','').replace('\\n','')\n",
    "\n",
    "prompt = f'I will give you a question, an initial answer, a feedback critquing that answer, and 2 different refined answers that try to incorporate the feedback. I want you to tell me, which of the two refined answers better incorporate the feedback. Strictly follow this format: if refined_answer_X is better, just say, Better Answer: refined_answer_X. \\n Question: {question} \\n Answer: {answer} \\n Feedback: {feedback} \\n refined_answer_0: {r2} \\n refined_answer_1: {r0} \\n Better Answer: '\n",
    "\n",
    "inp = tokenizer(prompt,return_tensors='pt',add_special_tokens=True)['input_ids'].to('cuda:1')\n",
    "with torch.no_grad():\n",
    "    out = model.generate(inp, max_new_tokens=50, do_sample=False, num_beams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d6eb2-5bf0-40a3-a444-bf22ad2773a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e563d3-e2e8-409b-aff4-fceff8b60141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model,valid_DL = accelerator.prepare(model,valid_DL)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "num_return_sequences = 2\n",
    "\n",
    "for i in range(num_return_sequences):\n",
    "    val_df[f'refined_answer_{i}'] = ['None']*len(val_df)\n",
    "with torch.no_grad():\n",
    "    for b in valid_DL:\n",
    "        out = model.generate(inputs=b['input'].to(device),\n",
    "                             attention_mask=b['attention_mask'].to(device),\n",
    "                             max_new_tokens=50,\n",
    "                             num_return_sequences=2,\n",
    "                             do_sample=True\n",
    "                            )\n",
    "        \n",
    "        l = [a.split('Refined answer: ')[1].replace('</s>','') for a in tokenizer.batch_decode(out)]\n",
    "        for i in range(num_return_sequences):\n",
    "            val_df[f'refined_answer_{i}'].loc[b['id'].tolist()] = l[i::num_return_sequences]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dca083-f34f-4766-81f0-6b8ee42c09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[6][['refined_answer_0','refined_answer_1']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edb53c-4135-4900-a97b-14ce9700113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0,1,2,3,4,5]\n",
    "l[2::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61cb9b-bfb0-47de-8c0b-d0a605b7a0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df = refine(bert_chkpt,val_df)\n",
    "val_df.to_csv('val_refined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c23e4-3ac9-46c4-9f62-8733698f73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d315680-59ec-4f8a-aa6d-c2a5181d95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa0c6b-ebc8-4083-808c-f777cb7039ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fe5d6-b6a8-413d-a09a-f7f205bcd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(out[2]).replace('</s>',''))#.replace('<unk>',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96c83d-155b-4a45-b5da-966ef050ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524eef71-2aad-4803-892f-01b0a6fa82de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return F.normalize(se, p=2, dim=1)\n",
    "\n",
    "j = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b in train_DL:\n",
    "        out = mean_pooling( model(input_ids=b['context_w_feedback'].to(device), attention_mask=b['context_w_feedback_attn'].to(device)) , b['feedback_pool_mask'].to(device))\n",
    "        print(out.shape)\n",
    "        print('----------------------------')\n",
    "        j+=1\n",
    "        if j>5:\n",
    "            break\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ed8bc-1d6e-47fa-bfbb-0f6b3b1d97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[[1,2,3,4,5],[6,7,8,9,0]]])\n",
    "t.repeat(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39373ab0-572f-42ec-8bee-d6945dd568bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, model_chkpt, device='cuda:0', inp_dim=768, hidden_dims=None, num_classes=4, use_norm=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.bert_model = AutoModel.from_pretrained(model_chkpt).to(device)\n",
    "        \n",
    "        self.use_norm = use_norm\n",
    "        self.inp_layer = nn.Linear(inp_dim,hidden_dims[0])\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            hidden_layers.append(nn.Linear(hidden_dims[i],hidden_dims[i+1]))\n",
    "            hidden_layers.append(nn.Dropout(p=0.2))\n",
    "            hidden_layers.append(nn.ReLU())\n",
    "        self.layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        self.out_layer = nn.Linear(hidden_dims[-1],num_classes)\n",
    "        \n",
    "    def mean_pooling(self,model_output,attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        se = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return se\n",
    "        \n",
    "    def forward(self, b):\n",
    "        y = self.mean_pooling( self.bert_model(input_ids=b['context_w_feedback'].to(self.device), attention_mask=b['context_w_feedback_attn'].to(self.device)),\n",
    "                               b['feedback_pool_mask'].to(self.device))\n",
    "        if self.use_norm:\n",
    "            y = F.normalize(y,p=2,dim=-1)\n",
    "        y = self.inp_layer(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.layers(y)\n",
    "        y = self.out_layer(y)\n",
    "        \n",
    "        return_dict = {}\n",
    "        \n",
    "        return_dict['logits'] = y\n",
    "        return_dict['class_probs'] = F.softmax(y,dim=-1)\n",
    "        return_dict['CE_loss'] = F.cross_entropy(y,b['rating_class'].to(self.device))\n",
    "        return return_dict\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1fcd9-7fb7-4557-a1ee-023591930420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier,train_dl,valid_dl,epochs,optimizer,PATIENCE=20,save_dir=None):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    classifier.train()\n",
    "    \n",
    "    loss_acc = 0\n",
    "    num_batches = 0\n",
    "    total_steps = 0\n",
    "    best_valid_loss = np.inf\n",
    "    patience = PATIENCE\n",
    "    \n",
    "    train_loss_arr,valid_loss_arr = [],[]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    classifier.zero_grad()\n",
    "    \n",
    "    for E in range(epochs):\n",
    "        \n",
    "        num_samples = 0\n",
    "        \n",
    "        for b in train_dl:\n",
    "            \n",
    "            y = classifier(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['CE_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_acc += loss.item()\n",
    "        \n",
    "            num_batches += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            train_loss_arr.append(loss_acc/num_batches)\n",
    "\n",
    "            if total_steps%100==0 and total_steps!=0:\n",
    "                print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "            \n",
    "        #print(\"Epoch:\",E,\"\\t\",\"Steps taken:\",total_steps,\"\\tLoss:\",loss_acc/num_batches)\n",
    "        \n",
    "        torch.save({'model_state':classifier.state_dict(),\n",
    "                    'optimizer':optimizer.state_dict(),\n",
    "                    'epoch':E},\n",
    "                    f\"{save_dir}/Epoch_{E}_model_chkpt.pth.tar\")\n",
    "        \n",
    "        valid_loss = validate(classifier,valid_dl)\n",
    "        valid_loss_arr.append(valid_loss/len(valid_dl))\n",
    "        \n",
    "        if valid_loss<best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            patience = PATIENCE\n",
    "            \n",
    "            torch.save({'model_state':classifier.state_dict(),\n",
    "                        'optimizer':optimizer.state_dict(),\n",
    "                        'epoch':E},\n",
    "                        f\"{save_dir}/best_model_chkpt.pth.tar\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            print(f\"REDUCING PATIENCE...{patience}\")\n",
    "\n",
    "        if patience<=0:\n",
    "            print(\"RUNNING OUT OF PATIENCE... TERMINATING\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "    return train_loss_arr,valid_loss_arr\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5931d-65fc-421d-8bf3-4bdb58b8b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(classifier,valid_dl):\n",
    "    \n",
    "    classifier.eval()\n",
    "    valid_loss = 0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for b in valid_dl:\n",
    "            y = classifier(b)\n",
    "                          # decoder_input_ids=b['feedback'].squeeze(1)[:,:-1].to(device),\n",
    "                          # decoder_attention_mask=b['feedback_attn'].squeeze(1)[:,:-1].to(device))\n",
    "            loss = y['CE_loss'] #F.cross_entropy(y.logits.permute(0,2,1), b['feedback'].squeeze(1)[:,1:].to(device), ignore_index=tokenizer.pad_token_id)\n",
    "            valid_loss += loss.item()\n",
    "            num_batches+=1\n",
    "            \n",
    "    print(\"Validation Loss:\",valid_loss/num_batches)\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114ae66-56d4-46de-a66e-c8311faa074f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "EPOCHS = 50\n",
    "FREEZE_BERT = False\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "# MPNet = AutoModel.from_pretrained(bert_chkpt).to(device)\n",
    "classifier_model = classifier(bert_chkpt,device=device,hidden_dims=[768,128], num_classes=4, use_norm=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12405b37-8101-433b-b5c7-6f373b484abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if FREEZE_BERT:\n",
    "    classifier_model.load_state_dict(torch.load('Rating_sent_MPNET_chkpts_1/best_model_chkpt.pth.tar')['model_state'])\n",
    "    classifier_model.bert_model.requires_grad_(False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(classifier_model.parameters(),lr=1e-4)\n",
    "\n",
    "save_dir = 'Rating_ctxt_FB_MPNET_chkpts_1'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "train_loss,valid_loss = train(classifier_model,\n",
    "                              train_DL,\n",
    "                              valid_DL,\n",
    "                              EPOCHS,\n",
    "                              optimizer,\n",
    "                              PATIENCE=5,\n",
    "                              save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91101fb6-ccc5-4b70-a781-f80306d79560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train_loss.json','w') as f:\n",
    "    json.dump(train_loss,f)\n",
    "\n",
    "with open('valid_loss.json','w') as f:\n",
    "    json.dump(valid_loss,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1438eb8-e8f1-41bd-ab9c-8c0ee15ab891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_ds = np.array(train_loss)[np.round(np.linspace(0, len(train_loss) - 1, len(valid_loss))).astype(int)]\n",
    "loss_df = pd.DataFrame({'train_loss':train_loss_ds , 'valid_loss':valid_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32161e3-1a96-4893-ac8a-5b567044334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import express as px\n",
    "px.line(loss_df,y=['train_loss','valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00229a87-1ae6-437a-b7fd-b5d9bac756d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DL = DataLoader(test_dataset,batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95aa46-fa36-4e08-9beb-38400ebddeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load('Rating_ctxt_FB_MPNET_chkpts_1/best_model_chkpt.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b9d00-0197-4bcc-be96-83e62d9c96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.load_state_dict(chkpt['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3a035-e5a3-49e4-bbf4-6a0699945e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "preds,gt = [],[]\n",
    "classifier_model.eval()\n",
    "with torch.no_grad():\n",
    "    for b in tqdm.tqdm(test_DL,desc='evaluating'):\n",
    "        out = classifier_model(b)\n",
    "        pred_labels = out['class_probs'].argmax(dim=-1).cpu().tolist()\n",
    "        gt_labels = b['rating_class'].tolist()\n",
    "        preds.extend(pred_labels)\n",
    "        gt.extend(gt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96357d85-64e1-4d7e-8eab-ee36d405bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\n",
    "cm = confusion_matrix(gt,preds,normalize='all')\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0bf9b-fa6f-44b1-8c67-19479faf6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076fa34-e8db-4702-8c36-118ff4185670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "print('Precision: ' , precision_score(gt,preds,average='macro'))\n",
    "print('Recall: ' , recall_score(gt,preds,average='macro'))\n",
    "print('Accuracy: ' , accuracy_score(gt,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107535f6-1c8b-4464-9d54-bede6445dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: ' , precision_score(gt,preds,average='micro'))\n",
    "print('Recall: ' , recall_score(gt,preds,average='micro'))\n",
    "print('Accuracy: ' , accuracy_score(gt,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b00097-4996-4e0b-b608-d3cb30054420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
