{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f48c29-e578-48c7-ad4a-cf3d15c5dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "dataset = load_dataset(\"McGill-NLP/feedbackQA\")\n",
    "\n",
    "rating_class = {'Excellent':3 , 'Acceptable':2 , 'Could be Improved':1, 'Bad': 0}\n",
    "\n",
    "def process_df(df):\n",
    "    df['list_feedback'] = df['feedback'].apply(lambda x: [ r + \"___\" + e for r,e in zip(x['rating'],x['explanation']) ])\n",
    "    df['sampled_feedback'] = df['list_feedback'].apply(lambda x: x[0].split(\"___\") if (x[0].split(\"___\")[0]!='Excellent' and x[0].split(\"___\")[0]!='Acceptable') else (x[1].split(\"___\") if (x[1].split(\"___\")[0]!='Excellent' and x[1].split(\"___\")[0]!='Acceptable') else np.random.choice(x).split(\"___\")) )\n",
    "    df['rating_class'] = df['sampled_feedback'].apply(lambda x: rating_class[x[0]])\n",
    "    df['rating'] = df['sampled_feedback'].apply(lambda x: x[0])\n",
    "    df['explanation'] = df['sampled_feedback'].apply(lambda x: x[1])\n",
    "    return df\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from accelerate import Accelerator\n",
    "\n",
    "\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class feedback_QA_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,tokenizer,max_length=2048):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        skipped = 0\n",
    "        \n",
    "        for i in range(len(self.df)):\n",
    "            \n",
    "            d = {}\n",
    "            question = self.tokenizer(f\"Question: {self.df.iloc[i]['question']}\", add_special_tokens=True)\n",
    "            answer = self.tokenizer(f\"Answer: {self.df.iloc[i]['answer']}\")\n",
    "            padding = [0] * (self.max_len - len(question['input_ids']+answer['input_ids']) - 1)       \n",
    "            \n",
    "            input = question['input_ids'] + answer['input_ids'] + [tokenizer.eos_token_id] #+ padding\n",
    "            labels = [-100]*len(question['input_ids']) + answer['input_ids'] + [tokenizer.eos_token_id] + [-100]*len(padding)\n",
    "            attention_mask = [1]*len(question['input_ids']) + [1]*len(answer['input_ids']) + [1] + [0]*len(padding)\n",
    "\n",
    "            \n",
    "            if len(input) > self.max_len:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            input = input + padding\n",
    "            \n",
    "            d['input'] = input\n",
    "            d['labels'] = labels\n",
    "            d['attention_mask'] = attention_mask\n",
    "            d['id'] = i\n",
    "\n",
    "            for k in d.keys():\n",
    "                d[k] = torch.tensor(d[k])\n",
    "\n",
    "            self.data.append(d)\n",
    "            \n",
    "        print(f'skipped: {skipped}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def valid(model,valid_DL,epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for b in valid_DL:\n",
    "            out = model(input_ids=b['input_ids'], labels=b['labels'])\n",
    "            loss = out.loss\n",
    "            total_loss += loss.item()\n",
    "    accelerator.print(f\"Epoch: {epoch}\\t\\t---->\\t\\t Valid Loss per batch: {total_loss/len(valid_DL)} \")\n",
    "    return (total_loss/len(valid_DL))\n",
    "\n",
    "\n",
    "def train(model,train_DL,optimizer,epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0\n",
    "    for b in train_DL:\n",
    "        out = model(input_ids=b['input_ids'], labels=b['labels'])\n",
    "        loss = out.loss\n",
    "        total_loss += loss.item()\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "    accelerator.print(f\"Epoch: {epoch}\\t\\t---->\\t\\t Train Loss per batch: {total_loss/len(train_DL)} \")\n",
    "\n",
    "def finetune(bert_chkpt,train_df, valid_df, BATCH_SIZE=2, EPOCHS=20, PATIENCE=5):\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "    accelerator = Accelerator()\n",
    "    device = accelerator.device\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "    model = AutoModelForCausalLM.from_pretrained(bert_chkpt,cache_dir='/home/jupyter/Ravi_new/HF_cache')\n",
    "    \n",
    "    train_dataset = feedback_QA_dataset(train_df,tokenizer)\n",
    "    train_DL = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "    valid_dataset = feedback_QA_dataset(valid_df,tokenizer)\n",
    "    valid_DL = DataLoader(valid_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=1e-6)\n",
    "    \n",
    "    model, train_DL, valid_DL, optimizer = accelerator.prepare(model,train_DL,valid_DL,optimizer)\n",
    "\n",
    "    best_val_loss = validate(model,valid_DL,0)\n",
    "    for e in range(EPOCHS):\n",
    "        train(model,train_DL,optimizer,e)\n",
    "        val_loss = validate(model,valid_DL,e)\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = PATIENCE\n",
    "            \n",
    "            torch.save({'model_state':model.state_dict(),\n",
    "                        'optimizer':optimizer.state_dict(),\n",
    "                        'epoch':e},\n",
    "                        f\"{save_dir}/best_model_chkpt.pth.tar\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            accelerator.print(f\"REDUCING PATIENCE...{patience}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd3d6b4-239c-47ad-9fa2-f22a54c46b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n",
      "skipped: 3566\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "An issue was found when launching the training: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/accelerate/utils/launch.py\", line 543, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_22608/1636976021.py\", line 104, in finetune\n    train_DL = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 351, in __init__\n    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 107, in __init__\n    raise ValueError(\"num_samples should be a positive integer \"\nValueError: num_samples should be a positive integer value, but got num_samples=0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/accelerate/launchers.py:154\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlauncher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    159\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/accelerate/utils/launch.py\", line 543, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_22608/1636976021.py\", line 104, in finetune\n    train_DL = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 351, in __init__\n    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 107, in __init__\n    raise ValueError(\"num_samples should be a positive integer \"\nValueError: num_samples should be a positive integer value, but got num_samples=0\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_launcher\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinetune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-2-7b-chat-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/accelerate/launchers.py:164\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    158\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA has been initialized before the `notebook_launcher` could create a forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis likely stems from an outside import causing issues once the `notebook_launcher()` is called. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease review your imports and test them when running the `notebook_launcher()` to identify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich one is problematic and causing CUDA to be initialized.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn issue was found when launching the training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# No need for a distributed launch otherwise as it's either CPU, GPU or MPS.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_mps_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: An issue was found when launching the training: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/accelerate/utils/launch.py\", line 543, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_22608/1636976021.py\", line 104, in finetune\n    train_DL = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 351, in __init__\n    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\n  File \"/home/jupyter/Ravi_new/py39_env/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 107, in __init__\n    raise ValueError(\"num_samples should be a positive integer \"\nValueError: num_samples should be a positive integer value, but got num_samples=0\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "notebook_launcher(finetune,(\"meta-llama/Llama-2-7b-chat-hf\",pd.read_csv('train_data.csv'),pd.read_csv('valid_data.csv')),num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c9082-cd60-4ea6-a792-d16a46ef5369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
